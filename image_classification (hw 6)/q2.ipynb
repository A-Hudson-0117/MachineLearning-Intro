{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'models/'\n",
    "train_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_map = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "data_path = '../dataset/cifar10'\n",
    "mean = [0.4914, 0.4822, 0.4465] # copied from Q1\n",
    "std = [0.2470, 0.2435, 0.2616] # copied from Q1\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "cifar10_train = data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root=data_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_test = data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root=data_path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Models For Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_in = 3\n",
    "n_channel_1  = 24\n",
    "n_out = len(cifar10_map)\n",
    "\n",
    "# Define the structure of the CNN\n",
    "class ConvolutionalModel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # img is 32 x 32\n",
    "        self.conv1 = nn.Conv2d(n_channel_in, n_channel_1, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # img is 16 x 16\n",
    "        \n",
    "        # Add a fully connected layer at the end of the CNN\n",
    "        self.fc = nn.Linear(n_channel_1 * 16 * 16, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional filters, activation functions, and pooling layers\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        \n",
    "        # Flatten the output of the convolutional layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Apply the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_in = 3\n",
    "n_channel_1  = 16\n",
    "n_channel_2  = 32\n",
    "n_out = len(cifar10_map)\n",
    "\n",
    "# Define the structure of the CNN\n",
    "class ConvolutionalModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # img is 32 x 32\n",
    "        self.conv1 = nn.Conv2d(n_channel_in, n_channel_1, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # img is 16 x 16\n",
    "        self.conv2 = nn.Conv2d(n_channel_1, n_channel_2, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        # img is 8 x 8\n",
    "        \n",
    "        # Add a fully connected layer at the end of the CNN\n",
    "        self.fc_nn = nn.Linear(n_channel_2 * 8 * 8, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional filters, activation functions, and pooling layers\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        \n",
    "        # Flatten the output of the convolutional layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Apply the fully connected layer\n",
    "        out = self.fc_nn(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_in = 3\n",
    "n_channel_1  = 16\n",
    "n_channel_2  = 32\n",
    "n_channel_3  = 64\n",
    "n_out = len(cifar10_map)\n",
    "\n",
    "# Define the structure of the CNN\n",
    "class ConvolutionalModel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # img is 32 x 32\n",
    "        self.conv1 = nn.Conv2d(n_channel_in, n_channel_1, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # img is 16 x 16\n",
    "        self.conv2 = nn.Conv2d(n_channel_1, n_channel_2, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        # img is 8 x 8\n",
    "        self.conv3 = nn.Conv2d(n_channel_2, n_channel_3, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        # img is 4 x 4\n",
    "        \n",
    "        # Add a fully connected layer at the end of the CNN\n",
    "        self.fc_nn = nn.Linear(n_channel_3 * 4 * 4, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional filters, activation functions, and pooling layers\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = self.pool3(self.act3(self.conv3(out)))\n",
    "        \n",
    "        # Flatten the output of the convolutional layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Apply the fully connected layer\n",
    "        out = self.fc_nn(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, training_imgs, loss_fn, optimizer, n_epochs:int, report_period:int = 10):\n",
    "    sum_time = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        start = time.time()\n",
    "        for images, labels in training_imgs:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "        sum_time += (time.time() - start)\n",
    "        if (epoch % report_period == 0) or (epoch == n_epochs - 1):\n",
    "            print(f'epoch {epoch}:\\t Loss: {loss:.15f}\\t AvgTime: {sum_time/(epoch+1):.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Layer Convolutional Neural Network\n",
    "Question 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalModel1(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=4096, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalModel1()\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 1e-2\n",
    "report_rate = 2\n",
    "n_epochs = 300\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\t Loss: 1.192782044410706\t AvgTime: 11.75 s\n",
      "epoch 2:\t Loss: 1.342231035232544\t AvgTime: 12.28 s\n",
      "epoch 4:\t Loss: 1.272854566574097\t AvgTime: 12.81 s\n",
      "epoch 6:\t Loss: 0.996095418930054\t AvgTime: 12.92 s\n",
      "epoch 8:\t Loss: 0.982859492301941\t AvgTime: 12.88 s\n",
      "epoch 10:\t Loss: 0.798455834388733\t AvgTime: 12.92 s\n",
      "epoch 12:\t Loss: 0.784306287765503\t AvgTime: 13.00 s\n",
      "epoch 14:\t Loss: 0.763695597648621\t AvgTime: 12.98 s\n",
      "epoch 16:\t Loss: 1.095210075378418\t AvgTime: 12.95 s\n",
      "epoch 18:\t Loss: 0.838917553424835\t AvgTime: 12.96 s\n",
      "epoch 20:\t Loss: 0.539276719093323\t AvgTime: 12.97 s\n",
      "epoch 22:\t Loss: 0.716680228710175\t AvgTime: 12.99 s\n",
      "epoch 24:\t Loss: 0.891482234001160\t AvgTime: 12.97 s\n",
      "epoch 26:\t Loss: 0.703024268150330\t AvgTime: 12.97 s\n",
      "epoch 28:\t Loss: 0.602555453777313\t AvgTime: 12.94 s\n",
      "epoch 30:\t Loss: 0.442127764225006\t AvgTime: 12.92 s\n",
      "epoch 32:\t Loss: 0.807938396930695\t AvgTime: 12.89 s\n",
      "epoch 34:\t Loss: 0.452445536851883\t AvgTime: 12.91 s\n",
      "epoch 36:\t Loss: 1.010540843009949\t AvgTime: 12.89 s\n",
      "epoch 38:\t Loss: 0.770697474479675\t AvgTime: 12.88 s\n",
      "epoch 40:\t Loss: 0.976161956787109\t AvgTime: 12.88 s\n",
      "epoch 42:\t Loss: 0.799186706542969\t AvgTime: 12.86 s\n",
      "epoch 44:\t Loss: 0.746624708175659\t AvgTime: 12.85 s\n",
      "epoch 46:\t Loss: 0.935321450233459\t AvgTime: 12.84 s\n",
      "epoch 48:\t Loss: 0.644175708293915\t AvgTime: 12.83 s\n",
      "epoch 50:\t Loss: 0.867159187793732\t AvgTime: 12.81 s\n",
      "epoch 52:\t Loss: 0.459986031055450\t AvgTime: 12.80 s\n",
      "epoch 54:\t Loss: 0.459336876869202\t AvgTime: 12.80 s\n",
      "epoch 56:\t Loss: 0.601665139198303\t AvgTime: 12.80 s\n",
      "epoch 58:\t Loss: 0.633064210414886\t AvgTime: 12.79 s\n",
      "epoch 60:\t Loss: 0.752451717853546\t AvgTime: 12.79 s\n",
      "epoch 62:\t Loss: 0.721055090427399\t AvgTime: 12.78 s\n",
      "epoch 64:\t Loss: 0.555940866470337\t AvgTime: 12.78 s\n",
      "epoch 66:\t Loss: 0.820823609828949\t AvgTime: 12.75 s\n",
      "epoch 68:\t Loss: 0.789018094539642\t AvgTime: 12.71 s\n",
      "epoch 70:\t Loss: 0.590298354625702\t AvgTime: 12.67 s\n",
      "epoch 72:\t Loss: 0.477840840816498\t AvgTime: 12.63 s\n",
      "epoch 74:\t Loss: 0.609133243560791\t AvgTime: 12.60 s\n",
      "epoch 76:\t Loss: 0.633352756500244\t AvgTime: 12.56 s\n",
      "epoch 78:\t Loss: 0.578359842300415\t AvgTime: 12.53 s\n",
      "epoch 80:\t Loss: 0.942273318767548\t AvgTime: 12.52 s\n",
      "epoch 82:\t Loss: 0.315129667520523\t AvgTime: 12.51 s\n",
      "epoch 84:\t Loss: 0.377684444189072\t AvgTime: 12.51 s\n",
      "epoch 86:\t Loss: 0.485609561204910\t AvgTime: 12.51 s\n",
      "epoch 88:\t Loss: 0.593073129653931\t AvgTime: 12.51 s\n",
      "epoch 90:\t Loss: 1.119330167770386\t AvgTime: 12.51 s\n",
      "epoch 92:\t Loss: 0.470837771892548\t AvgTime: 12.51 s\n",
      "epoch 94:\t Loss: 1.112785696983337\t AvgTime: 12.51 s\n",
      "epoch 96:\t Loss: 0.568702816963196\t AvgTime: 12.51 s\n",
      "epoch 98:\t Loss: 0.296503573656082\t AvgTime: 12.52 s\n",
      "epoch 100:\t Loss: 0.307279199361801\t AvgTime: 12.51 s\n",
      "epoch 102:\t Loss: 0.523138403892517\t AvgTime: 12.51 s\n",
      "epoch 104:\t Loss: 0.866011381149292\t AvgTime: 12.50 s\n",
      "epoch 106:\t Loss: 0.532971143722534\t AvgTime: 12.50 s\n",
      "epoch 108:\t Loss: 0.660051822662354\t AvgTime: 12.50 s\n",
      "epoch 110:\t Loss: 0.585550665855408\t AvgTime: 12.50 s\n",
      "epoch 112:\t Loss: 1.014230608940125\t AvgTime: 12.50 s\n",
      "epoch 114:\t Loss: 0.553889095783234\t AvgTime: 12.51 s\n",
      "epoch 116:\t Loss: 0.501347780227661\t AvgTime: 12.51 s\n",
      "epoch 118:\t Loss: 0.800011038780212\t AvgTime: 12.51 s\n",
      "epoch 120:\t Loss: 0.926547288894653\t AvgTime: 12.51 s\n",
      "epoch 122:\t Loss: 0.409052133560181\t AvgTime: 12.51 s\n",
      "epoch 124:\t Loss: 0.747459053993225\t AvgTime: 12.51 s\n",
      "epoch 126:\t Loss: 0.531716048717499\t AvgTime: 12.51 s\n",
      "epoch 128:\t Loss: 0.203828051686287\t AvgTime: 12.50 s\n",
      "epoch 130:\t Loss: 0.853433966636658\t AvgTime: 12.50 s\n",
      "epoch 132:\t Loss: 1.141430735588074\t AvgTime: 12.50 s\n",
      "epoch 134:\t Loss: 0.737792491912842\t AvgTime: 12.49 s\n",
      "epoch 136:\t Loss: 0.529797613620758\t AvgTime: 12.49 s\n",
      "epoch 138:\t Loss: 0.423533678054810\t AvgTime: 12.49 s\n",
      "epoch 140:\t Loss: 0.635318934917450\t AvgTime: 12.48 s\n",
      "epoch 142:\t Loss: 0.530876874923706\t AvgTime: 12.48 s\n",
      "epoch 144:\t Loss: 0.297667354345322\t AvgTime: 12.48 s\n",
      "epoch 146:\t Loss: 0.566600203514099\t AvgTime: 12.48 s\n",
      "epoch 148:\t Loss: 0.420798867940903\t AvgTime: 12.48 s\n",
      "epoch 150:\t Loss: 0.641288936138153\t AvgTime: 12.47 s\n",
      "epoch 152:\t Loss: 0.866641104221344\t AvgTime: 12.48 s\n",
      "epoch 154:\t Loss: 0.875508546829224\t AvgTime: 12.48 s\n",
      "epoch 156:\t Loss: 0.270792663097382\t AvgTime: 12.47 s\n",
      "epoch 158:\t Loss: 0.697363376617432\t AvgTime: 12.47 s\n",
      "epoch 160:\t Loss: 0.451096713542938\t AvgTime: 12.47 s\n",
      "epoch 162:\t Loss: 0.772129893302917\t AvgTime: 12.47 s\n",
      "epoch 164:\t Loss: 0.203753650188446\t AvgTime: 12.47 s\n",
      "epoch 166:\t Loss: 0.585871875286102\t AvgTime: 12.47 s\n",
      "epoch 168:\t Loss: 0.433236271142960\t AvgTime: 12.47 s\n",
      "epoch 170:\t Loss: 0.542560696601868\t AvgTime: 12.47 s\n",
      "epoch 172:\t Loss: 0.592525124549866\t AvgTime: 12.47 s\n",
      "epoch 174:\t Loss: 0.699980914592743\t AvgTime: 12.47 s\n",
      "epoch 176:\t Loss: 0.846895933151245\t AvgTime: 12.47 s\n",
      "epoch 178:\t Loss: 0.679130613803864\t AvgTime: 12.46 s\n",
      "epoch 180:\t Loss: 0.442950606346130\t AvgTime: 12.45 s\n",
      "epoch 182:\t Loss: 0.774001598358154\t AvgTime: 12.44 s\n",
      "epoch 184:\t Loss: 0.529548585414886\t AvgTime: 12.43 s\n",
      "epoch 186:\t Loss: 0.441196590662003\t AvgTime: 12.43 s\n",
      "epoch 188:\t Loss: 0.267392426729202\t AvgTime: 12.43 s\n",
      "epoch 190:\t Loss: 0.480157852172852\t AvgTime: 12.42 s\n",
      "epoch 192:\t Loss: 0.468465447425842\t AvgTime: 12.41 s\n",
      "epoch 194:\t Loss: 0.680109024047852\t AvgTime: 12.40 s\n",
      "epoch 196:\t Loss: 0.687236726284027\t AvgTime: 12.38 s\n",
      "epoch 198:\t Loss: 0.548993229866028\t AvgTime: 12.37 s\n",
      "epoch 200:\t Loss: 0.535788238048553\t AvgTime: 12.36 s\n",
      "epoch 202:\t Loss: 0.253497302532196\t AvgTime: 12.35 s\n",
      "epoch 204:\t Loss: 0.360690146684647\t AvgTime: 12.34 s\n",
      "epoch 206:\t Loss: 0.670070469379425\t AvgTime: 12.33 s\n",
      "epoch 208:\t Loss: 0.479254454374313\t AvgTime: 12.33 s\n",
      "epoch 210:\t Loss: 0.696211934089661\t AvgTime: 12.32 s\n",
      "epoch 212:\t Loss: 0.154437184333801\t AvgTime: 12.31 s\n",
      "epoch 214:\t Loss: 0.638046085834503\t AvgTime: 12.31 s\n",
      "epoch 216:\t Loss: 0.603721678256989\t AvgTime: 12.30 s\n",
      "epoch 218:\t Loss: 0.482089310884476\t AvgTime: 12.30 s\n",
      "epoch 220:\t Loss: 0.449887543916702\t AvgTime: 12.29 s\n",
      "epoch 222:\t Loss: 0.585169553756714\t AvgTime: 12.30 s\n",
      "epoch 224:\t Loss: 0.651814341545105\t AvgTime: 12.30 s\n",
      "epoch 226:\t Loss: 0.750956594944000\t AvgTime: 12.30 s\n",
      "epoch 228:\t Loss: 0.332802951335907\t AvgTime: 12.30 s\n",
      "epoch 230:\t Loss: 0.307029277086258\t AvgTime: 12.30 s\n",
      "epoch 232:\t Loss: 0.598291754722595\t AvgTime: 12.30 s\n",
      "epoch 234:\t Loss: 0.624146103858948\t AvgTime: 12.30 s\n",
      "epoch 236:\t Loss: 0.644032537937164\t AvgTime: 12.31 s\n",
      "epoch 238:\t Loss: 0.546654224395752\t AvgTime: 12.31 s\n",
      "epoch 240:\t Loss: 0.286387711763382\t AvgTime: 12.31 s\n",
      "epoch 242:\t Loss: 0.545494735240936\t AvgTime: 12.31 s\n",
      "epoch 244:\t Loss: 0.600944161415100\t AvgTime: 12.31 s\n",
      "epoch 246:\t Loss: 0.406117737293243\t AvgTime: 12.31 s\n",
      "epoch 248:\t Loss: 0.679328918457031\t AvgTime: 12.31 s\n",
      "epoch 250:\t Loss: 0.619611680507660\t AvgTime: 12.31 s\n",
      "epoch 252:\t Loss: 0.702698051929474\t AvgTime: 12.31 s\n",
      "epoch 254:\t Loss: 0.487484425306320\t AvgTime: 12.31 s\n",
      "epoch 256:\t Loss: 0.815515041351318\t AvgTime: 12.31 s\n",
      "epoch 258:\t Loss: 0.212341696023941\t AvgTime: 12.32 s\n",
      "epoch 260:\t Loss: 0.320272684097290\t AvgTime: 12.32 s\n",
      "epoch 262:\t Loss: 0.506700873374939\t AvgTime: 12.32 s\n",
      "epoch 264:\t Loss: 1.302241325378418\t AvgTime: 12.32 s\n",
      "epoch 266:\t Loss: 0.679688394069672\t AvgTime: 12.32 s\n",
      "epoch 268:\t Loss: 0.282104611396790\t AvgTime: 12.33 s\n",
      "epoch 270:\t Loss: 0.374336540699005\t AvgTime: 12.33 s\n",
      "epoch 272:\t Loss: 0.772729039192200\t AvgTime: 12.33 s\n",
      "epoch 274:\t Loss: 0.665217041969299\t AvgTime: 12.33 s\n",
      "epoch 276:\t Loss: 0.738857746124268\t AvgTime: 12.33 s\n",
      "epoch 278:\t Loss: 0.581071019172668\t AvgTime: 12.33 s\n",
      "epoch 280:\t Loss: 0.317291945219040\t AvgTime: 12.33 s\n",
      "epoch 282:\t Loss: 0.303800076246262\t AvgTime: 12.33 s\n",
      "epoch 284:\t Loss: 0.195833325386047\t AvgTime: 12.33 s\n",
      "epoch 286:\t Loss: 0.591568470001221\t AvgTime: 12.33 s\n",
      "epoch 288:\t Loss: 0.960973560810089\t AvgTime: 12.33 s\n",
      "epoch 290:\t Loss: 0.453121095895767\t AvgTime: 12.33 s\n",
      "epoch 292:\t Loss: 0.538687229156494\t AvgTime: 12.33 s\n",
      "epoch 294:\t Loss: 0.392638981342316\t AvgTime: 12.33 s\n",
      "epoch 296:\t Loss: 0.435513645410538\t AvgTime: 12.33 s\n",
      "epoch 298:\t Loss: 0.464508026838303\t AvgTime: 12.33 s\n",
      "epoch 299:\t Loss: 0.752079069614410\t AvgTime: 12.33 s\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    training(model, \n",
    "         cifar10_train, \n",
    "         loss, \n",
    "         optimizer, \n",
    "         n_epochs,\n",
    "         report_period=report_rate\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model :\n",
    "    torch.save(model.state_dict(), save_path + '1_layer_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = ConvolutionalModel1()\n",
    "load_model.load_state_dict(torch.load(save_path + '1_layer_cnn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50000\n",
      "Accuracy: 0.85314\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_train:\n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000\n",
      "Accuracy: 0.56970\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_test:\n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2 Layer Convolutional Neural Network\n",
    "Question 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalModel2(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_nn): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalModel2()\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 1e-2\n",
    "report_rate = 2\n",
    "n_epochs = 300\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\t Loss: 1.458693504333496\t AvgTime: 15.80 s\n",
      "epoch 2:\t Loss: 1.171113610267639\t AvgTime: 15.92 s\n",
      "epoch 4:\t Loss: 1.109544634819031\t AvgTime: 15.97 s\n",
      "epoch 6:\t Loss: 0.877274453639984\t AvgTime: 15.87 s\n",
      "epoch 8:\t Loss: 0.726249217987061\t AvgTime: 15.85 s\n",
      "epoch 10:\t Loss: 0.808838188648224\t AvgTime: 15.86 s\n",
      "epoch 12:\t Loss: 0.469166874885559\t AvgTime: 15.88 s\n",
      "epoch 14:\t Loss: 0.930553793907166\t AvgTime: 15.89 s\n",
      "epoch 16:\t Loss: 0.810217261314392\t AvgTime: 15.89 s\n",
      "epoch 18:\t Loss: 0.706465780735016\t AvgTime: 15.90 s\n",
      "epoch 20:\t Loss: 0.924698352813721\t AvgTime: 15.92 s\n",
      "epoch 22:\t Loss: 0.771431982517242\t AvgTime: 15.95 s\n",
      "epoch 24:\t Loss: 0.694605886936188\t AvgTime: 15.94 s\n",
      "epoch 26:\t Loss: 0.762440264225006\t AvgTime: 15.96 s\n",
      "epoch 28:\t Loss: 0.813989937305450\t AvgTime: 15.97 s\n",
      "epoch 30:\t Loss: 0.335229635238647\t AvgTime: 15.98 s\n",
      "epoch 32:\t Loss: 0.736242473125458\t AvgTime: 16.00 s\n",
      "epoch 34:\t Loss: 0.547020316123962\t AvgTime: 15.99 s\n",
      "epoch 36:\t Loss: 0.987408280372620\t AvgTime: 16.00 s\n",
      "epoch 38:\t Loss: 0.568866908550262\t AvgTime: 16.01 s\n",
      "epoch 40:\t Loss: 0.361904740333557\t AvgTime: 16.02 s\n",
      "epoch 42:\t Loss: 0.298674076795578\t AvgTime: 16.02 s\n",
      "epoch 44:\t Loss: 0.306216508150101\t AvgTime: 16.05 s\n",
      "epoch 46:\t Loss: 0.659295201301575\t AvgTime: 16.04 s\n",
      "epoch 48:\t Loss: 0.434197664260864\t AvgTime: 16.04 s\n",
      "epoch 50:\t Loss: 0.600135445594788\t AvgTime: 16.05 s\n",
      "epoch 52:\t Loss: 0.743622601032257\t AvgTime: 16.06 s\n",
      "epoch 54:\t Loss: 0.400045007467270\t AvgTime: 16.05 s\n",
      "epoch 56:\t Loss: 0.655766904354095\t AvgTime: 16.05 s\n",
      "epoch 58:\t Loss: 0.240228027105331\t AvgTime: 16.05 s\n",
      "epoch 60:\t Loss: 0.295201569795609\t AvgTime: 16.06 s\n",
      "epoch 62:\t Loss: 0.811004817485809\t AvgTime: 16.08 s\n",
      "epoch 64:\t Loss: 0.502798020839691\t AvgTime: 16.08 s\n",
      "epoch 66:\t Loss: 0.334421396255493\t AvgTime: 16.08 s\n",
      "epoch 68:\t Loss: 0.407356798648834\t AvgTime: 16.08 s\n",
      "epoch 70:\t Loss: 0.311676383018494\t AvgTime: 16.08 s\n",
      "epoch 72:\t Loss: 0.404983758926392\t AvgTime: 16.09 s\n",
      "epoch 74:\t Loss: 0.512787580490112\t AvgTime: 16.09 s\n",
      "epoch 76:\t Loss: 0.411975890398026\t AvgTime: 16.08 s\n",
      "epoch 78:\t Loss: 0.248077049851418\t AvgTime: 16.08 s\n",
      "epoch 80:\t Loss: 0.153539136052132\t AvgTime: 16.07 s\n",
      "epoch 82:\t Loss: 0.815419614315033\t AvgTime: 16.06 s\n",
      "epoch 84:\t Loss: 0.149716287851334\t AvgTime: 16.06 s\n",
      "epoch 86:\t Loss: 0.329093098640442\t AvgTime: 16.06 s\n",
      "epoch 88:\t Loss: 0.398216545581818\t AvgTime: 16.06 s\n",
      "epoch 90:\t Loss: 0.449681162834167\t AvgTime: 16.06 s\n",
      "epoch 92:\t Loss: 0.183223724365234\t AvgTime: 16.06 s\n",
      "epoch 94:\t Loss: 0.379494160413742\t AvgTime: 16.08 s\n",
      "epoch 96:\t Loss: 0.205419018864632\t AvgTime: 16.07 s\n",
      "epoch 98:\t Loss: 0.677334845066071\t AvgTime: 16.07 s\n",
      "epoch 100:\t Loss: 0.167844921350479\t AvgTime: 16.07 s\n",
      "epoch 102:\t Loss: 0.512394547462463\t AvgTime: 16.07 s\n",
      "epoch 104:\t Loss: 1.091811776161194\t AvgTime: 16.08 s\n",
      "epoch 106:\t Loss: 0.612587153911591\t AvgTime: 16.17 s\n",
      "epoch 108:\t Loss: 0.439782828092575\t AvgTime: 16.15 s\n",
      "epoch 110:\t Loss: 0.508444011211395\t AvgTime: 16.13 s\n",
      "epoch 112:\t Loss: 0.474880754947662\t AvgTime: 16.10 s\n",
      "epoch 114:\t Loss: 0.577280521392822\t AvgTime: 16.07 s\n",
      "epoch 116:\t Loss: 0.217339262366295\t AvgTime: 16.04 s\n",
      "epoch 118:\t Loss: 0.241715013980865\t AvgTime: 16.01 s\n",
      "epoch 120:\t Loss: 0.794075846672058\t AvgTime: 15.99 s\n",
      "epoch 122:\t Loss: 0.314225971698761\t AvgTime: 15.96 s\n",
      "epoch 124:\t Loss: 0.330960988998413\t AvgTime: 15.93 s\n",
      "epoch 126:\t Loss: 0.480380862951279\t AvgTime: 15.91 s\n",
      "epoch 128:\t Loss: 0.805617570877075\t AvgTime: 15.89 s\n",
      "epoch 130:\t Loss: 0.628880798816681\t AvgTime: 15.86 s\n",
      "epoch 132:\t Loss: 0.330115586519241\t AvgTime: 15.84 s\n",
      "epoch 134:\t Loss: 0.193405136466026\t AvgTime: 15.82 s\n",
      "epoch 136:\t Loss: 0.544800698757172\t AvgTime: 15.79 s\n",
      "epoch 138:\t Loss: 0.450899273157120\t AvgTime: 15.77 s\n",
      "epoch 140:\t Loss: 0.224023550748825\t AvgTime: 15.75 s\n",
      "epoch 142:\t Loss: 0.472230136394501\t AvgTime: 15.73 s\n",
      "epoch 144:\t Loss: 0.516413509845734\t AvgTime: 15.72 s\n",
      "epoch 146:\t Loss: 0.508285760879517\t AvgTime: 15.70 s\n",
      "epoch 148:\t Loss: 0.419224053621292\t AvgTime: 15.68 s\n",
      "epoch 150:\t Loss: 0.199668362736702\t AvgTime: 15.66 s\n",
      "epoch 152:\t Loss: 0.233407482504845\t AvgTime: 15.64 s\n",
      "epoch 154:\t Loss: 0.450379550457001\t AvgTime: 15.63 s\n",
      "epoch 156:\t Loss: 0.279785245656967\t AvgTime: 15.61 s\n",
      "epoch 158:\t Loss: 0.275998681783676\t AvgTime: 15.59 s\n",
      "epoch 160:\t Loss: 0.441226273775101\t AvgTime: 15.58 s\n",
      "epoch 162:\t Loss: 0.287733107805252\t AvgTime: 15.56 s\n",
      "epoch 164:\t Loss: 0.619497954845428\t AvgTime: 15.55 s\n",
      "epoch 166:\t Loss: 0.226717397570610\t AvgTime: 15.53 s\n",
      "epoch 168:\t Loss: 0.318145960569382\t AvgTime: 15.52 s\n",
      "epoch 170:\t Loss: 0.327085793018341\t AvgTime: 15.51 s\n",
      "epoch 172:\t Loss: 1.049120664596558\t AvgTime: 15.49 s\n",
      "epoch 174:\t Loss: 0.248858809471130\t AvgTime: 15.48 s\n",
      "epoch 176:\t Loss: 0.428236305713654\t AvgTime: 15.46 s\n",
      "epoch 178:\t Loss: 0.200223386287689\t AvgTime: 15.45 s\n",
      "epoch 180:\t Loss: 0.395232439041138\t AvgTime: 15.44 s\n",
      "epoch 182:\t Loss: 0.322011113166809\t AvgTime: 15.43 s\n",
      "epoch 184:\t Loss: 0.795316219329834\t AvgTime: 15.41 s\n",
      "epoch 186:\t Loss: 0.351796954870224\t AvgTime: 15.40 s\n",
      "epoch 188:\t Loss: 0.258669286966324\t AvgTime: 15.39 s\n",
      "epoch 190:\t Loss: 0.191483035683632\t AvgTime: 15.38 s\n",
      "epoch 192:\t Loss: 0.414200752973557\t AvgTime: 15.37 s\n",
      "epoch 194:\t Loss: 0.549997389316559\t AvgTime: 15.35 s\n",
      "epoch 196:\t Loss: 0.368033915758133\t AvgTime: 15.34 s\n",
      "epoch 198:\t Loss: 0.365276753902435\t AvgTime: 15.33 s\n",
      "epoch 200:\t Loss: 0.442619591951370\t AvgTime: 15.32 s\n",
      "epoch 202:\t Loss: 0.324238210916519\t AvgTime: 15.31 s\n",
      "epoch 204:\t Loss: 0.445460468530655\t AvgTime: 15.30 s\n",
      "epoch 206:\t Loss: 0.380769729614258\t AvgTime: 15.29 s\n",
      "epoch 208:\t Loss: 0.409083455801010\t AvgTime: 15.28 s\n",
      "epoch 210:\t Loss: 0.233841940760612\t AvgTime: 15.27 s\n",
      "epoch 212:\t Loss: 0.257086575031281\t AvgTime: 15.25 s\n",
      "epoch 214:\t Loss: 0.809729814529419\t AvgTime: 15.24 s\n",
      "epoch 216:\t Loss: 0.189076080918312\t AvgTime: 15.23 s\n",
      "epoch 218:\t Loss: 0.281682729721069\t AvgTime: 15.22 s\n",
      "epoch 220:\t Loss: 0.094193369150162\t AvgTime: 15.21 s\n",
      "epoch 222:\t Loss: 0.546724140644073\t AvgTime: 15.21 s\n",
      "epoch 224:\t Loss: 0.581214368343353\t AvgTime: 15.20 s\n",
      "epoch 226:\t Loss: 0.147758707404137\t AvgTime: 15.19 s\n",
      "epoch 228:\t Loss: 0.079422980546951\t AvgTime: 15.18 s\n",
      "epoch 230:\t Loss: 0.142050877213478\t AvgTime: 15.17 s\n",
      "epoch 232:\t Loss: 0.733696460723877\t AvgTime: 15.16 s\n",
      "epoch 234:\t Loss: 0.264291733503342\t AvgTime: 15.15 s\n",
      "epoch 236:\t Loss: 0.390101432800293\t AvgTime: 15.14 s\n",
      "epoch 238:\t Loss: 0.301382571458817\t AvgTime: 15.13 s\n",
      "epoch 240:\t Loss: 0.473795115947723\t AvgTime: 15.12 s\n",
      "epoch 242:\t Loss: 0.321689993143082\t AvgTime: 15.12 s\n",
      "epoch 244:\t Loss: 0.743364930152893\t AvgTime: 15.11 s\n",
      "epoch 246:\t Loss: 0.104134082794189\t AvgTime: 15.10 s\n",
      "epoch 248:\t Loss: 0.185113772749901\t AvgTime: 15.09 s\n",
      "epoch 250:\t Loss: 0.122064135968685\t AvgTime: 15.08 s\n",
      "epoch 252:\t Loss: 0.136721730232239\t AvgTime: 15.07 s\n",
      "epoch 254:\t Loss: 0.212739393115044\t AvgTime: 15.07 s\n",
      "epoch 256:\t Loss: 0.627404093742371\t AvgTime: 15.06 s\n",
      "epoch 258:\t Loss: 0.301487326622009\t AvgTime: 15.05 s\n",
      "epoch 260:\t Loss: 0.683892965316772\t AvgTime: 15.04 s\n",
      "epoch 262:\t Loss: 0.338053137063980\t AvgTime: 15.03 s\n",
      "epoch 264:\t Loss: 0.723824560642242\t AvgTime: 15.02 s\n",
      "epoch 266:\t Loss: 0.124641716480255\t AvgTime: 15.02 s\n",
      "epoch 268:\t Loss: 0.197619974613190\t AvgTime: 15.01 s\n",
      "epoch 270:\t Loss: 0.385997176170349\t AvgTime: 15.00 s\n",
      "epoch 272:\t Loss: 0.147793203592300\t AvgTime: 15.00 s\n",
      "epoch 274:\t Loss: 0.216050922870636\t AvgTime: 14.99 s\n",
      "epoch 276:\t Loss: 0.758542120456696\t AvgTime: 14.98 s\n",
      "epoch 278:\t Loss: 0.305946797132492\t AvgTime: 14.97 s\n",
      "epoch 280:\t Loss: 0.213111221790314\t AvgTime: 14.96 s\n",
      "epoch 282:\t Loss: 0.407327622175217\t AvgTime: 14.96 s\n",
      "epoch 284:\t Loss: 0.430210977792740\t AvgTime: 14.95 s\n",
      "epoch 286:\t Loss: 0.394136607646942\t AvgTime: 14.94 s\n",
      "epoch 288:\t Loss: 0.504338085651398\t AvgTime: 14.94 s\n",
      "epoch 290:\t Loss: 0.200778007507324\t AvgTime: 14.93 s\n",
      "epoch 292:\t Loss: 0.300305992364883\t AvgTime: 14.92 s\n",
      "epoch 294:\t Loss: 0.471271872520447\t AvgTime: 14.92 s\n",
      "epoch 296:\t Loss: 0.262361675500870\t AvgTime: 14.91 s\n",
      "epoch 298:\t Loss: 0.236048892140388\t AvgTime: 14.90 s\n",
      "epoch 299:\t Loss: 0.409998983144760\t AvgTime: 14.90 s\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    training(model, \n",
    "         cifar10_train, \n",
    "         loss, \n",
    "         optimizer, \n",
    "         n_epochs,\n",
    "         report_period=report_rate\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model :\n",
    "    torch.save(model.state_dict(), save_path + '2_layer_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = ConvolutionalModel2()\n",
    "load_model.load_state_dict(torch.load(save_path + '2_layer_cnn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50000\n",
      "Accuracy: 0.89720\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_train:\n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000\n",
      "Accuracy: 0.64760\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_test:\n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3 Layer Convolutional Neural Network\n",
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalModel3(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act3): ReLU()\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_nn): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalModel3()\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 1e-2\n",
    "report_rate = 2\n",
    "n_epochs = 300\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\t Loss: 1.280963778495789\t AvgTime: 16.19 s\n",
      "epoch 2:\t Loss: 1.487491250038147\t AvgTime: 16.17 s\n",
      "epoch 4:\t Loss: 1.011541962623596\t AvgTime: 16.17 s\n",
      "epoch 6:\t Loss: 0.983987033367157\t AvgTime: 16.16 s\n",
      "epoch 8:\t Loss: 0.667466819286346\t AvgTime: 16.15 s\n",
      "epoch 10:\t Loss: 0.631892263889313\t AvgTime: 16.14 s\n",
      "epoch 12:\t Loss: 0.677984178066254\t AvgTime: 16.14 s\n",
      "epoch 14:\t Loss: 1.267391681671143\t AvgTime: 16.15 s\n",
      "epoch 16:\t Loss: 0.406652420759201\t AvgTime: 16.14 s\n",
      "epoch 18:\t Loss: 0.403346091508865\t AvgTime: 16.14 s\n",
      "epoch 20:\t Loss: 0.508854806423187\t AvgTime: 16.13 s\n",
      "epoch 22:\t Loss: 0.262133955955505\t AvgTime: 16.13 s\n",
      "epoch 24:\t Loss: 0.637381792068481\t AvgTime: 16.13 s\n",
      "epoch 26:\t Loss: 0.602623820304871\t AvgTime: 16.12 s\n",
      "epoch 28:\t Loss: 0.178334668278694\t AvgTime: 16.12 s\n",
      "epoch 30:\t Loss: 0.532237768173218\t AvgTime: 16.12 s\n",
      "epoch 32:\t Loss: 0.419770091772079\t AvgTime: 16.12 s\n",
      "epoch 34:\t Loss: 0.801614046096802\t AvgTime: 16.12 s\n",
      "epoch 36:\t Loss: 0.210775047540665\t AvgTime: 16.12 s\n",
      "epoch 38:\t Loss: 0.219517320394516\t AvgTime: 16.11 s\n",
      "epoch 40:\t Loss: 0.172304362058640\t AvgTime: 16.11 s\n",
      "epoch 42:\t Loss: 0.084799639880657\t AvgTime: 16.11 s\n",
      "epoch 44:\t Loss: 0.211890816688538\t AvgTime: 16.11 s\n",
      "epoch 46:\t Loss: 0.268238663673401\t AvgTime: 16.11 s\n",
      "epoch 48:\t Loss: 0.186000481247902\t AvgTime: 16.11 s\n",
      "epoch 50:\t Loss: 0.098228730261326\t AvgTime: 16.11 s\n",
      "epoch 52:\t Loss: 0.309468865394592\t AvgTime: 16.11 s\n",
      "epoch 54:\t Loss: 0.118498980998993\t AvgTime: 16.11 s\n",
      "epoch 56:\t Loss: 0.496128261089325\t AvgTime: 16.11 s\n",
      "epoch 58:\t Loss: 0.350794523954391\t AvgTime: 16.11 s\n",
      "epoch 60:\t Loss: 0.299360364675522\t AvgTime: 16.11 s\n",
      "epoch 62:\t Loss: 0.660027444362640\t AvgTime: 16.11 s\n",
      "epoch 64:\t Loss: 0.381240010261536\t AvgTime: 16.11 s\n",
      "epoch 66:\t Loss: 0.250219047069550\t AvgTime: 16.11 s\n",
      "epoch 68:\t Loss: 0.202495828270912\t AvgTime: 16.11 s\n",
      "epoch 70:\t Loss: 0.322467029094696\t AvgTime: 16.11 s\n",
      "epoch 72:\t Loss: 0.303791821002960\t AvgTime: 16.11 s\n",
      "epoch 74:\t Loss: 0.316577076911926\t AvgTime: 16.11 s\n",
      "epoch 76:\t Loss: 0.283871471881866\t AvgTime: 16.11 s\n",
      "epoch 78:\t Loss: 0.145040079951286\t AvgTime: 16.11 s\n",
      "epoch 80:\t Loss: 0.109176360070705\t AvgTime: 16.10 s\n",
      "epoch 82:\t Loss: 0.542435288429260\t AvgTime: 16.10 s\n",
      "epoch 84:\t Loss: 0.133200004696846\t AvgTime: 16.10 s\n",
      "epoch 86:\t Loss: 0.074427887797356\t AvgTime: 16.10 s\n",
      "epoch 88:\t Loss: 0.634921550750732\t AvgTime: 16.10 s\n",
      "epoch 90:\t Loss: 0.223808214068413\t AvgTime: 16.10 s\n",
      "epoch 92:\t Loss: 0.153027907013893\t AvgTime: 16.10 s\n",
      "epoch 94:\t Loss: 0.116843357682228\t AvgTime: 16.10 s\n",
      "epoch 96:\t Loss: 0.223453193902969\t AvgTime: 16.10 s\n",
      "epoch 98:\t Loss: 0.542964696884155\t AvgTime: 16.09 s\n",
      "epoch 100:\t Loss: 0.162399828433990\t AvgTime: 16.09 s\n",
      "epoch 102:\t Loss: 0.334143400192261\t AvgTime: 16.09 s\n",
      "epoch 104:\t Loss: 0.165214836597443\t AvgTime: 16.09 s\n",
      "epoch 106:\t Loss: 0.192620933055878\t AvgTime: 16.09 s\n",
      "epoch 108:\t Loss: 0.514796853065491\t AvgTime: 16.09 s\n",
      "epoch 110:\t Loss: 0.379488527774811\t AvgTime: 16.09 s\n",
      "epoch 112:\t Loss: 0.086678668856621\t AvgTime: 16.09 s\n",
      "epoch 114:\t Loss: 0.478315174579620\t AvgTime: 16.09 s\n",
      "epoch 116:\t Loss: 0.056797150522470\t AvgTime: 16.09 s\n",
      "epoch 118:\t Loss: 0.021790690720081\t AvgTime: 16.09 s\n",
      "epoch 120:\t Loss: 0.596272349357605\t AvgTime: 16.08 s\n",
      "epoch 122:\t Loss: 0.414212316274643\t AvgTime: 16.08 s\n",
      "epoch 124:\t Loss: 0.157961517572403\t AvgTime: 16.08 s\n",
      "epoch 126:\t Loss: 0.016588384285569\t AvgTime: 16.08 s\n",
      "epoch 128:\t Loss: 0.054651059210300\t AvgTime: 16.08 s\n",
      "epoch 130:\t Loss: 0.607279837131500\t AvgTime: 16.08 s\n",
      "epoch 132:\t Loss: 0.195992618799210\t AvgTime: 16.08 s\n",
      "epoch 134:\t Loss: 0.242883414030075\t AvgTime: 16.08 s\n",
      "epoch 136:\t Loss: 0.406818240880966\t AvgTime: 16.08 s\n",
      "epoch 138:\t Loss: 0.512930572032928\t AvgTime: 16.08 s\n",
      "epoch 140:\t Loss: 0.215191915631294\t AvgTime: 16.08 s\n",
      "epoch 142:\t Loss: 0.277491450309753\t AvgTime: 16.08 s\n",
      "epoch 144:\t Loss: 0.212152779102325\t AvgTime: 16.08 s\n",
      "epoch 146:\t Loss: 0.441133856773376\t AvgTime: 16.08 s\n",
      "epoch 148:\t Loss: 0.313640832901001\t AvgTime: 16.08 s\n",
      "epoch 150:\t Loss: 0.050601556897163\t AvgTime: 16.08 s\n",
      "epoch 152:\t Loss: 0.270472407341003\t AvgTime: 16.08 s\n",
      "epoch 154:\t Loss: 0.236292570829391\t AvgTime: 16.08 s\n",
      "epoch 156:\t Loss: 0.313125252723694\t AvgTime: 16.08 s\n",
      "epoch 158:\t Loss: 0.711311399936676\t AvgTime: 16.08 s\n",
      "epoch 160:\t Loss: 0.471684187650681\t AvgTime: 16.08 s\n",
      "epoch 162:\t Loss: 0.119695693254471\t AvgTime: 16.08 s\n",
      "epoch 164:\t Loss: 0.195346206426620\t AvgTime: 16.08 s\n",
      "epoch 166:\t Loss: 0.654694378376007\t AvgTime: 16.08 s\n",
      "epoch 168:\t Loss: 0.593879520893097\t AvgTime: 16.08 s\n",
      "epoch 170:\t Loss: 0.337938994169235\t AvgTime: 16.08 s\n",
      "epoch 172:\t Loss: 0.047380790114403\t AvgTime: 16.08 s\n",
      "epoch 174:\t Loss: 0.411558419466019\t AvgTime: 16.08 s\n",
      "epoch 176:\t Loss: 0.256776690483093\t AvgTime: 16.08 s\n",
      "epoch 178:\t Loss: 0.937277197837830\t AvgTime: 16.08 s\n",
      "epoch 180:\t Loss: 0.287412941455841\t AvgTime: 16.08 s\n",
      "epoch 182:\t Loss: 0.297695368528366\t AvgTime: 16.08 s\n",
      "epoch 184:\t Loss: 0.123860895633698\t AvgTime: 16.08 s\n",
      "epoch 186:\t Loss: 0.371503561735153\t AvgTime: 16.08 s\n",
      "epoch 188:\t Loss: 0.018139334395528\t AvgTime: 16.08 s\n",
      "epoch 190:\t Loss: 0.010548458434641\t AvgTime: 16.08 s\n",
      "epoch 192:\t Loss: 0.135356947779655\t AvgTime: 16.08 s\n",
      "epoch 194:\t Loss: 0.142342805862427\t AvgTime: 16.08 s\n",
      "epoch 196:\t Loss: 0.454192847013474\t AvgTime: 16.08 s\n",
      "epoch 198:\t Loss: 0.075606547296047\t AvgTime: 16.08 s\n",
      "epoch 200:\t Loss: 0.422481626272202\t AvgTime: 16.09 s\n",
      "epoch 202:\t Loss: 0.198464915156364\t AvgTime: 16.09 s\n",
      "epoch 204:\t Loss: 0.000313281867420\t AvgTime: 16.09 s\n",
      "epoch 206:\t Loss: 0.513754725456238\t AvgTime: 16.09 s\n",
      "epoch 208:\t Loss: 0.471108853816986\t AvgTime: 16.09 s\n",
      "epoch 210:\t Loss: 0.025609210133553\t AvgTime: 16.09 s\n",
      "epoch 212:\t Loss: 0.081261433660984\t AvgTime: 16.09 s\n",
      "epoch 214:\t Loss: 0.366253823041916\t AvgTime: 16.10 s\n",
      "epoch 216:\t Loss: 0.422474563121796\t AvgTime: 16.10 s\n",
      "epoch 218:\t Loss: 0.199856877326965\t AvgTime: 16.10 s\n",
      "epoch 220:\t Loss: 0.301009058952332\t AvgTime: 16.10 s\n",
      "epoch 222:\t Loss: 0.020617187023163\t AvgTime: 16.10 s\n",
      "epoch 224:\t Loss: 0.169029861688614\t AvgTime: 16.10 s\n",
      "epoch 226:\t Loss: 0.296695649623871\t AvgTime: 16.10 s\n",
      "epoch 228:\t Loss: 0.026392202824354\t AvgTime: 16.11 s\n",
      "epoch 230:\t Loss: 0.017075901851058\t AvgTime: 16.11 s\n",
      "epoch 232:\t Loss: 0.034953482449055\t AvgTime: 16.11 s\n",
      "epoch 234:\t Loss: 0.231685414910316\t AvgTime: 16.11 s\n",
      "epoch 236:\t Loss: 0.598319470882416\t AvgTime: 16.11 s\n",
      "epoch 238:\t Loss: 0.138265743851662\t AvgTime: 16.12 s\n",
      "epoch 240:\t Loss: 0.623602569103241\t AvgTime: 16.12 s\n",
      "epoch 242:\t Loss: 0.009489441290498\t AvgTime: 16.12 s\n",
      "epoch 244:\t Loss: 0.979044198989868\t AvgTime: 16.12 s\n",
      "epoch 246:\t Loss: 0.584197759628296\t AvgTime: 16.13 s\n",
      "epoch 248:\t Loss: 0.699343740940094\t AvgTime: 16.13 s\n",
      "epoch 250:\t Loss: 0.023858549073339\t AvgTime: 16.13 s\n",
      "epoch 252:\t Loss: 0.598764002323151\t AvgTime: 16.13 s\n",
      "epoch 254:\t Loss: 0.064203597605228\t AvgTime: 16.14 s\n",
      "epoch 256:\t Loss: 0.187378317117691\t AvgTime: 16.14 s\n",
      "epoch 258:\t Loss: 0.150836139917374\t AvgTime: 16.14 s\n",
      "epoch 260:\t Loss: 0.030202602967620\t AvgTime: 16.14 s\n",
      "epoch 262:\t Loss: 0.256901174783707\t AvgTime: 16.14 s\n",
      "epoch 264:\t Loss: 0.555444538593292\t AvgTime: 16.15 s\n",
      "epoch 266:\t Loss: 0.020596196874976\t AvgTime: 16.15 s\n",
      "epoch 268:\t Loss: 0.192021667957306\t AvgTime: 16.15 s\n",
      "epoch 270:\t Loss: 0.203605264425278\t AvgTime: 16.16 s\n",
      "epoch 272:\t Loss: 0.608869194984436\t AvgTime: 16.16 s\n",
      "epoch 274:\t Loss: 0.496035337448120\t AvgTime: 16.16 s\n",
      "epoch 276:\t Loss: 0.470520108938217\t AvgTime: 16.16 s\n",
      "epoch 278:\t Loss: 0.303210347890854\t AvgTime: 16.17 s\n",
      "epoch 280:\t Loss: 0.623985767364502\t AvgTime: 16.17 s\n",
      "epoch 282:\t Loss: 0.159866452217102\t AvgTime: 16.17 s\n",
      "epoch 284:\t Loss: 0.258242309093475\t AvgTime: 16.17 s\n",
      "epoch 286:\t Loss: 0.722220838069916\t AvgTime: 16.17 s\n",
      "epoch 288:\t Loss: 0.031360428780317\t AvgTime: 16.18 s\n",
      "epoch 290:\t Loss: 0.198933720588684\t AvgTime: 16.18 s\n",
      "epoch 292:\t Loss: 0.361244171857834\t AvgTime: 16.18 s\n",
      "epoch 294:\t Loss: 0.480706036090851\t AvgTime: 16.19 s\n",
      "epoch 296:\t Loss: 0.003544384147972\t AvgTime: 16.19 s\n",
      "epoch 298:\t Loss: 0.099680095911026\t AvgTime: 16.19 s\n",
      "epoch 299:\t Loss: 0.097704403102398\t AvgTime: 16.19 s\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    training(model, \n",
    "         cifar10_train, \n",
    "         loss, \n",
    "         optimizer, \n",
    "         n_epochs,\n",
    "         report_period=report_rate\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model :\n",
    "    torch.save(model.state_dict(), save_path + '3_layer_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = ConvolutionalModel3()\n",
    "load_model.load_state_dict(torch.load(save_path + '3_layer_cnn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50000\n",
      "Accuracy: 0.94010\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_train:\n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000\n",
      "Accuracy: 0.67140\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_test:\n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77aa5c7a8032890130e9a412da4828609b1dfa25c62620094c03af7a5cea44b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
