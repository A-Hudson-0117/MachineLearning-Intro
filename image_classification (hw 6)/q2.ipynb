{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_map = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "data_path = '../dataset/cifar10'\n",
    "mean = [0.4914, 0.4822, 0.4465] # copied from Q1\n",
    "std = [0.2470, 0.2435, 0.2616] # copied from Q1\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "cifar10_train = data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root=data_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_test = data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        root=data_path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Models For Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_in = 3\n",
    "n_channel_1  = 16\n",
    "n_channel_2  = 32\n",
    "n_out = len(cifar10_map)\n",
    "\n",
    "# Define the structure of the CNN\n",
    "class ConvolutionalModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # img is 32 x 32\n",
    "        self.conv1 = nn.Conv2d(n_channel_in, n_channel_1, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # img is 16 x 16\n",
    "        self.conv2 = nn.Conv2d(n_channel_1, n_channel_2, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        # img is 8 x 8\n",
    "        \n",
    "        # Add a fully connected layer at the end of the CNN\n",
    "        self.fc_nn = nn.Linear(n_channel_2 * 8 * 8, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional filters, activation functions, and pooling layers\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        \n",
    "        # Flatten the output of the convolutional layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Apply the fully connected layer\n",
    "        out = self.fc_nn(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_in = 3\n",
    "n_channel_1  = 24\n",
    "n_out = len(cifar10_map)\n",
    "\n",
    "# Define the structure of the CNN\n",
    "class ConvolutionalModel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # img is 32 x 32\n",
    "        self.conv1 = nn.Conv2d(n_channel_in, n_channel_1, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # img is 16 x 16\n",
    "        \n",
    "        # Add a fully connected layer at the end of the CNN\n",
    "        self.fc = nn.Linear(n_channel_1 * 16 * 16, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional filters, activation functions, and pooling layers\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        \n",
    "        # Flatten the output of the convolutional layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Apply the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, training_imgs, loss_fn, optimizer, n_epochs:int, report_period:int = 10):\n",
    "    for epoch in range(n_epochs):\n",
    "        for images, labels in training_imgs:\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "        if epoch % report_period == 0:\n",
    "            print(f'epoch {epoch}:\\t Loss: {loss:.15f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Layer Convolutional Neural Network\n",
    "Question 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalModel1(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=6144, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalModel1()\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 1e-2\n",
    "report_rate = 2\n",
    "n_epochs = 300\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]  Loss: 2.0867693424224854\n",
      "[2]  Loss: 1.6567201614379883\n",
      "[4]  Loss: 1.876031517982483\n",
      "[6]  Loss: 2.1773462295532227\n",
      "[8]  Loss: 2.1267964839935303\n",
      "[10]  Loss: 1.554593563079834\n",
      "[12]  Loss: 1.3991973400115967\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Adam\\Documents\\__School\\_UNC C\\ecgr 4105\\MachineLearning-Intro\\image_classification (hw 6)\\q2.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training(model, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m          cifar10_train, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m          loss, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m          optimizer, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m          n_epochs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m          report_period\u001b[39m=\u001b[39;49mreport_rate\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m          )\n",
      "\u001b[1;32md:\\Adam\\Documents\\__School\\_UNC C\\ecgr 4105\\MachineLearning-Intro\\image_classification (hw 6)\\q2.ipynb Cell 14\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(model, training_imgs, loss_fn, optimizer, n_epochs, report_period)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining\u001b[39m(model, training_imgs, loss_fn, optimizer, n_epochs:\u001b[39mint\u001b[39m, report_period:\u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mfor\u001b[39;00m images, labels \u001b[39min\u001b[39;00m training_imgs:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m             \u001b[39m# Zero the gradients\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m             optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             \u001b[39m# Forward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    128\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(model, \n",
    "         cifar10_train, \n",
    "         loss, \n",
    "         optimizer, \n",
    "         n_epochs,\n",
    "         report_period=report_rate\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50000\n",
      "Accuracy: 0.467200\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_train:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000\n",
      "Accuracy: 0.388400\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_test:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Layer Convolutional Neural Network\n",
    "Question 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalModel2(\n",
       "  (conv1): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_nn): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalModel2()\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 1e-2\n",
    "report_rate = 2\n",
    "n_epochs = 300\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]  Loss: 2.02242374420166\n",
      "[2]  Loss: 1.7911823987960815\n",
      "[4]  Loss: 1.6053640842437744\n",
      "[6]  Loss: 1.82623291015625\n",
      "[8]  Loss: 1.8039251565933228\n",
      "[10]  Loss: 1.5589200258255005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Adam\\Documents\\__School\\_UNC C\\ecgr 4105\\MachineLearning-Intro\\image_classification (hw 6)\\q2.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training(model, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m          cifar10_train, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m          loss, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m          optimizer, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m          n_epochs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m          report_period\u001b[39m=\u001b[39;49mreport_rate\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m          )\n",
      "\u001b[1;32md:\\Adam\\Documents\\__School\\_UNC C\\ecgr 4105\\MachineLearning-Intro\\image_classification (hw 6)\\q2.ipynb Cell 20\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(model, training_imgs, loss_fn, optimizer, n_epochs, report_period)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Update the parameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Adam/Documents/__School/_UNC%20C/ecgr%204105/MachineLearning-Intro/image_classification%20%28hw%206%29/q2.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(model, \n",
    "         cifar10_train, \n",
    "         loss, \n",
    "         optimizer, \n",
    "         n_epochs,\n",
    "         report_period=report_rate\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50000\n",
      "Accuracy: 0.348860\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_train:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000\n",
      "Accuracy: 0.340500\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_test:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77aa5c7a8032890130e9a412da4828609b1dfa25c62620094c03af7a5cea44b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
