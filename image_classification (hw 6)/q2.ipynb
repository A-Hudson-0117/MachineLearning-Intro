{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = True\n",
    "\n",
    "save_path = 'models/'\n",
    "sub_name = '_cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA supported by this system? True\n",
      "CUDA version: 11.7\n",
      "ID of current CUDA device: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "# print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the code device-agnostic\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_map = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}\n",
    "data_path = '../dataset/cifar10'\n",
    "mean = [0.4914, 0.4822, 0.4465] # copied from Q1\n",
    "std = [0.2470, 0.2435, 0.2616] # copied from Q1\n",
    "batch_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "train_data = datasets.CIFAR10(\n",
    "        root=data_path,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    )\n",
    "cifar10_train = data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_data = datasets.CIFAR10(\n",
    "        root=data_path,\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    )\n",
    "cifar10_test = data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Models For Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_in = 3\n",
    "n_channel_1  = 24\n",
    "n_out = len(cifar10_map)\n",
    "\n",
    "# Define the structure of the CNN\n",
    "class ConvolutionalModel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # img is 32 x 32\n",
    "        self.conv1 = nn.Conv2d(n_channel_in, n_channel_1, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # img is 16 x 16\n",
    "        \n",
    "        # Add a fully connected layer at the end of the CNN\n",
    "        self.fc = nn.Linear(n_channel_1 * 16 * 16, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional filters, activation functions, and pooling layers\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        \n",
    "        # Flatten the output of the convolutional layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Apply the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_in = 3\n",
    "n_channel_1  = 16\n",
    "n_channel_2  = 32\n",
    "n_out = len(cifar10_map)\n",
    "\n",
    "# Define the structure of the CNN\n",
    "class ConvolutionalModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # img is 32 x 32\n",
    "        self.conv1 = nn.Conv2d(n_channel_in, n_channel_1, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # img is 16 x 16\n",
    "        self.conv2 = nn.Conv2d(n_channel_1, n_channel_2, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        # img is 8 x 8\n",
    "        \n",
    "        # Add a fully connected layer at the end of the CNN\n",
    "        self.fc_nn = nn.Linear(n_channel_2 * 8 * 8, n_out)\n",
    "\n",
    "    def forward(self, out):\n",
    "        # Apply the convolutional filters, activation functions, and pooling layers\n",
    "        out = self.pool1(self.act1(self.conv1(out)))\n",
    "        \n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        \n",
    "        # Flatten the output of the convolutional layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Apply the fully connected layer\n",
    "        out = self.fc_nn(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel_in = 3\n",
    "n_channel_1  = 16\n",
    "n_channel_2  = 32\n",
    "n_channel_3  = 64\n",
    "n_out = len(cifar10_map)\n",
    "\n",
    "# Define the structure of the CNN\n",
    "class ConvolutionalModel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # img is 32 x 32\n",
    "        self.conv1 = nn.Conv2d(n_channel_in, n_channel_1, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        # img is 16 x 16\n",
    "        self.conv2 = nn.Conv2d(n_channel_1, n_channel_2, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        # img is 8 x 8\n",
    "        self.conv3 = nn.Conv2d(n_channel_2, n_channel_3, kernel_size=3, padding=1)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        # img is 4 x 4\n",
    "        \n",
    "        # Add a fully connected layer at the end of the CNN\n",
    "        self.fc_nn = nn.Linear(n_channel_3 * 4 * 4, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional filters, activation functions, and pooling layers\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = self.pool3(self.act3(self.conv3(out)))\n",
    "        \n",
    "        # Flatten the output of the convolutional layers\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Apply the fully connected layer\n",
    "        out = self.fc_nn(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, training_imgs, loss_fn, optimizer, n_epochs:int, report_period:int = 10):\n",
    "    sum_time = 0\n",
    "    for epoch in range(n_epochs):\n",
    "        start = time.time()\n",
    "        for images, labels in training_imgs:\n",
    "            # Convert to device (cuda)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            _outputs = model(images)\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(_outputs, labels)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "        sum_time += (time.time() - start)\n",
    "        if (epoch % report_period == 0) or (epoch == n_epochs - 1):\n",
    "            print(f'epoch {epoch}:\\t Loss: {loss:.15f}\\t AvgTime: {sum_time/(epoch+1):.2f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Layer Convolutional Neural Network\n",
    "Question 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalModel1(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=4096, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalModel1()\n",
    "model = model.to(device)\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 1e-2\n",
    "report_rate = 2\n",
    "n_epochs = 300\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate)\n",
    "# optimizer = optimizer.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss = loss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\t Loss: 2.148381471633911\t AvgTime: 18.16 s\n",
      "epoch 2:\t Loss: 2.012739896774292\t AvgTime: 14.16 s\n",
      "epoch 4:\t Loss: 1.952702760696411\t AvgTime: 13.54 s\n",
      "epoch 6:\t Loss: 1.872948884963989\t AvgTime: 13.48 s\n",
      "epoch 8:\t Loss: 1.836333990097046\t AvgTime: 13.24 s\n",
      "epoch 10:\t Loss: 1.813726544380188\t AvgTime: 13.15 s\n",
      "epoch 12:\t Loss: 1.778575420379639\t AvgTime: 13.03 s\n",
      "epoch 14:\t Loss: 1.759590983390808\t AvgTime: 12.94 s\n",
      "epoch 16:\t Loss: 1.733090996742249\t AvgTime: 12.85 s\n",
      "epoch 18:\t Loss: 1.726481080055237\t AvgTime: 12.79 s\n",
      "epoch 20:\t Loss: 1.687560319900513\t AvgTime: 12.73 s\n",
      "epoch 22:\t Loss: 1.678763031959534\t AvgTime: 12.70 s\n",
      "epoch 24:\t Loss: 1.676784753799438\t AvgTime: 12.72 s\n",
      "epoch 26:\t Loss: 1.645305633544922\t AvgTime: 12.71 s\n",
      "epoch 28:\t Loss: 1.632562994956970\t AvgTime: 12.68 s\n",
      "epoch 30:\t Loss: 1.634198546409607\t AvgTime: 12.65 s\n",
      "epoch 32:\t Loss: 1.591570615768433\t AvgTime: 12.62 s\n",
      "epoch 34:\t Loss: 1.601046442985535\t AvgTime: 12.61 s\n",
      "epoch 36:\t Loss: 1.589016675949097\t AvgTime: 12.59 s\n",
      "epoch 38:\t Loss: 1.584752917289734\t AvgTime: 12.61 s\n",
      "epoch 40:\t Loss: 1.561240196228027\t AvgTime: 12.59 s\n",
      "epoch 42:\t Loss: 1.558634519577026\t AvgTime: 12.57 s\n",
      "epoch 44:\t Loss: 1.547934293746948\t AvgTime: 12.56 s\n",
      "epoch 46:\t Loss: 1.531457185745239\t AvgTime: 12.55 s\n",
      "epoch 48:\t Loss: 1.512682676315308\t AvgTime: 12.55 s\n",
      "epoch 50:\t Loss: 1.512116432189941\t AvgTime: 12.57 s\n",
      "epoch 52:\t Loss: 1.507902026176453\t AvgTime: 12.56 s\n",
      "epoch 54:\t Loss: 1.472544908523560\t AvgTime: 12.54 s\n",
      "epoch 56:\t Loss: 1.487205624580383\t AvgTime: 12.53 s\n",
      "epoch 58:\t Loss: 1.483453273773193\t AvgTime: 12.53 s\n",
      "epoch 60:\t Loss: 1.467987060546875\t AvgTime: 12.52 s\n",
      "epoch 62:\t Loss: 1.467647194862366\t AvgTime: 12.53 s\n",
      "epoch 64:\t Loss: 1.440849184989929\t AvgTime: 12.52 s\n",
      "epoch 66:\t Loss: 1.435927391052246\t AvgTime: 12.51 s\n",
      "epoch 68:\t Loss: 1.447855710983276\t AvgTime: 12.49 s\n",
      "epoch 70:\t Loss: 1.432965278625488\t AvgTime: 12.49 s\n",
      "epoch 72:\t Loss: 1.424260854721069\t AvgTime: 12.48 s\n",
      "epoch 74:\t Loss: 1.415464878082275\t AvgTime: 12.47 s\n",
      "epoch 76:\t Loss: 1.390692949295044\t AvgTime: 12.46 s\n",
      "epoch 78:\t Loss: 1.389787912368774\t AvgTime: 12.45 s\n",
      "epoch 80:\t Loss: 1.380878329277039\t AvgTime: 12.45 s\n",
      "epoch 82:\t Loss: 1.378607034683228\t AvgTime: 12.44 s\n",
      "epoch 84:\t Loss: 1.364982008934021\t AvgTime: 12.43 s\n",
      "epoch 86:\t Loss: 1.362926125526428\t AvgTime: 12.43 s\n",
      "epoch 88:\t Loss: 1.351748228073120\t AvgTime: 12.42 s\n",
      "epoch 90:\t Loss: 1.352887511253357\t AvgTime: 12.40 s\n",
      "epoch 92:\t Loss: 1.364153385162354\t AvgTime: 12.40 s\n",
      "epoch 94:\t Loss: 1.326824665069580\t AvgTime: 12.40 s\n",
      "epoch 96:\t Loss: 1.327644467353821\t AvgTime: 12.39 s\n",
      "epoch 98:\t Loss: 1.321910738945007\t AvgTime: 12.38 s\n",
      "epoch 100:\t Loss: 1.349020004272461\t AvgTime: 12.37 s\n",
      "epoch 102:\t Loss: 1.322507023811340\t AvgTime: 12.37 s\n",
      "epoch 104:\t Loss: 1.313919186592102\t AvgTime: 12.37 s\n",
      "epoch 106:\t Loss: 1.294832348823547\t AvgTime: 12.37 s\n",
      "epoch 108:\t Loss: 1.305098891258240\t AvgTime: 12.37 s\n",
      "epoch 110:\t Loss: 1.286866903305054\t AvgTime: 12.36 s\n",
      "epoch 112:\t Loss: 1.288749575614929\t AvgTime: 12.35 s\n",
      "epoch 114:\t Loss: 1.276909708976746\t AvgTime: 12.35 s\n",
      "epoch 116:\t Loss: 1.274798154830933\t AvgTime: 12.35 s\n",
      "epoch 118:\t Loss: 1.272312283515930\t AvgTime: 12.34 s\n",
      "epoch 120:\t Loss: 1.275307297706604\t AvgTime: 12.34 s\n",
      "epoch 122:\t Loss: 1.263589978218079\t AvgTime: 12.33 s\n",
      "epoch 124:\t Loss: 1.300037026405334\t AvgTime: 12.34 s\n",
      "epoch 126:\t Loss: 1.291095614433289\t AvgTime: 12.33 s\n",
      "epoch 128:\t Loss: 1.267029047012329\t AvgTime: 12.33 s\n",
      "epoch 130:\t Loss: 1.258422374725342\t AvgTime: 12.33 s\n",
      "epoch 132:\t Loss: 1.263676524162292\t AvgTime: 12.32 s\n",
      "epoch 134:\t Loss: 1.258745789527893\t AvgTime: 12.32 s\n",
      "epoch 136:\t Loss: 1.239214539527893\t AvgTime: 12.32 s\n",
      "epoch 138:\t Loss: 1.243258714675903\t AvgTime: 12.32 s\n",
      "epoch 140:\t Loss: 1.222675800323486\t AvgTime: 12.31 s\n",
      "epoch 142:\t Loss: 1.274469494819641\t AvgTime: 12.31 s\n",
      "epoch 144:\t Loss: 1.222275853157043\t AvgTime: 12.31 s\n",
      "epoch 146:\t Loss: 1.236236691474915\t AvgTime: 12.30 s\n",
      "epoch 148:\t Loss: 1.218522429466248\t AvgTime: 12.30 s\n",
      "epoch 150:\t Loss: 1.256969690322876\t AvgTime: 12.30 s\n",
      "epoch 152:\t Loss: 1.229362368583679\t AvgTime: 12.29 s\n",
      "epoch 154:\t Loss: 1.229195356369019\t AvgTime: 12.29 s\n",
      "epoch 156:\t Loss: 1.226264238357544\t AvgTime: 12.29 s\n",
      "epoch 158:\t Loss: 1.211547613143921\t AvgTime: 12.29 s\n",
      "epoch 160:\t Loss: 1.221412062644958\t AvgTime: 12.29 s\n",
      "epoch 162:\t Loss: 1.228404521942139\t AvgTime: 12.29 s\n",
      "epoch 164:\t Loss: 1.197674751281738\t AvgTime: 12.29 s\n",
      "epoch 166:\t Loss: 1.222772121429443\t AvgTime: 12.29 s\n",
      "epoch 168:\t Loss: 1.211006283760071\t AvgTime: 12.29 s\n",
      "epoch 170:\t Loss: 1.217005014419556\t AvgTime: 12.28 s\n",
      "epoch 172:\t Loss: 1.194827675819397\t AvgTime: 12.28 s\n",
      "epoch 174:\t Loss: 1.195721507072449\t AvgTime: 12.28 s\n",
      "epoch 176:\t Loss: 1.210205435752869\t AvgTime: 12.28 s\n",
      "epoch 178:\t Loss: 1.177451133728027\t AvgTime: 12.29 s\n",
      "epoch 180:\t Loss: 1.211993217468262\t AvgTime: 12.28 s\n",
      "epoch 182:\t Loss: 1.199459552764893\t AvgTime: 12.28 s\n",
      "epoch 184:\t Loss: 1.189978480339050\t AvgTime: 12.29 s\n",
      "epoch 186:\t Loss: 1.203068017959595\t AvgTime: 12.28 s\n",
      "epoch 188:\t Loss: 1.182588458061218\t AvgTime: 12.28 s\n",
      "epoch 190:\t Loss: 1.170475244522095\t AvgTime: 12.28 s\n",
      "epoch 192:\t Loss: 1.176368832588196\t AvgTime: 12.28 s\n",
      "epoch 194:\t Loss: 1.179268002510071\t AvgTime: 12.28 s\n",
      "epoch 196:\t Loss: 1.187839150428772\t AvgTime: 12.28 s\n",
      "epoch 198:\t Loss: 1.168234586715698\t AvgTime: 12.28 s\n",
      "epoch 200:\t Loss: 1.176277995109558\t AvgTime: 12.28 s\n",
      "epoch 202:\t Loss: 1.172338843345642\t AvgTime: 12.28 s\n",
      "epoch 204:\t Loss: 1.167480111122131\t AvgTime: 12.28 s\n",
      "epoch 206:\t Loss: 1.156551599502563\t AvgTime: 12.28 s\n",
      "epoch 208:\t Loss: 1.176175951957703\t AvgTime: 12.28 s\n",
      "epoch 210:\t Loss: 1.174684047698975\t AvgTime: 12.28 s\n",
      "epoch 212:\t Loss: 1.166233420372009\t AvgTime: 12.28 s\n",
      "epoch 214:\t Loss: 1.198660492897034\t AvgTime: 12.28 s\n",
      "epoch 216:\t Loss: 1.159811377525330\t AvgTime: 12.28 s\n",
      "epoch 218:\t Loss: 1.176746845245361\t AvgTime: 12.28 s\n",
      "epoch 220:\t Loss: 1.154589772224426\t AvgTime: 12.28 s\n",
      "epoch 222:\t Loss: 1.143279433250427\t AvgTime: 12.28 s\n",
      "epoch 224:\t Loss: 1.170039296150208\t AvgTime: 12.28 s\n",
      "epoch 226:\t Loss: 1.157019019126892\t AvgTime: 12.28 s\n",
      "epoch 228:\t Loss: 1.170146942138672\t AvgTime: 12.28 s\n",
      "epoch 230:\t Loss: 1.133809447288513\t AvgTime: 12.28 s\n",
      "epoch 232:\t Loss: 1.145743012428284\t AvgTime: 12.28 s\n",
      "epoch 234:\t Loss: 1.121430516242981\t AvgTime: 12.28 s\n",
      "epoch 236:\t Loss: 1.138243198394775\t AvgTime: 12.27 s\n",
      "epoch 238:\t Loss: 1.154454350471497\t AvgTime: 12.27 s\n",
      "epoch 240:\t Loss: 1.139661908149719\t AvgTime: 12.27 s\n",
      "epoch 242:\t Loss: 1.171445369720459\t AvgTime: 12.27 s\n",
      "epoch 244:\t Loss: 1.138565659523010\t AvgTime: 12.27 s\n",
      "epoch 246:\t Loss: 1.102329611778259\t AvgTime: 12.27 s\n",
      "epoch 248:\t Loss: 1.117249369621277\t AvgTime: 12.27 s\n",
      "epoch 250:\t Loss: 1.130818843841553\t AvgTime: 12.27 s\n",
      "epoch 252:\t Loss: 1.111289024353027\t AvgTime: 12.27 s\n",
      "epoch 254:\t Loss: 1.138874292373657\t AvgTime: 12.27 s\n",
      "epoch 256:\t Loss: 1.123574018478394\t AvgTime: 12.28 s\n",
      "epoch 258:\t Loss: 1.134368300437927\t AvgTime: 12.28 s\n",
      "epoch 260:\t Loss: 1.122017860412598\t AvgTime: 12.28 s\n",
      "epoch 262:\t Loss: 1.108311176300049\t AvgTime: 12.28 s\n",
      "epoch 264:\t Loss: 1.117346405982971\t AvgTime: 12.28 s\n",
      "epoch 266:\t Loss: 1.131234288215637\t AvgTime: 12.28 s\n",
      "epoch 268:\t Loss: 1.125494122505188\t AvgTime: 12.28 s\n",
      "epoch 270:\t Loss: 1.109787702560425\t AvgTime: 12.28 s\n",
      "epoch 272:\t Loss: 1.135408401489258\t AvgTime: 12.28 s\n",
      "epoch 274:\t Loss: 1.153505444526672\t AvgTime: 12.28 s\n",
      "epoch 276:\t Loss: 1.125238656997681\t AvgTime: 12.27 s\n",
      "epoch 278:\t Loss: 1.124150156974792\t AvgTime: 12.27 s\n",
      "epoch 280:\t Loss: 1.110727548599243\t AvgTime: 12.27 s\n",
      "epoch 282:\t Loss: 1.110169529914856\t AvgTime: 12.27 s\n",
      "epoch 284:\t Loss: 1.098062157630920\t AvgTime: 12.27 s\n",
      "epoch 286:\t Loss: 1.129083395004272\t AvgTime: 12.27 s\n",
      "epoch 288:\t Loss: 1.122163534164429\t AvgTime: 12.27 s\n",
      "epoch 290:\t Loss: 1.106358528137207\t AvgTime: 12.27 s\n",
      "epoch 292:\t Loss: 1.123113036155701\t AvgTime: 12.27 s\n",
      "epoch 294:\t Loss: 1.120002150535583\t AvgTime: 12.27 s\n",
      "epoch 296:\t Loss: 1.097128033638000\t AvgTime: 12.27 s\n",
      "epoch 298:\t Loss: 1.099011540412903\t AvgTime: 12.27 s\n",
      "epoch 299:\t Loss: 1.094388604164124\t AvgTime: 12.27 s\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    training(model, \n",
    "         cifar10_train, \n",
    "         loss, \n",
    "         optimizer, \n",
    "         n_epochs,\n",
    "         report_period=report_rate\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model :\n",
    "    torch.save(model.state_dict(), save_path + f'1_layer_cnn{sub_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = ConvolutionalModel1()\n",
    "load_model = load_model.to(device)\n",
    "load_model.load_state_dict(torch.load(save_path + f'1_layer_cnn{sub_name}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50000\n",
      "Accuracy: 0.62388\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_train:\n",
    "        # convert to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000\n",
      "Accuracy: 0.58070\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_test:\n",
    "        # convert to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2 Layer Convolutional Neural Network\n",
    "Question 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalModel2(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_nn): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalModel2()\n",
    "model = model.to(device)\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 1e-2\n",
    "report_rate = 2\n",
    "n_epochs = 300\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss = loss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\t Loss: 2.286010026931763\t AvgTime: 12.31 s\n",
      "epoch 2:\t Loss: 2.252520799636841\t AvgTime: 12.14 s\n",
      "epoch 4:\t Loss: 2.213654756546021\t AvgTime: 12.20 s\n",
      "epoch 6:\t Loss: 2.172257900238037\t AvgTime: 12.19 s\n",
      "epoch 8:\t Loss: 2.127006053924561\t AvgTime: 12.19 s\n",
      "epoch 10:\t Loss: 2.072481632232666\t AvgTime: 12.15 s\n",
      "epoch 12:\t Loss: 2.032099008560181\t AvgTime: 12.12 s\n",
      "epoch 14:\t Loss: 1.996951699256897\t AvgTime: 12.15 s\n",
      "epoch 16:\t Loss: 1.967066168785095\t AvgTime: 12.16 s\n",
      "epoch 18:\t Loss: 1.937609434127808\t AvgTime: 12.13 s\n",
      "epoch 20:\t Loss: 1.915834546089172\t AvgTime: 12.13 s\n",
      "epoch 22:\t Loss: 1.876950025558472\t AvgTime: 12.16 s\n",
      "epoch 24:\t Loss: 1.851774573326111\t AvgTime: 12.18 s\n",
      "epoch 26:\t Loss: 1.833824753761292\t AvgTime: 12.18 s\n",
      "epoch 28:\t Loss: 1.828540444374084\t AvgTime: 12.17 s\n",
      "epoch 30:\t Loss: 1.814255237579346\t AvgTime: 12.17 s\n",
      "epoch 32:\t Loss: 1.798223018646240\t AvgTime: 12.17 s\n",
      "epoch 34:\t Loss: 1.771083354949951\t AvgTime: 12.19 s\n",
      "epoch 36:\t Loss: 1.754318118095398\t AvgTime: 12.18 s\n",
      "epoch 38:\t Loss: 1.754208564758301\t AvgTime: 12.18 s\n",
      "epoch 40:\t Loss: 1.732138514518738\t AvgTime: 12.17 s\n",
      "epoch 42:\t Loss: 1.723890423774719\t AvgTime: 12.17 s\n",
      "epoch 44:\t Loss: 1.715262055397034\t AvgTime: 12.17 s\n",
      "epoch 46:\t Loss: 1.736783027648926\t AvgTime: 12.16 s\n",
      "epoch 48:\t Loss: 1.677781581878662\t AvgTime: 12.16 s\n",
      "epoch 50:\t Loss: 1.669500231742859\t AvgTime: 12.15 s\n",
      "epoch 52:\t Loss: 1.639465808868408\t AvgTime: 12.16 s\n",
      "epoch 54:\t Loss: 1.638867735862732\t AvgTime: 12.17 s\n",
      "epoch 56:\t Loss: 1.639241814613342\t AvgTime: 12.16 s\n",
      "epoch 58:\t Loss: 1.601780891418457\t AvgTime: 12.16 s\n",
      "epoch 60:\t Loss: 1.605559229850769\t AvgTime: 12.16 s\n",
      "epoch 62:\t Loss: 1.589562296867371\t AvgTime: 12.16 s\n",
      "epoch 64:\t Loss: 1.583255290985107\t AvgTime: 12.16 s\n",
      "epoch 66:\t Loss: 1.584240317344666\t AvgTime: 12.15 s\n",
      "epoch 68:\t Loss: 1.564901113510132\t AvgTime: 12.16 s\n",
      "epoch 70:\t Loss: 1.552003979682922\t AvgTime: 12.16 s\n",
      "epoch 72:\t Loss: 1.524862527847290\t AvgTime: 12.16 s\n",
      "epoch 74:\t Loss: 1.549224376678467\t AvgTime: 12.17 s\n",
      "epoch 76:\t Loss: 1.514271736145020\t AvgTime: 12.17 s\n",
      "epoch 78:\t Loss: 1.537231206893921\t AvgTime: 12.17 s\n",
      "epoch 80:\t Loss: 1.502198576927185\t AvgTime: 12.17 s\n",
      "epoch 82:\t Loss: 1.496394872665405\t AvgTime: 12.17 s\n",
      "epoch 84:\t Loss: 1.490154266357422\t AvgTime: 12.17 s\n",
      "epoch 86:\t Loss: 1.497488379478455\t AvgTime: 12.18 s\n",
      "epoch 88:\t Loss: 1.510947227478027\t AvgTime: 12.18 s\n",
      "epoch 90:\t Loss: 1.457075715065002\t AvgTime: 12.18 s\n",
      "epoch 92:\t Loss: 1.449797868728638\t AvgTime: 12.18 s\n",
      "epoch 94:\t Loss: 1.488973617553711\t AvgTime: 12.18 s\n",
      "epoch 96:\t Loss: 1.442782759666443\t AvgTime: 12.19 s\n",
      "epoch 98:\t Loss: 1.464842319488525\t AvgTime: 12.19 s\n",
      "epoch 100:\t Loss: 1.459284543991089\t AvgTime: 12.20 s\n",
      "epoch 102:\t Loss: 1.474519491195679\t AvgTime: 12.20 s\n",
      "epoch 104:\t Loss: 1.437529444694519\t AvgTime: 12.20 s\n",
      "epoch 106:\t Loss: 1.441065907478333\t AvgTime: 12.20 s\n",
      "epoch 108:\t Loss: 1.450911283493042\t AvgTime: 12.20 s\n",
      "epoch 110:\t Loss: 1.425079226493835\t AvgTime: 12.20 s\n",
      "epoch 112:\t Loss: 1.426730513572693\t AvgTime: 12.21 s\n",
      "epoch 114:\t Loss: 1.416092038154602\t AvgTime: 12.21 s\n",
      "epoch 116:\t Loss: 1.418835401535034\t AvgTime: 12.22 s\n",
      "epoch 118:\t Loss: 1.401436686515808\t AvgTime: 12.22 s\n",
      "epoch 120:\t Loss: 1.385793089866638\t AvgTime: 12.21 s\n",
      "epoch 122:\t Loss: 1.401233315467834\t AvgTime: 12.27 s\n",
      "epoch 124:\t Loss: 1.386366724967957\t AvgTime: 12.27 s\n",
      "epoch 126:\t Loss: 1.405180215835571\t AvgTime: 12.27 s\n",
      "epoch 128:\t Loss: 1.378451704978943\t AvgTime: 12.28 s\n",
      "epoch 130:\t Loss: 1.392775774002075\t AvgTime: 12.30 s\n",
      "epoch 132:\t Loss: 1.381015896797180\t AvgTime: 12.35 s\n",
      "epoch 134:\t Loss: 1.361237645149231\t AvgTime: 12.48 s\n",
      "epoch 136:\t Loss: 1.373357534408569\t AvgTime: 12.52 s\n",
      "epoch 138:\t Loss: 1.365934610366821\t AvgTime: 12.55 s\n",
      "epoch 140:\t Loss: 1.351262450218201\t AvgTime: 12.69 s\n",
      "epoch 142:\t Loss: 1.358795762062073\t AvgTime: 12.90 s\n",
      "epoch 144:\t Loss: 1.368062734603882\t AvgTime: 12.98 s\n",
      "epoch 146:\t Loss: 1.346091032028198\t AvgTime: 13.07 s\n",
      "epoch 148:\t Loss: 1.345525145530701\t AvgTime: 13.17 s\n",
      "epoch 150:\t Loss: 1.351487398147583\t AvgTime: 13.29 s\n",
      "epoch 152:\t Loss: 1.346819996833801\t AvgTime: 13.38 s\n",
      "epoch 154:\t Loss: 1.324272632598877\t AvgTime: 13.43 s\n",
      "epoch 156:\t Loss: 1.342524170875549\t AvgTime: 13.45 s\n",
      "epoch 158:\t Loss: 1.307923674583435\t AvgTime: 13.47 s\n",
      "epoch 160:\t Loss: 1.339894413948059\t AvgTime: 13.49 s\n",
      "epoch 162:\t Loss: 1.336582422256470\t AvgTime: 13.51 s\n",
      "epoch 164:\t Loss: 1.336902379989624\t AvgTime: 13.53 s\n",
      "epoch 166:\t Loss: 1.321816444396973\t AvgTime: 13.55 s\n",
      "epoch 168:\t Loss: 1.309105753898621\t AvgTime: 13.56 s\n",
      "epoch 170:\t Loss: 1.298411488533020\t AvgTime: 13.58 s\n",
      "epoch 172:\t Loss: 1.325235605239868\t AvgTime: 13.60 s\n",
      "epoch 174:\t Loss: 1.296615481376648\t AvgTime: 13.62 s\n",
      "epoch 176:\t Loss: 1.309171438217163\t AvgTime: 13.63 s\n",
      "epoch 178:\t Loss: 1.329168200492859\t AvgTime: 13.65 s\n",
      "epoch 180:\t Loss: 1.322645664215088\t AvgTime: 13.66 s\n",
      "epoch 182:\t Loss: 1.288583636283875\t AvgTime: 13.67 s\n",
      "epoch 184:\t Loss: 1.308701753616333\t AvgTime: 13.69 s\n",
      "epoch 186:\t Loss: 1.345325112342834\t AvgTime: 13.70 s\n",
      "epoch 188:\t Loss: 1.296922683715820\t AvgTime: 13.75 s\n",
      "epoch 190:\t Loss: 1.283248424530029\t AvgTime: 13.78 s\n",
      "epoch 192:\t Loss: 1.284822225570679\t AvgTime: 13.82 s\n",
      "epoch 194:\t Loss: 1.293431401252747\t AvgTime: 13.86 s\n",
      "epoch 196:\t Loss: 1.252556324005127\t AvgTime: 13.89 s\n",
      "epoch 198:\t Loss: 1.263577580451965\t AvgTime: 13.92 s\n",
      "epoch 200:\t Loss: 1.241860628128052\t AvgTime: 13.97 s\n",
      "epoch 202:\t Loss: 1.272583723068237\t AvgTime: 14.01 s\n",
      "epoch 204:\t Loss: 1.293616771697998\t AvgTime: 14.05 s\n",
      "epoch 206:\t Loss: 1.249737024307251\t AvgTime: 14.09 s\n",
      "epoch 208:\t Loss: 1.274805784225464\t AvgTime: 14.12 s\n",
      "epoch 210:\t Loss: 1.252716064453125\t AvgTime: 14.14 s\n",
      "epoch 212:\t Loss: 1.241842389106750\t AvgTime: 14.16 s\n",
      "epoch 214:\t Loss: 1.215625762939453\t AvgTime: 14.18 s\n",
      "epoch 216:\t Loss: 1.240987539291382\t AvgTime: 14.21 s\n",
      "epoch 218:\t Loss: 1.230098724365234\t AvgTime: 14.23 s\n",
      "epoch 220:\t Loss: 1.232815861701965\t AvgTime: 14.24 s\n",
      "epoch 222:\t Loss: 1.248472094535828\t AvgTime: 14.25 s\n",
      "epoch 224:\t Loss: 1.241206169128418\t AvgTime: 14.27 s\n",
      "epoch 226:\t Loss: 1.232648372650146\t AvgTime: 14.28 s\n",
      "epoch 228:\t Loss: 1.212979912757874\t AvgTime: 14.30 s\n",
      "epoch 230:\t Loss: 1.226062059402466\t AvgTime: 14.31 s\n",
      "epoch 232:\t Loss: 1.222316741943359\t AvgTime: 14.32 s\n",
      "epoch 234:\t Loss: 1.216706991195679\t AvgTime: 14.34 s\n",
      "epoch 236:\t Loss: 1.237229347229004\t AvgTime: 14.37 s\n",
      "epoch 238:\t Loss: 1.268485665321350\t AvgTime: 14.39 s\n",
      "epoch 240:\t Loss: 1.185025691986084\t AvgTime: 14.42 s\n",
      "epoch 242:\t Loss: 1.201709270477295\t AvgTime: 14.44 s\n",
      "epoch 244:\t Loss: 1.225691556930542\t AvgTime: 14.48 s\n",
      "epoch 246:\t Loss: 1.228837847709656\t AvgTime: 14.49 s\n",
      "epoch 248:\t Loss: 1.223539710044861\t AvgTime: 14.50 s\n",
      "epoch 250:\t Loss: 1.243287324905396\t AvgTime: 14.51 s\n",
      "epoch 252:\t Loss: 1.213016390800476\t AvgTime: 14.52 s\n",
      "epoch 254:\t Loss: 1.205712556838989\t AvgTime: 14.53 s\n",
      "epoch 256:\t Loss: 1.215881109237671\t AvgTime: 14.55 s\n",
      "epoch 258:\t Loss: 1.194376826286316\t AvgTime: 14.56 s\n",
      "epoch 260:\t Loss: 1.201943755149841\t AvgTime: 14.58 s\n",
      "epoch 262:\t Loss: 1.188480138778687\t AvgTime: 14.59 s\n",
      "epoch 264:\t Loss: 1.174682378768921\t AvgTime: 14.62 s\n",
      "epoch 266:\t Loss: 1.200811386108398\t AvgTime: 14.63 s\n",
      "epoch 268:\t Loss: 1.183211803436279\t AvgTime: 14.65 s\n",
      "epoch 270:\t Loss: 1.157495856285095\t AvgTime: 14.67 s\n",
      "epoch 272:\t Loss: 1.186696529388428\t AvgTime: 14.68 s\n",
      "epoch 274:\t Loss: 1.153692364692688\t AvgTime: 14.69 s\n",
      "epoch 276:\t Loss: 1.176306009292603\t AvgTime: 14.69 s\n",
      "epoch 278:\t Loss: 1.145288228988647\t AvgTime: 14.71 s\n",
      "epoch 280:\t Loss: 1.170749664306641\t AvgTime: 14.72 s\n",
      "epoch 282:\t Loss: 1.217077493667603\t AvgTime: 14.74 s\n",
      "epoch 284:\t Loss: 1.150506615638733\t AvgTime: 14.75 s\n",
      "epoch 286:\t Loss: 1.155064105987549\t AvgTime: 14.77 s\n",
      "epoch 288:\t Loss: 1.149831891059875\t AvgTime: 14.78 s\n",
      "epoch 290:\t Loss: 1.143668413162231\t AvgTime: 14.79 s\n",
      "epoch 292:\t Loss: 1.137010693550110\t AvgTime: 14.81 s\n",
      "epoch 294:\t Loss: 1.151570081710815\t AvgTime: 14.81 s\n",
      "epoch 296:\t Loss: 1.131166100502014\t AvgTime: 14.81 s\n",
      "epoch 298:\t Loss: 1.152693748474121\t AvgTime: 14.82 s\n",
      "epoch 299:\t Loss: 1.143582105636597\t AvgTime: 14.82 s\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    training(model, \n",
    "         cifar10_train, \n",
    "         loss, \n",
    "         optimizer, \n",
    "         n_epochs,\n",
    "         report_period=report_rate\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model :\n",
    "    torch.save(model.state_dict(), save_path + f'2_layer_cnn{sub_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = ConvolutionalModel2()\n",
    "load_model = load_model.to(device)\n",
    "load_model.load_state_dict(torch.load(save_path + f'2_layer_cnn{sub_name}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50000\n",
      "Accuracy: 0.59416\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_train:\n",
    "        # convert to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000\n",
      "Accuracy: 0.57520\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_test:\n",
    "        # convert to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3 Layer Convolutional Neural Network\n",
    "extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalModel3(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (act3): ReLU()\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_nn): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalModel3()\n",
    "model = model.to(device)\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate = 1e-2\n",
    "report_rate = 2\n",
    "n_epochs = 300\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learn_rate)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss = loss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0:\t Loss: 2.304883241653442\t AvgTime: 18.19 s\n",
      "epoch 2:\t Loss: 2.297615766525269\t AvgTime: 17.76 s\n",
      "epoch 4:\t Loss: 2.288931131362915\t AvgTime: 17.28 s\n",
      "epoch 6:\t Loss: 2.280941009521484\t AvgTime: 17.60 s\n",
      "epoch 8:\t Loss: 2.275190114974976\t AvgTime: 17.46 s\n",
      "epoch 10:\t Loss: 2.261464118957520\t AvgTime: 17.62 s\n",
      "epoch 12:\t Loss: 2.240642309188843\t AvgTime: 17.40 s\n",
      "epoch 14:\t Loss: 2.220862150192261\t AvgTime: 17.42 s\n",
      "epoch 16:\t Loss: 2.194751977920532\t AvgTime: 17.37 s\n",
      "epoch 18:\t Loss: 2.162788152694702\t AvgTime: 17.30 s\n",
      "epoch 20:\t Loss: 2.136578559875488\t AvgTime: 17.21 s\n",
      "epoch 22:\t Loss: 2.098626852035522\t AvgTime: 17.12 s\n",
      "epoch 24:\t Loss: 2.069032907485962\t AvgTime: 17.22 s\n",
      "epoch 26:\t Loss: 2.043383836746216\t AvgTime: 17.14 s\n",
      "epoch 28:\t Loss: 2.017389059066772\t AvgTime: 17.08 s\n",
      "epoch 30:\t Loss: 2.000645160675049\t AvgTime: 17.01 s\n",
      "epoch 32:\t Loss: 1.983270525932312\t AvgTime: 16.95 s\n",
      "epoch 34:\t Loss: 1.966071248054504\t AvgTime: 16.96 s\n",
      "epoch 36:\t Loss: 1.947727203369141\t AvgTime: 16.99 s\n",
      "epoch 38:\t Loss: 1.934031248092651\t AvgTime: 16.98 s\n",
      "epoch 40:\t Loss: 1.889921307563782\t AvgTime: 16.99 s\n",
      "epoch 42:\t Loss: 1.874391436576843\t AvgTime: 16.97 s\n",
      "epoch 44:\t Loss: 1.849801778793335\t AvgTime: 16.94 s\n",
      "epoch 46:\t Loss: 1.821582674980164\t AvgTime: 16.89 s\n",
      "epoch 48:\t Loss: 1.821052908897400\t AvgTime: 16.86 s\n",
      "epoch 50:\t Loss: 1.810627698898315\t AvgTime: 16.89 s\n",
      "epoch 52:\t Loss: 1.785271286964417\t AvgTime: 16.93 s\n",
      "epoch 54:\t Loss: 1.797197699546814\t AvgTime: 16.91 s\n",
      "epoch 56:\t Loss: 1.775377511978149\t AvgTime: 16.92 s\n",
      "epoch 58:\t Loss: 1.772136330604553\t AvgTime: 16.89 s\n",
      "epoch 60:\t Loss: 1.712947607040405\t AvgTime: 16.92 s\n",
      "epoch 62:\t Loss: 1.740014076232910\t AvgTime: 16.93 s\n",
      "epoch 64:\t Loss: 1.718617439270020\t AvgTime: 16.93 s\n",
      "epoch 66:\t Loss: 1.688661336898804\t AvgTime: 16.92 s\n",
      "epoch 68:\t Loss: 1.698800206184387\t AvgTime: 16.90 s\n",
      "epoch 70:\t Loss: 1.676452398300171\t AvgTime: 16.91 s\n",
      "epoch 72:\t Loss: 1.678706884384155\t AvgTime: 16.93 s\n",
      "epoch 74:\t Loss: 1.667761921882629\t AvgTime: 16.94 s\n",
      "epoch 76:\t Loss: 1.661326527595520\t AvgTime: 16.94 s\n",
      "epoch 78:\t Loss: 1.648689508438110\t AvgTime: 16.96 s\n",
      "epoch 80:\t Loss: 1.646829247474670\t AvgTime: 16.95 s\n",
      "epoch 82:\t Loss: 1.659756064414978\t AvgTime: 16.96 s\n",
      "epoch 84:\t Loss: 1.647490978240967\t AvgTime: 16.97 s\n",
      "epoch 86:\t Loss: 1.635593891143799\t AvgTime: 17.00 s\n",
      "epoch 88:\t Loss: 1.606354713439941\t AvgTime: 16.99 s\n",
      "epoch 90:\t Loss: 1.596112847328186\t AvgTime: 16.96 s\n",
      "epoch 92:\t Loss: 1.629938960075378\t AvgTime: 16.96 s\n",
      "epoch 94:\t Loss: 1.597532987594604\t AvgTime: 16.98 s\n",
      "epoch 96:\t Loss: 1.619569897651672\t AvgTime: 17.01 s\n",
      "epoch 98:\t Loss: 1.557269930839539\t AvgTime: 17.01 s\n",
      "epoch 100:\t Loss: 1.534381389617920\t AvgTime: 17.02 s\n",
      "epoch 102:\t Loss: 1.576396226882935\t AvgTime: 17.04 s\n",
      "epoch 104:\t Loss: 1.545375823974609\t AvgTime: 17.06 s\n",
      "epoch 106:\t Loss: 1.564058899879456\t AvgTime: 17.08 s\n",
      "epoch 108:\t Loss: 1.552444577217102\t AvgTime: 17.12 s\n",
      "epoch 110:\t Loss: 1.536990046501160\t AvgTime: 17.10 s\n",
      "epoch 112:\t Loss: 1.512998819351196\t AvgTime: 17.09 s\n",
      "epoch 114:\t Loss: 1.524575710296631\t AvgTime: 17.08 s\n",
      "epoch 116:\t Loss: 1.515407562255859\t AvgTime: 17.14 s\n",
      "epoch 118:\t Loss: 1.498787045478821\t AvgTime: 17.17 s\n",
      "epoch 120:\t Loss: 1.476700901985168\t AvgTime: 17.19 s\n",
      "epoch 122:\t Loss: 1.485230326652527\t AvgTime: 17.22 s\n",
      "epoch 124:\t Loss: 1.539101958274841\t AvgTime: 17.23 s\n",
      "epoch 126:\t Loss: 1.463865280151367\t AvgTime: 17.23 s\n",
      "epoch 128:\t Loss: 1.469645500183105\t AvgTime: 17.22 s\n",
      "epoch 130:\t Loss: 1.518099665641785\t AvgTime: 17.23 s\n",
      "epoch 132:\t Loss: 1.432674646377563\t AvgTime: 17.18 s\n",
      "epoch 134:\t Loss: 1.455969810485840\t AvgTime: 17.14 s\n",
      "epoch 136:\t Loss: 1.463418722152710\t AvgTime: 17.07 s\n",
      "epoch 138:\t Loss: 1.452405691146851\t AvgTime: 17.01 s\n",
      "epoch 140:\t Loss: 1.463104367256165\t AvgTime: 16.94 s\n",
      "epoch 142:\t Loss: 1.443808197975159\t AvgTime: 16.89 s\n",
      "epoch 144:\t Loss: 1.457522869110107\t AvgTime: 16.83 s\n",
      "epoch 146:\t Loss: 1.437402725219727\t AvgTime: 16.77 s\n",
      "epoch 148:\t Loss: 1.440696001052856\t AvgTime: 16.72 s\n",
      "epoch 150:\t Loss: 1.455627441406250\t AvgTime: 16.67 s\n",
      "epoch 152:\t Loss: 1.401217579841614\t AvgTime: 16.62 s\n",
      "epoch 154:\t Loss: 1.432345390319824\t AvgTime: 16.58 s\n",
      "epoch 156:\t Loss: 1.436632037162781\t AvgTime: 16.53 s\n",
      "epoch 158:\t Loss: 1.427363753318787\t AvgTime: 16.49 s\n",
      "epoch 160:\t Loss: 1.410257577896118\t AvgTime: 16.44 s\n",
      "epoch 162:\t Loss: 1.384599208831787\t AvgTime: 16.39 s\n",
      "epoch 164:\t Loss: 1.397819042205811\t AvgTime: 16.35 s\n",
      "epoch 166:\t Loss: 1.395241141319275\t AvgTime: 16.31 s\n",
      "epoch 168:\t Loss: 1.391433000564575\t AvgTime: 16.26 s\n",
      "epoch 170:\t Loss: 1.394370436668396\t AvgTime: 16.22 s\n",
      "epoch 172:\t Loss: 1.392224788665771\t AvgTime: 16.18 s\n",
      "epoch 174:\t Loss: 1.396745562553406\t AvgTime: 16.14 s\n",
      "epoch 176:\t Loss: 1.386957168579102\t AvgTime: 16.10 s\n",
      "epoch 178:\t Loss: 1.335024595260620\t AvgTime: 16.06 s\n",
      "epoch 180:\t Loss: 1.378605842590332\t AvgTime: 16.03 s\n",
      "epoch 182:\t Loss: 1.355944275856018\t AvgTime: 16.00 s\n",
      "epoch 184:\t Loss: 1.361094832420349\t AvgTime: 15.96 s\n",
      "epoch 186:\t Loss: 1.374970197677612\t AvgTime: 15.93 s\n",
      "epoch 188:\t Loss: 1.388723254203796\t AvgTime: 15.89 s\n",
      "epoch 190:\t Loss: 1.342010259628296\t AvgTime: 15.86 s\n",
      "epoch 192:\t Loss: 1.362706780433655\t AvgTime: 15.83 s\n",
      "epoch 194:\t Loss: 1.311853528022766\t AvgTime: 15.79 s\n",
      "epoch 196:\t Loss: 1.336730480194092\t AvgTime: 15.76 s\n",
      "epoch 198:\t Loss: 1.347394108772278\t AvgTime: 15.73 s\n",
      "epoch 200:\t Loss: 1.343269705772400\t AvgTime: 15.70 s\n",
      "epoch 202:\t Loss: 1.322077870368958\t AvgTime: 15.67 s\n",
      "epoch 204:\t Loss: 1.338803291320801\t AvgTime: 15.64 s\n",
      "epoch 206:\t Loss: 1.342182397842407\t AvgTime: 15.62 s\n",
      "epoch 208:\t Loss: 1.326525926589966\t AvgTime: 15.59 s\n",
      "epoch 210:\t Loss: 1.341064214706421\t AvgTime: 15.56 s\n",
      "epoch 212:\t Loss: 1.306468009948730\t AvgTime: 15.53 s\n",
      "epoch 214:\t Loss: 1.347586631774902\t AvgTime: 15.51 s\n",
      "epoch 216:\t Loss: 1.307964920997620\t AvgTime: 15.51 s\n",
      "epoch 218:\t Loss: 1.309501886367798\t AvgTime: 15.49 s\n",
      "epoch 220:\t Loss: 1.329560041427612\t AvgTime: 15.46 s\n",
      "epoch 222:\t Loss: 1.342088937759399\t AvgTime: 15.44 s\n",
      "epoch 224:\t Loss: 1.293621063232422\t AvgTime: 15.41 s\n",
      "epoch 226:\t Loss: 1.295987844467163\t AvgTime: 15.39 s\n",
      "epoch 228:\t Loss: 1.299275279045105\t AvgTime: 15.37 s\n",
      "epoch 230:\t Loss: 1.294217228889465\t AvgTime: 15.35 s\n",
      "epoch 232:\t Loss: 1.282129883766174\t AvgTime: 15.33 s\n",
      "epoch 234:\t Loss: 1.286442875862122\t AvgTime: 15.30 s\n",
      "epoch 236:\t Loss: 1.383340001106262\t AvgTime: 15.28 s\n",
      "epoch 238:\t Loss: 1.270310997962952\t AvgTime: 15.26 s\n",
      "epoch 240:\t Loss: 1.245940804481506\t AvgTime: 15.24 s\n",
      "epoch 242:\t Loss: 1.275410532951355\t AvgTime: 15.22 s\n",
      "epoch 244:\t Loss: 1.318874716758728\t AvgTime: 15.20 s\n",
      "epoch 246:\t Loss: 1.258084893226624\t AvgTime: 15.18 s\n",
      "epoch 248:\t Loss: 1.309074878692627\t AvgTime: 15.16 s\n",
      "epoch 250:\t Loss: 1.245908975601196\t AvgTime: 15.14 s\n",
      "epoch 252:\t Loss: 1.280485987663269\t AvgTime: 15.12 s\n",
      "epoch 254:\t Loss: 1.263462662696838\t AvgTime: 15.10 s\n",
      "epoch 256:\t Loss: 1.296762585639954\t AvgTime: 15.09 s\n",
      "epoch 258:\t Loss: 1.252841711044312\t AvgTime: 15.07 s\n",
      "epoch 260:\t Loss: 1.230319619178772\t AvgTime: 15.05 s\n",
      "epoch 262:\t Loss: 1.278255820274353\t AvgTime: 15.04 s\n",
      "epoch 264:\t Loss: 1.246066451072693\t AvgTime: 15.02 s\n",
      "epoch 266:\t Loss: 1.256426334381104\t AvgTime: 15.01 s\n",
      "epoch 268:\t Loss: 1.219975590705872\t AvgTime: 14.99 s\n",
      "epoch 270:\t Loss: 1.235064625740051\t AvgTime: 14.97 s\n",
      "epoch 272:\t Loss: 1.261440992355347\t AvgTime: 14.96 s\n",
      "epoch 274:\t Loss: 1.296992897987366\t AvgTime: 14.94 s\n",
      "epoch 276:\t Loss: 1.243521571159363\t AvgTime: 14.93 s\n",
      "epoch 278:\t Loss: 1.232617139816284\t AvgTime: 14.93 s\n",
      "epoch 280:\t Loss: 1.218316435813904\t AvgTime: 14.92 s\n",
      "epoch 282:\t Loss: 1.221415519714355\t AvgTime: 14.90 s\n",
      "epoch 284:\t Loss: 1.210853576660156\t AvgTime: 14.90 s\n",
      "epoch 286:\t Loss: 1.280001997947693\t AvgTime: 14.90 s\n",
      "epoch 288:\t Loss: 1.227377891540527\t AvgTime: 14.89 s\n",
      "epoch 290:\t Loss: 1.224195957183838\t AvgTime: 14.88 s\n",
      "epoch 292:\t Loss: 1.199134707450867\t AvgTime: 14.87 s\n",
      "epoch 294:\t Loss: 1.230505347251892\t AvgTime: 14.86 s\n",
      "epoch 296:\t Loss: 1.225845694541931\t AvgTime: 14.85 s\n",
      "epoch 298:\t Loss: 1.190488934516907\t AvgTime: 14.84 s\n",
      "epoch 299:\t Loss: 1.192478537559509\t AvgTime: 14.84 s\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    training(model, \n",
    "         cifar10_train, \n",
    "         loss, \n",
    "         optimizer, \n",
    "         n_epochs,\n",
    "         report_period=report_rate\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model :\n",
    "    torch.save(model.state_dict(), save_path + f'3_layer_cnn{sub_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = ConvolutionalModel3()\n",
    "load_model = load_model.to(device)\n",
    "load_model.load_state_dict(torch.load(save_path + f'3_layer_cnn{sub_name}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 50000\n",
      "Accuracy: 0.58290\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_train:\n",
    "        # convert to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000\n",
      "Accuracy: 0.57280\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the CNN on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in cifar10_test:\n",
    "        # convert to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = load_model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Report the training time, training loss, and evaluation accuracy\n",
    "print(f'Total: {total}')\n",
    "print(f'Accuracy: {correct / total:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77aa5c7a8032890130e9a412da4828609b1dfa25c62620094c03af7a5cea44b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
