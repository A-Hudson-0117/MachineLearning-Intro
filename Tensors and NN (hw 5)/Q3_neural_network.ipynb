{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5 Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## define model and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature, w5, w4, w3, w2, w1, b):\n",
    "    return feature[4] * w5 + feature[3] * w4 + feature[2] * w3 + feature[1] * w2 + feature[0] * w1 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(predicted, actual):\n",
    "    squared_diffs = (predicted - actual)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.01, 0.001, 0.0001, 1e-05]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_to_learn_at = [1/x for x in [10, 100, 1000, 10000, 100000]]\n",
    "rates_to_learn_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_for_validation = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(pd.read_csv('Housing.csv'))\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = (545, 13)\n",
      "features are: ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape = {np.shape(housing_df)}\")\n",
    "\n",
    "# creates a list of all variables from the column names\n",
    "feature_list = list( housing_df.columns )\n",
    "\n",
    "print(f\"features are: {feature_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary vars = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
      "furnish vars = ['furnishingstatus']\n",
      "value vars = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n"
     ]
    }
   ],
   "source": [
    "# Maps to turn categorys into numbers \n",
    "def boolean_map(x):\n",
    "    return x.map({'yes': 1 , 'no': 0})\n",
    "def furnish_map(x):\n",
    "    return x.map({'furnished': 1 , 'semi-furnished': 0.5 , 'unfurnished': 0})\n",
    "\n",
    "# Extracts the yes and no column names\n",
    "binary_vars = [*feature_list[5:10], feature_list[11]]\n",
    "print(f\"binary vars = {binary_vars}\")\n",
    "\n",
    "# Extracts the furnishing column names\n",
    "furnish_vars = [feature_list[12]]\n",
    "print(f\"furnish vars = {furnish_vars}\")\n",
    "\n",
    "# Extracts the column names that are actual values\n",
    "valued_vars = feature_list.copy()\n",
    "[valued_vars.remove( item ) for item in binary_vars]\n",
    "[valued_vars.remove( item ) for item in furnish_vars]\n",
    "print(f\"value vars = {valued_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = housing_df.copy()\n",
    "\n",
    "## scale data\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "x_df[valued_vars] = scaler.fit_transform(x_df[valued_vars])\n",
    "\n",
    "## map text values\n",
    "x_df[binary_vars] = x_df[binary_vars].apply(boolean_map)\n",
    "x_df[furnish_vars] = x_df[furnish_vars].apply(furnish_map)\n",
    "\n",
    "## make y_df\n",
    "y_df = x_df.pop('price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_values = valued_vars.copy()\n",
    "# input_values.remove('price')\n",
    "\n",
    "\n",
    "# x_df = x_df[input_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories  mainroad  guestroom  basement  \\\n",
       "0  1.046726  1.403419   1.421812  1.378217         1          0         0   \n",
       "1  1.757010  1.403419   5.405809  2.532024         1          0         0   \n",
       "2  2.218232  0.047278   1.421812  0.224410         1          0         1   \n",
       "3  1.083624  1.403419   1.421812  0.224410         1          0         1   \n",
       "4  1.046726  1.403419  -0.570187  0.224410         1          1         1   \n",
       "\n",
       "   hotwaterheating  airconditioning   parking  prefarea  furnishingstatus  \n",
       "0                0                1  1.517692         1               1.0  \n",
       "1                0                1  2.679409         0               1.0  \n",
       "2                0                0  1.517692         1               0.5  \n",
       "3                0                1  2.679409         1               1.0  \n",
       "4                0                1  1.517692         0               1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.566365\n",
       "1    4.004484\n",
       "2    4.004484\n",
       "3    3.985755\n",
       "4    3.554979\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories   parking\n",
       "0  1.046726  1.403419   1.421812  1.378217  1.517692\n",
       "1  1.757010  1.403419   5.405809  2.532024  2.679409\n",
       "2  2.218232  0.047278   1.421812  0.224410  1.517692\n",
       "3  1.083624  1.403419   1.421812  0.224410  2.679409\n",
       "4  1.046726  1.403419  -0.570187  0.224410  1.517692"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted data\n",
    "for item in [*binary_vars, *furnish_vars] :\n",
    "    x_df.pop(item)\n",
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frame to tensor\n",
    "\n",
    "x = torch.tensor(x_df.values, dtype=torch.float32)\n",
    "y = torch.tensor(y_df.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([545, 5])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([110, 297, 255, 485, 289, 264, 323,  32, 316,  76,  75, 380, 359,\n",
       "         392, 452, 408, 237, 450,  56, 275, 490, 295, 344, 405, 515, 201,\n",
       "         265, 198, 121, 276, 451, 307,  34, 135,  61,  74, 542, 230, 514,\n",
       "         182, 129, 477, 361, 493, 126, 183, 336, 365, 239, 141, 433, 245,\n",
       "         406,  86, 122, 229, 302,  44, 389, 219, 143, 435, 218, 172,  60,\n",
       "         166, 233, 217, 314, 132, 192, 395, 124, 404, 285,   5, 328, 238,\n",
       "         120,  99, 354,  22, 510, 440, 214, 349,  51, 234, 524, 471, 434,\n",
       "         241, 394, 370,   8, 498,   9, 235, 248, 460,   3, 331, 432,  41,\n",
       "         149, 329, 252, 343, 468, 522, 151, 386, 189, 495, 486, 402, 301,\n",
       "         527, 270,  29,   7, 512, 210, 320, 457, 459, 437, 209, 377,  89,\n",
       "         378, 322, 507, 462, 190,  87, 116, 503, 342, 309,  11, 426, 139,\n",
       "         473, 523,  78, 193, 163, 159, 520, 325,  12, 540, 508, 466, 223,\n",
       "         513, 501,  49,  25, 410, 134,  98,  18,  73, 530, 213, 185, 103,\n",
       "         205, 196, 531, 422, 357, 260, 224, 338,  90, 128, 381, 356, 254,\n",
       "         339, 423, 160, 528, 535, 157,  46, 176, 212, 274, 181,  53, 464,\n",
       "         315, 117, 416, 306, 372, 465, 278, 360, 123, 425, 350, 382, 206,\n",
       "         326, 118,  95, 341, 376, 494, 403, 267, 115,  72,  55,  42, 333,\n",
       "         399,  30, 102,   6, 533, 220, 481, 155, 480, 497, 161, 164, 179,\n",
       "          58, 114, 461, 330,  65,  45,  20, 112,  26, 105, 282, 168, 227,\n",
       "         318, 505, 337, 153, 367, 305, 277, 236, 136, 300, 363, 375, 138,\n",
       "         421, 188, 487, 443, 418, 242, 544, 449, 298, 226, 222, 525, 308,\n",
       "         414, 287, 202, 438,  40, 184, 261, 167,  33, 231, 534,  37,  52,\n",
       "         470, 492, 319, 519, 294,  57, 518,  47, 509, 253, 303, 384, 444,\n",
       "         441, 346,  70, 165, 536,  59, 483, 538,  64, 228, 469, 388, 244,\n",
       "         174, 400,  88, 352, 197,  97, 150, 246,  92, 113, 312, 127,  82,\n",
       "         393, 191, 125, 454, 502, 445, 348, 517, 373, 335, 489,  79, 353,\n",
       "          50, 431, 204, 415, 496,  83, 288, 500, 351, 284, 340, 472, 420,\n",
       "         366, 391,  81, 169, 417, 262,  13, 409, 208,  39, 104, 476, 107,\n",
       "         177,  54,  27, 358, 458,  15, 133, 448, 293, 334, 532, 411, 398,\n",
       "         211, 290, 504, 368,  14, 273, 516, 453, 521, 158, 345,  80,  21,\n",
       "         436, 216,  71,  28, 225, 455, 292, 321, 187, 162, 173, 304, 180,\n",
       "         482, 463, 281,  16,  93, 390, 221, 529, 152, 130, 526, 200, 364,\n",
       "         428, 324, 385, 240,  36, 266, 111, 419, 407, 296, 283,  67, 263,\n",
       "          48,  69,  17, 401,  66, 474,   0]),\n",
       " tensor([ 94, 144, 175,   1, 396, 286, 313, 347, 327, 475, 257, 511, 479,\n",
       "           4,  84,  63,  24, 537, 541, 154, 424,   2, 171,  62, 119, 310,\n",
       "          68,  31, 413, 146, 215, 439, 499, 100,  77,  91, 269, 259, 412,\n",
       "         543, 101, 397, 148, 108, 427, 332, 355, 280, 232, 362, 484, 374,\n",
       "         478, 317, 251,  19, 387, 106, 137, 140, 447, 429, 178, 195,  10,\n",
       "          35, 442, 488, 371, 491, 446, 291, 299, 142, 272, 506, 256, 311,\n",
       "         430, 249, 194, 379, 147, 271,  23, 131, 207, 203, 243, 467, 156,\n",
       "         186, 279, 268, 369,  96, 109, 145, 170, 250, 258, 383,  85, 199,\n",
       "         456,  43, 247,  38, 539]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = x.shape[0]\n",
    "n_val = int(percent_for_validation * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, val_indices  # <1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = x[train_indices]\n",
    "training_y  = y [train_indices]\n",
    "\n",
    "validation_x = x[val_indices]\n",
    "validation_y  = y[val_indices]\n",
    "\n",
    "# training_un   = 0.1 * training_x\n",
    "# validation_un = 0.1 * validation_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Learning how to use neural network component\n",
    "nothing to grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2683],\n",
       "        [ 0.5689],\n",
       "        [ 0.9638],\n",
       "        [ 1.0409],\n",
       "        [ 0.5852],\n",
       "        [ 0.9486],\n",
       "        [-0.2637],\n",
       "        [-0.0575],\n",
       "        [ 0.0768],\n",
       "        [ 0.6753],\n",
       "        [ 0.2348],\n",
       "        [ 1.1554],\n",
       "        [ 0.2473],\n",
       "        [ 0.4131],\n",
       "        [ 0.3248],\n",
       "        [ 1.0896],\n",
       "        [ 0.5474],\n",
       "        [ 0.3420],\n",
       "        [ 0.6044],\n",
       "        [ 1.0938],\n",
       "        [ 0.0865],\n",
       "        [ 0.1939],\n",
       "        [ 1.0699],\n",
       "        [ 0.5502],\n",
       "        [ 0.3104],\n",
       "        [ 0.4269],\n",
       "        [ 0.2670],\n",
       "        [ 0.6709],\n",
       "        [ 0.8398],\n",
       "        [ 0.7683],\n",
       "        [ 1.4517],\n",
       "        [-0.3230],\n",
       "        [-0.4169],\n",
       "        [ 0.3605],\n",
       "        [ 1.3581],\n",
       "        [ 0.0457],\n",
       "        [ 1.0396],\n",
       "        [ 1.0144],\n",
       "        [ 0.2828],\n",
       "        [ 0.3368],\n",
       "        [ 0.3891],\n",
       "        [ 1.2160],\n",
       "        [ 0.9399],\n",
       "        [ 0.6687],\n",
       "        [ 0.3420],\n",
       "        [ 0.8240],\n",
       "        [ 0.4632],\n",
       "        [ 1.2805],\n",
       "        [ 0.0404],\n",
       "        [ 0.1768],\n",
       "        [-0.4437],\n",
       "        [-0.1545],\n",
       "        [ 0.8894],\n",
       "        [ 0.5064],\n",
       "        [ 0.3829],\n",
       "        [ 0.5728],\n",
       "        [-0.4633],\n",
       "        [-0.4291],\n",
       "        [ 0.0778],\n",
       "        [ 0.8094],\n",
       "        [-0.3692],\n",
       "        [ 1.0949],\n",
       "        [ 1.1969],\n",
       "        [ 0.2458],\n",
       "        [ 0.5056],\n",
       "        [ 0.4263],\n",
       "        [ 0.6950],\n",
       "        [ 0.0433],\n",
       "        [ 0.4613],\n",
       "        [ 0.3129],\n",
       "        [ 1.0163],\n",
       "        [-1.2591],\n",
       "        [ 0.0556],\n",
       "        [ 0.5329],\n",
       "        [ 0.7633],\n",
       "        [ 0.7904],\n",
       "        [ 0.6821],\n",
       "        [ 0.2678],\n",
       "        [ 0.2604],\n",
       "        [ 0.0026],\n",
       "        [ 1.2949],\n",
       "        [ 0.8332],\n",
       "        [ 0.5265],\n",
       "        [-0.0486],\n",
       "        [ 1.1357],\n",
       "        [ 0.5224],\n",
       "        [-0.1725],\n",
       "        [-0.1475],\n",
       "        [ 0.9927],\n",
       "        [ 0.3815],\n",
       "        [-0.0286],\n",
       "        [-0.1056],\n",
       "        [ 0.6055],\n",
       "        [ 0.3785],\n",
       "        [-0.2094],\n",
       "        [ 0.5667],\n",
       "        [-0.0464],\n",
       "        [ 0.2616],\n",
       "        [ 1.3046],\n",
       "        [ 1.2554],\n",
       "        [-0.4606],\n",
       "        [ 0.1830],\n",
       "        [ 0.9452],\n",
       "        [ 0.4079],\n",
       "        [ 0.8025],\n",
       "        [ 0.4092],\n",
       "        [ 1.4455],\n",
       "        [ 1.1001],\n",
       "        [ 0.9362],\n",
       "        [ 0.2136],\n",
       "        [-0.6965],\n",
       "        [-0.0938],\n",
       "        [ 1.0290],\n",
       "        [ 0.0404],\n",
       "        [ 1.3529],\n",
       "        [ 1.3371],\n",
       "        [ 0.3512],\n",
       "        [ 0.8047],\n",
       "        [ 0.0486],\n",
       "        [ 0.0241],\n",
       "        [ 1.5931],\n",
       "        [ 0.6984],\n",
       "        [-0.2485],\n",
       "        [-0.2914],\n",
       "        [ 0.5423],\n",
       "        [ 1.0238],\n",
       "        [ 0.5475],\n",
       "        [ 1.0321],\n",
       "        [ 0.4648],\n",
       "        [-0.1582],\n",
       "        [-0.0722],\n",
       "        [ 0.4307],\n",
       "        [ 1.0369],\n",
       "        [ 0.1722],\n",
       "        [-0.2752],\n",
       "        [-0.0793],\n",
       "        [ 1.2576],\n",
       "        [ 0.6740],\n",
       "        [ 0.8294],\n",
       "        [ 0.0820],\n",
       "        [-0.0822],\n",
       "        [ 0.5028],\n",
       "        [ 0.2367],\n",
       "        [ 1.6228],\n",
       "        [ 0.0409],\n",
       "        [ 0.1498],\n",
       "        [ 1.1949],\n",
       "        [ 1.0459],\n",
       "        [ 0.7639],\n",
       "        [ 1.5768],\n",
       "        [-0.0723],\n",
       "        [ 0.1624],\n",
       "        [ 0.2099],\n",
       "        [ 1.1423],\n",
       "        [ 0.2946],\n",
       "        [ 0.3460],\n",
       "        [ 0.4671],\n",
       "        [ 0.4673],\n",
       "        [ 1.3287],\n",
       "        [-0.2130],\n",
       "        [ 0.6542],\n",
       "        [ 0.3210],\n",
       "        [ 0.6990],\n",
       "        [-0.0527],\n",
       "        [ 0.8551],\n",
       "        [ 0.4041],\n",
       "        [ 0.5912],\n",
       "        [ 0.2828],\n",
       "        [ 0.6661],\n",
       "        [ 0.2288],\n",
       "        [ 1.1593],\n",
       "        [ 0.8451],\n",
       "        [ 1.0527],\n",
       "        [ 0.0106],\n",
       "        [-0.0699],\n",
       "        [ 1.1632],\n",
       "        [ 0.8011],\n",
       "        [ 0.5461],\n",
       "        [-0.0216],\n",
       "        [ 1.0896],\n",
       "        [-0.5243],\n",
       "        [-0.6820],\n",
       "        [ 0.0927],\n",
       "        [ 0.6411],\n",
       "        [-0.2293],\n",
       "        [ 1.5013],\n",
       "        [ 0.6313],\n",
       "        [-0.3291],\n",
       "        [-0.0135],\n",
       "        [ 0.5211],\n",
       "        [-0.6237],\n",
       "        [ 0.3214],\n",
       "        [ 0.4618],\n",
       "        [-0.4994],\n",
       "        [ 0.5219],\n",
       "        [ 1.3003],\n",
       "        [-0.0407],\n",
       "        [-0.1464],\n",
       "        [ 0.1510],\n",
       "        [ 0.3065],\n",
       "        [ 1.0633],\n",
       "        [-0.4126],\n",
       "        [ 1.0949],\n",
       "        [ 0.6377],\n",
       "        [ 0.2343],\n",
       "        [ 0.3797],\n",
       "        [ 0.3025],\n",
       "        [ 1.3266],\n",
       "        [ 0.2715],\n",
       "        [ 0.9926],\n",
       "        [-0.3781],\n",
       "        [ 0.4355],\n",
       "        [-0.1146],\n",
       "        [ 1.4583],\n",
       "        [ 1.8516],\n",
       "        [ 0.1616],\n",
       "        [ 0.4526],\n",
       "        [ 0.0297],\n",
       "        [ 0.3038],\n",
       "        [-0.3243],\n",
       "        [ 0.2828],\n",
       "        [ 1.1567],\n",
       "        [-0.1933],\n",
       "        [-0.0793],\n",
       "        [-0.2616],\n",
       "        [ 0.2038],\n",
       "        [-0.7284],\n",
       "        [ 0.9184],\n",
       "        [ 0.4043],\n",
       "        [-0.0280],\n",
       "        [ 1.0809],\n",
       "        [ 0.4314],\n",
       "        [ 0.5991],\n",
       "        [-0.2397],\n",
       "        [-0.2079],\n",
       "        [ 0.7103],\n",
       "        [ 1.2160],\n",
       "        [ 0.8367],\n",
       "        [ 0.8848],\n",
       "        [ 0.6200],\n",
       "        [-0.2914],\n",
       "        [-0.5912],\n",
       "        [ 0.3605],\n",
       "        [-0.0388],\n",
       "        [ 0.1742],\n",
       "        [ 0.0330],\n",
       "        [ 0.9789],\n",
       "        [ 0.7187],\n",
       "        [ 0.4144],\n",
       "        [ 0.2159],\n",
       "        [ 0.7259],\n",
       "        [ 1.0409],\n",
       "        [-0.0320],\n",
       "        [ 1.5530],\n",
       "        [ 0.6813],\n",
       "        [-0.3630],\n",
       "        [ 0.1653],\n",
       "        [ 1.0348],\n",
       "        [ 0.6725],\n",
       "        [ 0.2866],\n",
       "        [ 1.1883],\n",
       "        [ 1.0565],\n",
       "        [ 0.1831],\n",
       "        [ 0.3421],\n",
       "        [-0.8150],\n",
       "        [ 0.3670],\n",
       "        [ 0.3947],\n",
       "        [ 0.1050],\n",
       "        [ 0.1630],\n",
       "        [ 0.0494],\n",
       "        [ 1.0218],\n",
       "        [ 1.0422],\n",
       "        [ 0.0465],\n",
       "        [ 1.0949],\n",
       "        [ 0.6119],\n",
       "        [ 0.7314],\n",
       "        [ 1.1554],\n",
       "        [ 0.7502],\n",
       "        [ 0.4846],\n",
       "        [ 0.3499],\n",
       "        [ 0.6224],\n",
       "        [ 0.7021],\n",
       "        [ 0.7161],\n",
       "        [-0.1329],\n",
       "        [-0.4081],\n",
       "        [-0.4291],\n",
       "        [ 0.8156],\n",
       "        [-0.1373],\n",
       "        [-1.1404],\n",
       "        [ 0.9407],\n",
       "        [ 0.2006],\n",
       "        [-0.0341],\n",
       "        [ 1.0238],\n",
       "        [-0.8843],\n",
       "        [ 0.6052],\n",
       "        [ 0.7669],\n",
       "        [ 0.7398],\n",
       "        [ 1.1554],\n",
       "        [ 0.2986],\n",
       "        [ 0.4632],\n",
       "        [ 0.5899],\n",
       "        [ 0.6163],\n",
       "        [ 1.1984],\n",
       "        [-0.4932],\n",
       "        [-0.0135],\n",
       "        [ 0.7587],\n",
       "        [ 1.0434],\n",
       "        [ 1.2447],\n",
       "        [-0.3823],\n",
       "        [ 1.1686],\n",
       "        [ 0.3684],\n",
       "        [ 0.5882],\n",
       "        [ 0.0141],\n",
       "        [ 0.6514],\n",
       "        [ 0.3749],\n",
       "        [ 0.5826],\n",
       "        [ 0.0843],\n",
       "        [ 0.6160],\n",
       "        [ 0.5640],\n",
       "        [ 0.6108],\n",
       "        [ 0.2025],\n",
       "        [ 0.6659],\n",
       "        [ 0.6213],\n",
       "        [ 0.6859],\n",
       "        [ 1.3576],\n",
       "        [ 1.1248],\n",
       "        [ 1.2966],\n",
       "        [ 1.4533],\n",
       "        [ 0.4803],\n",
       "        [ 0.6471],\n",
       "        [ 1.4328],\n",
       "        [ 1.1795],\n",
       "        [ 0.5839],\n",
       "        [ 0.6984],\n",
       "        [ 0.3174],\n",
       "        [-0.0517],\n",
       "        [ 0.6200],\n",
       "        [ 0.0043],\n",
       "        [ 0.1761],\n",
       "        [-0.1092],\n",
       "        [ 0.7753],\n",
       "        [ 0.1438],\n",
       "        [ 1.0896],\n",
       "        [ 0.3605],\n",
       "        [ 0.5514],\n",
       "        [ 0.5160],\n",
       "        [ 1.0369],\n",
       "        [ 1.2120],\n",
       "        [-0.0439],\n",
       "        [-1.1719],\n",
       "        [ 0.8459],\n",
       "        [ 1.0409],\n",
       "        [ 0.2875],\n",
       "        [ 0.2423],\n",
       "        [ 0.5350],\n",
       "        [ 1.0422],\n",
       "        [ 1.0567],\n",
       "        [-0.6132],\n",
       "        [ 0.2343],\n",
       "        [ 0.0193],\n",
       "        [-0.4291],\n",
       "        [ 0.3253],\n",
       "        [ 0.2840],\n",
       "        [ 0.4735],\n",
       "        [ 0.9439],\n",
       "        [ 0.5056],\n",
       "        [ 0.9418],\n",
       "        [ 1.0211],\n",
       "        [ 0.3947],\n",
       "        [-0.4859],\n",
       "        [ 0.2602],\n",
       "        [ 0.3541],\n",
       "        [ 0.7696],\n",
       "        [ 0.6221],\n",
       "        [ 0.9579],\n",
       "        [-0.0893],\n",
       "        [-0.0754],\n",
       "        [ 1.0978],\n",
       "        [ 0.2194],\n",
       "        [ 0.9823],\n",
       "        [ 1.3055],\n",
       "        [ 1.1166],\n",
       "        [-0.8150],\n",
       "        [ 0.6155],\n",
       "        [ 0.5930],\n",
       "        [ 1.0415],\n",
       "        [ 0.4500],\n",
       "        [ 0.1531],\n",
       "        [ 0.3038],\n",
       "        [ 0.5432],\n",
       "        [ 0.1702],\n",
       "        [ 0.1946],\n",
       "        [-0.0551],\n",
       "        [-0.4429],\n",
       "        [ 0.2889],\n",
       "        [ 0.8708],\n",
       "        [ 0.0356],\n",
       "        [-0.1805],\n",
       "        [ 0.9505],\n",
       "        [ 0.5429],\n",
       "        [ 0.6313],\n",
       "        [ 0.1115],\n",
       "        [-0.2220],\n",
       "        [ 0.3025],\n",
       "        [ 0.9698],\n",
       "        [ 0.4074],\n",
       "        [ 0.1689],\n",
       "        [ 0.1751],\n",
       "        [ 0.3707],\n",
       "        [ 0.1243],\n",
       "        [ 0.4105],\n",
       "        [-0.2325],\n",
       "        [ 0.7793],\n",
       "        [ 0.9816],\n",
       "        [ 0.4829],\n",
       "        [ 0.2986],\n",
       "        [ 0.7209],\n",
       "        [ 0.4803],\n",
       "        [ 1.0422],\n",
       "        [ 0.0194],\n",
       "        [ 0.4412],\n",
       "        [ 0.0418],\n",
       "        [-0.0175],\n",
       "        [-0.1343],\n",
       "        [-0.0893],\n",
       "        [ 0.3213],\n",
       "        [ 0.0462],\n",
       "        [ 0.6149],\n",
       "        [ 0.4102],\n",
       "        [ 0.2818],\n",
       "        [ 0.5178],\n",
       "        [-0.0583],\n",
       "        [ 0.0166],\n",
       "        [ 1.9269],\n",
       "        [-0.3289],\n",
       "        [-0.3566]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = training_x.shape[1]\n",
    "print(num_features)\n",
    "\n",
    "linear_model = nn.Linear(num_features,1) # <1>\n",
    "linear_model(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2855, -0.3065,  0.1013, -0.2249, -0.3219]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.4293], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.7330e-01],\n",
       "        [ 1.6118e-01],\n",
       "        [-8.5777e-01],\n",
       "        [-4.3072e-01],\n",
       "        [-1.2204e+00],\n",
       "        [-2.8546e-02],\n",
       "        [-1.2032e+00],\n",
       "        [ 1.3089e-01],\n",
       "        [ 1.0220e-01],\n",
       "        [ 5.2089e-01],\n",
       "        [ 5.1196e-01],\n",
       "        [-4.5519e-01],\n",
       "        [-4.2530e-01],\n",
       "        [ 3.6526e-01],\n",
       "        [-5.0291e-01],\n",
       "        [-4.4112e-01],\n",
       "        [ 3.3657e-01],\n",
       "        [ 3.8045e-01],\n",
       "        [ 1.6032e-01],\n",
       "        [-4.4202e-01],\n",
       "        [-8.5014e-03],\n",
       "        [ 4.1208e-01],\n",
       "        [-4.3691e-01],\n",
       "        [-4.6475e-02],\n",
       "        [ 3.8719e-01],\n",
       "        [ 3.6231e-01],\n",
       "        [ 3.9647e-01],\n",
       "        [ 3.1019e-01],\n",
       "        [ 2.7411e-01],\n",
       "        [-8.1601e-01],\n",
       "        [-5.1846e-01],\n",
       "        [-3.6454e-01],\n",
       "        [ 6.5790e-01],\n",
       "        [ 9.7059e-01],\n",
       "        [-9.4200e-01],\n",
       "        [ 2.1663e-04],\n",
       "        [-4.3044e-01],\n",
       "        [-4.2608e-02],\n",
       "        [ 3.9310e-01],\n",
       "        [ 3.8157e-01],\n",
       "        [-1.3420e-01],\n",
       "        [-4.6812e-01],\n",
       "        [-1.2972e-01],\n",
       "        [-7.1786e-02],\n",
       "        [-8.8905e-01],\n",
       "        [-5.4847e-01],\n",
       "        [-9.1492e-01],\n",
       "        [-4.8190e-01],\n",
       "        [ 1.3415e-03],\n",
       "        [ 8.0830e-02],\n",
       "        [ 3.8418e-01],\n",
       "        [-4.0054e-01],\n",
       "        [-8.4188e-01],\n",
       "        [ 7.2778e-01],\n",
       "        [-3.4564e-01],\n",
       "        [-3.7347e-03],\n",
       "        [ 4.9140e-01],\n",
       "        [ 9.7517e-01],\n",
       "        [ 7.1632e-01],\n",
       "        [ 2.8061e-01],\n",
       "        [ 1.3029e+00],\n",
       "        [-4.4225e-01],\n",
       "        [-4.6404e-01],\n",
       "        [-4.8603e-01],\n",
       "        [-2.6882e-01],\n",
       "        [-9.0705e-01],\n",
       "        [-7.7410e-02],\n",
       "        [-4.4278e-01],\n",
       "        [-3.6800e-01],\n",
       "        [ 7.6912e-01],\n",
       "        [-1.4603e-01],\n",
       "        [ 1.1172e+00],\n",
       "        [ 5.9219e-01],\n",
       "        [ 3.3967e-01],\n",
       "        [ 2.9045e-01],\n",
       "        [-1.3264e+00],\n",
       "        [ 1.3700e-01],\n",
       "        [ 5.0493e-01],\n",
       "        [-8.7161e-01],\n",
       "        [ 1.1148e+00],\n",
       "        [-9.2850e-01],\n",
       "        [-5.5044e-01],\n",
       "        [-4.1413e-02],\n",
       "        [ 7.4332e-01],\n",
       "        [-4.5097e-01],\n",
       "        [ 3.4192e-01],\n",
       "        [ 8.1173e-01],\n",
       "        [-5.7284e-01],\n",
       "        [-4.2043e-01],\n",
       "        [ 3.7201e-01],\n",
       "        [ 7.3904e-01],\n",
       "        [-7.9343e-01],\n",
       "        [-5.8287e-02],\n",
       "        [-1.1763e+00],\n",
       "        [-1.0938e-01],\n",
       "        [ 5.3009e-02],\n",
       "        [ 6.1398e-01],\n",
       "        [-4.5904e-02],\n",
       "        [-6.5786e-01],\n",
       "        [-9.2006e-01],\n",
       "        [-6.7006e-01],\n",
       "        [-1.4694e+00],\n",
       "        [-1.3084e-01],\n",
       "        [ 9.6047e-01],\n",
       "        [ 8.2653e-03],\n",
       "        [ 3.6610e-01],\n",
       "        [-2.3771e-01],\n",
       "        [-4.4337e-01],\n",
       "        [-4.0836e-01],\n",
       "        [ 4.0786e-01],\n",
       "        [-5.3298e-03],\n",
       "        [-7.9596e-01],\n",
       "        [-4.2819e-01],\n",
       "        [ 1.3415e-03],\n",
       "        [-4.9737e-01],\n",
       "        [-4.9399e-01],\n",
       "        [ 3.7848e-01],\n",
       "        [-3.8027e-01],\n",
       "        [ 2.1125e-01],\n",
       "        [ 1.1345e-01],\n",
       "        [ 3.3047e-01],\n",
       "        [ 2.4887e-02],\n",
       "        [-3.8046e-01],\n",
       "        [-3.7129e-01],\n",
       "        [-4.4788e-02],\n",
       "        [-4.2706e-01],\n",
       "        [-4.8942e-01],\n",
       "        [-1.4940e-01],\n",
       "        [ 1.8340e-01],\n",
       "        [-1.8251e-01],\n",
       "        [ 8.5138e-01],\n",
       "        [-6.3528e-01],\n",
       "        [-4.2988e-01],\n",
       "        [ 4.1672e-01],\n",
       "        [-9.5322e-02],\n",
       "        [-7.9906e-01],\n",
       "        [-3.6839e-01],\n",
       "        [-7.2911e-02],\n",
       "        [ 2.7634e-01],\n",
       "        [ 7.1542e-01],\n",
       "        [-4.7816e-01],\n",
       "        [-3.6351e-02],\n",
       "        [-8.6655e-01],\n",
       "        [-5.5502e-01],\n",
       "        [ 5.5339e-01],\n",
       "        [-8.4799e-01],\n",
       "        [-4.6362e-01],\n",
       "        [-1.5236e-01],\n",
       "        [-2.6293e-01],\n",
       "        [-5.4518e-01],\n",
       "        [ 7.4838e-01],\n",
       "        [ 8.3924e-02],\n",
       "        [-1.1403e+00],\n",
       "        [-4.5237e-01],\n",
       "        [ 3.9057e-01],\n",
       "        [-6.3931e-02],\n",
       "        [ 3.5373e-01],\n",
       "        [-2.8758e-02],\n",
       "        [-3.8357e-01],\n",
       "        [-2.7943e-01],\n",
       "        [-6.8692e-02],\n",
       "        [-8.8455e-01],\n",
       "        [ 5.1583e-01],\n",
       "        [-5.9309e-01],\n",
       "        [ 5.8550e-01],\n",
       "        [-1.5259e-02],\n",
       "        [ 5.3402e-02],\n",
       "        [ 3.9310e-01],\n",
       "        [ 5.2286e-01],\n",
       "        [-8.6486e-01],\n",
       "        [-1.7657e-01],\n",
       "        [-1.0947e-01],\n",
       "        [-4.3325e-01],\n",
       "        [ 2.8716e-01],\n",
       "        [ 2.4908e-02],\n",
       "        [-1.3439e+00],\n",
       "        [ 2.9509e-03],\n",
       "        [ 3.3685e-01],\n",
       "        [ 3.9705e-01],\n",
       "        [-4.4112e-01],\n",
       "        [ 1.2758e-01],\n",
       "        [-8.4233e-03],\n",
       "        [ 5.4233e-01],\n",
       "        [-6.5880e-02],\n",
       "        [ 1.5468e+00],\n",
       "        [-8.0849e-01],\n",
       "        [-7.8676e-01],\n",
       "        [ 1.8891e-01],\n",
       "        [ 6.0695e-01],\n",
       "        [-9.2730e-01],\n",
       "        [-1.9169e-01],\n",
       "        [ 6.6429e-01],\n",
       "        [-8.8651e-02],\n",
       "        [ 2.6722e-01],\n",
       "        [-3.8093e-01],\n",
       "        [-4.8612e-01],\n",
       "        [ 7.4163e-01],\n",
       "        [-7.8472e-01],\n",
       "        [-2.2281e-02],\n",
       "        [ 3.8804e-01],\n",
       "        [-4.3550e-01],\n",
       "        [-3.4542e-01],\n",
       "        [-4.4225e-01],\n",
       "        [ 4.2591e-01],\n",
       "        [-1.1455e+00],\n",
       "        [-3.5056e-01],\n",
       "        [ 3.8888e-01],\n",
       "        [-4.9175e-01],\n",
       "        [ 2.9249e-01],\n",
       "        [-1.4097e-01],\n",
       "        [-1.4114e-01],\n",
       "        [-1.3593e+00],\n",
       "        [-5.7987e-01],\n",
       "        [-5.1987e-01],\n",
       "        [-3.2444e-01],\n",
       "        [-2.4531e-02],\n",
       "        [-9.1267e-01],\n",
       "        [ 1.2121e+00],\n",
       "        [-5.4904e-02],\n",
       "        [ 2.2982e-01],\n",
       "        [ 3.9310e-01],\n",
       "        [-8.9897e-01],\n",
       "        [ 2.0184e-01],\n",
       "        [ 6.2102e-01],\n",
       "        [ 3.2506e-01],\n",
       "        [ 4.0997e-01],\n",
       "        [ 7.6639e-01],\n",
       "        [-4.0456e-01],\n",
       "        [-1.0732e+00],\n",
       "        [ 1.5965e-02],\n",
       "        [-4.3927e-01],\n",
       "        [ 7.4381e-01],\n",
       "        [-2.8879e-01],\n",
       "        [-5.5315e-01],\n",
       "        [ 9.2792e-01],\n",
       "        [-1.2471e+00],\n",
       "        [-4.6812e-01],\n",
       "        [-4.6422e-03],\n",
       "        [-3.4982e-01],\n",
       "        [ 5.3270e-01],\n",
       "        [-3.7129e-01],\n",
       "        [ 1.2473e+00],\n",
       "        [ 9.7059e-01],\n",
       "        [ 1.2267e+00],\n",
       "        [ 4.1630e-01],\n",
       "        [ 7.2588e-01],\n",
       "        [-8.6101e-01],\n",
       "        [-8.2472e-02],\n",
       "        [ 3.6498e-01],\n",
       "        [ 1.3355e-01],\n",
       "        [-4.3174e-02],\n",
       "        [-4.3072e-01],\n",
       "        [ 1.6809e-02],\n",
       "        [-9.8362e-01],\n",
       "        [ 2.8542e-02],\n",
       "        [-2.4737e-01],\n",
       "        [ 8.0064e-01],\n",
       "        [-4.2943e-01],\n",
       "        [ 3.0986e-01],\n",
       "        [ 7.7474e-01],\n",
       "        [-4.6222e-01],\n",
       "        [-5.1607e-02],\n",
       "        [ 6.9382e-01],\n",
       "        [-4.4555e-01],\n",
       "        [ 1.9981e-02],\n",
       "        [ 3.7510e-01],\n",
       "        [ 3.6920e-01],\n",
       "        [ 4.3107e-01],\n",
       "        [-8.5080e-01],\n",
       "        [ 1.2079e+00],\n",
       "        [-1.3137e+00],\n",
       "        [-4.3100e-01],\n",
       "        [ 4.7900e-05],\n",
       "        [-4.4225e-01],\n",
       "        [ 3.2279e-01],\n",
       "        [-8.0814e-01],\n",
       "        [-4.5519e-01],\n",
       "        [ 2.9326e-01],\n",
       "        [ 1.7918e-01],\n",
       "        [ 3.7876e-01],\n",
       "        [-1.3992e+00],\n",
       "        [-4.8162e-01],\n",
       "        [-8.1910e-02],\n",
       "        [ 7.6131e-01],\n",
       "        [ 5.2716e-01],\n",
       "        [ 9.7517e-01],\n",
       "        [-1.0317e-01],\n",
       "        [ 3.9307e-02],\n",
       "        [ 4.7193e-01],\n",
       "        [-2.6859e-02],\n",
       "        [ 5.1927e-01],\n",
       "        [ 8.9080e-01],\n",
       "        [-4.2706e-01],\n",
       "        [ 7.6727e-02],\n",
       "        [-5.6954e-01],\n",
       "        [ 1.0263e-02],\n",
       "        [-8.6972e-02],\n",
       "        [-4.5519e-01],\n",
       "        [ 3.8973e-01],\n",
       "        [ 3.5457e-01],\n",
       "        [ 4.8060e-02],\n",
       "        [ 1.5106e-01],\n",
       "        [-3.5573e-01],\n",
       "        [ 1.1177e+00],\n",
       "        [ 6.0695e-01],\n",
       "        [ 2.9144e-01],\n",
       "        [-4.3125e-01],\n",
       "        [-6.3833e-01],\n",
       "        [-3.5189e-01],\n",
       "        [-4.5800e-01],\n",
       "        [ 3.7482e-01],\n",
       "        [ 3.2786e-01],\n",
       "        [ 6.9661e-03],\n",
       "        [-7.9104e-01],\n",
       "        [-8.9608e-01],\n",
       "        [-1.2199e+00],\n",
       "        [-1.7883e-01],\n",
       "        [-5.0404e-01],\n",
       "        [ 3.3303e-01],\n",
       "        [-5.9412e-02],\n",
       "        [ 1.0043e+00],\n",
       "        [-9.5823e-01],\n",
       "        [-6.1662e-02],\n",
       "        [ 5.1864e-01],\n",
       "        [-8.3326e-01],\n",
       "        [-1.6920e-01],\n",
       "        [ 1.7656e-01],\n",
       "        [-1.1264e+00],\n",
       "        [ 3.5092e-01],\n",
       "        [-7.9014e-01],\n",
       "        [-7.9387e-01],\n",
       "        [-6.3114e-01],\n",
       "        [-7.7664e-01],\n",
       "        [ 2.4887e-02],\n",
       "        [-1.1632e+00],\n",
       "        [ 2.1027e-02],\n",
       "        [ 5.3270e-01],\n",
       "        [ 8.3504e-01],\n",
       "        [ 5.6646e-01],\n",
       "        [ 7.5625e-01],\n",
       "        [-9.4565e-02],\n",
       "        [-2.0735e-02],\n",
       "        [-4.4112e-01],\n",
       "        [ 9.7059e-01],\n",
       "        [ 3.3573e-01],\n",
       "        [-3.9163e-02],\n",
       "        [-4.2988e-01],\n",
       "        [-9.1078e-01],\n",
       "        [ 8.5093e-01],\n",
       "        [-3.4731e-01],\n",
       "        [-6.6108e-03],\n",
       "        [-4.3072e-01],\n",
       "        [ 3.9209e-01],\n",
       "        [-2.1258e-01],\n",
       "        [ 4.4784e-01],\n",
       "        [-4.3100e-01],\n",
       "        [-4.3409e-01],\n",
       "        [-1.9394e-01],\n",
       "        [-1.1455e+00],\n",
       "        [ 8.3183e-01],\n",
       "        [ 9.7517e-01],\n",
       "        [-1.0563e+00],\n",
       "        [-5.0685e-02],\n",
       "        [ 7.3481e-01],\n",
       "        [-1.3056e-01],\n",
       "        [-2.6882e-01],\n",
       "        [-5.7364e-01],\n",
       "        [-4.2650e-01],\n",
       "        [ 3.6920e-01],\n",
       "        [-5.0326e-02],\n",
       "        [ 7.8037e-01],\n",
       "        [-1.1711e+00],\n",
       "        [-8.1629e-01],\n",
       "        [-7.8479e-01],\n",
       "        [-4.1300e-01],\n",
       "        [ 8.5503e-01],\n",
       "        [ 2.6089e-02],\n",
       "        [-1.0505e+00],\n",
       "        [ 3.4444e-01],\n",
       "        [-4.1820e-01],\n",
       "        [-4.8725e-01],\n",
       "        [ 4.4193e-02],\n",
       "        [ 1.9981e-02],\n",
       "        [-7.8339e-01],\n",
       "        [-7.7858e-01],\n",
       "        [-4.3086e-01],\n",
       "        [-9.1211e-01],\n",
       "        [ 4.2080e-01],\n",
       "        [-5.4904e-02],\n",
       "        [-1.1028e+00],\n",
       "        [ 4.1715e-01],\n",
       "        [-8.5755e-01],\n",
       "        [ 1.3388e+00],\n",
       "        [ 4.9130e-02],\n",
       "        [-1.6007e+00],\n",
       "        [-1.1495e-01],\n",
       "        [ 5.5451e-01],\n",
       "        [-5.6581e-01],\n",
       "        [-1.3197e-01],\n",
       "        [ 4.4615e-01],\n",
       "        [ 4.4825e-02],\n",
       "        [-1.2833e+00],\n",
       "        [-6.5995e-01],\n",
       "        [ 3.8888e-01],\n",
       "        [-4.1553e-01],\n",
       "        [-1.1825e+00],\n",
       "        [ 8.2517e-02],\n",
       "        [-1.4677e+00],\n",
       "        [ 2.0351e-01],\n",
       "        [ 5.3558e-01],\n",
       "        [ 3.6582e-01],\n",
       "        [ 1.0620e+00],\n",
       "        [-9.5409e-02],\n",
       "        [-4.1806e-01],\n",
       "        [ 3.5035e-01],\n",
       "        [ 3.8973e-01],\n",
       "        [-8.0589e-01],\n",
       "        [ 3.5092e-01],\n",
       "        [-4.3100e-01],\n",
       "        [ 5.8412e-03],\n",
       "        [ 1.2739e-01],\n",
       "        [-8.2493e-01],\n",
       "        [-4.7358e-02],\n",
       "        [ 1.1441e+00],\n",
       "        [ 8.5503e-01],\n",
       "        [-2.2945e-01],\n",
       "        [ 7.2307e-01],\n",
       "        [-1.1182e+00],\n",
       "        [ 3.6588e-01],\n",
       "        [-2.2101e-01],\n",
       "        [-4.3551e-01],\n",
       "        [ 1.7301e-01],\n",
       "        [-8.8060e-01],\n",
       "        [-1.0635e+00],\n",
       "        [ 3.5966e-01],\n",
       "        [ 1.3371e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) # <1>\n",
    "optimizer = optim.SGD(\n",
    "    linear_model.parameters(), # <2>\n",
    "    lr=1e-2)\n",
    "\n",
    "linear_model(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7ff24546dc80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0610,  0.2715, -0.1074,  0.3795, -0.3130]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0788], requires_grad=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(linear_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, \n",
    "                  train_x, val_x,\n",
    "                  train_y, val_y, \n",
    "                  epoch_report = 1000):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_p = model(train_x) # <1>\n",
    "        loss_train = loss_fn(train_p, train_y)\n",
    "\n",
    "        val_p = model(val_x) # <1>\n",
    "        loss_val = loss_fn(val_p, val_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % epoch_report == 0 or epoch == n_epochs:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Neural Network training with a single node\n",
    "nothign to grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.3292, Validation loss 1.4603\n",
      "Epoch 500, Training loss 0.9600, Validation loss 1.1625\n",
      "Epoch 1000, Training loss 0.9600, Validation loss 1.1625\n",
      "Epoch 1500, Training loss 0.9600, Validation loss 1.1625\n",
      "Epoch 2000, Training loss 0.9600, Validation loss 1.1625\n",
      "Epoch 2500, Training loss 0.9600, Validation loss 1.1625\n",
      "Epoch 3000, Training loss 0.9600, Validation loss 1.1625\n",
      "\n",
      "Weight Parameter containing:\n",
      "tensor([[ 5.2285e-12, -2.7448e-10, -2.5329e-12, -3.1897e-10, -3.1807e-10]],\n",
      "       requires_grad=True)\n",
      "Bias Parameter containing:\n",
      "tensor([-0.0221], requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) # <1>\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 3000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 500\n",
    "    )\n",
    "\n",
    "print()\n",
    "print(\"Weight\", linear_model.weight)\n",
    "print(\"Bias\", linear_model.bias)\n",
    "\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning Sequential layer models\n",
    "nothing here to be graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=22, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=22, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model_example = nn.Sequential(\n",
    "            nn.Linear(9, 22), # <1>\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(22, 3)) # <2>\n",
    "seq_model_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([22, 9]), torch.Size([22]), torch.Size([3, 22]), torch.Size([3])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.shape for param in seq_model_example.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([22, 9])\n",
      "0.bias torch.Size([22])\n",
      "2.weight torch.Size([3, 22])\n",
      "2.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model_example.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_linear): Linear(in_features=1, out_features=8, bias=True)\n",
       "  (hidden_activation): Tanh()\n",
       "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "seq_model_example = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(1, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 1))\n",
    "]))\n",
    "\n",
    "seq_model_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([8, 1])\n",
      "hidden_linear.bias torch.Size([8])\n",
      "output_linear.weight torch.Size([1, 8])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model_example.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2838], requires_grad=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model_example.output_linear.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper training with a sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### example of single layer\n",
    "for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.1196, Validation loss 1.3638\n",
      "Epoch 25, Training loss 1.1196, Validation loss 1.3638\n",
      "Epoch 50, Training loss 1.1196, Validation loss 1.3638\n",
      "Epoch 75, Training loss 1.1196, Validation loss 1.3638\n",
      "Epoch 100, Training loss 1.1196, Validation loss 1.3638\n",
      "Epoch 125, Training loss 1.1196, Validation loss 1.3638\n",
      "Epoch 150, Training loss 1.1196, Validation loss 1.3638\n",
      "Epoch 175, Training loss 1.1196, Validation loss 1.3638\n",
      "Epoch 200, Training loss 1.1196, Validation loss 1.3638\n",
      "\n",
      "Weight Parameter containing:\n",
      "tensor([[ 5.2285e-12, -2.7448e-10, -2.5329e-12, -3.1897e-10, -3.1807e-10]],\n",
      "       requires_grad=True)\n",
      "Bias Parameter containing:\n",
      "tensor([-0.0221], requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/terminator0117/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([436])) that is different to the input size (torch.Size([436, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/terminator0117/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "linear_model_0 = nn.Linear(5, 1)\n",
    "linear_model_0.zero_grad()\n",
    "\n",
    "optimizer_0 = optim.SGD(linear_model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_0 = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer_0,\n",
    "    model = linear_model_0,\n",
    "    loss_fn = loss_0, \n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y,  \n",
    "    epoch_report = 25)\n",
    "\n",
    "print()\n",
    "print(\"Weight\", linear_model.weight)\n",
    "print(\"Bias\", linear_model.bias)\n",
    "\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a\n",
    "1 hidden layer with 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0410, Validation loss 1.2467\n",
      "Epoch 25, Training loss 1.0370, Validation loss 1.2431\n",
      "Epoch 50, Training loss 1.0332, Validation loss 1.2397\n",
      "Epoch 75, Training loss 1.0297, Validation loss 1.2364\n",
      "Epoch 100, Training loss 1.0264, Validation loss 1.2334\n",
      "Epoch 125, Training loss 1.0234, Validation loss 1.2306\n",
      "Epoch 150, Training loss 1.0206, Validation loss 1.2280\n",
      "Epoch 175, Training loss 1.0181, Validation loss 1.2255\n",
      "Epoch 200, Training loss 1.0157, Validation loss 1.2232\n"
     ]
    }
   ],
   "source": [
    "seq_model_1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(5, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 1))\n",
    "]))\n",
    "seq_model_1.zero_grad()\n",
    "\n",
    "optimizer_1 = optim.SGD(seq_model_1.parameters(), lr=1e-3)\n",
    "optimizer_1.zero_grad()\n",
    "\n",
    "loss_1 = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer_1,\n",
    "    model = seq_model_1,\n",
    "    loss_fn = loss_1,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('Hidden Weight', seq_model_1.hidden_linear.weight)\n",
    "# print('Hidden Bias', seq_model_1.hidden_linear.bias)\n",
    "# print()\n",
    "# print(\"Output Weight\", seq_model_1.output_linear.weight)\n",
    "# print(\"Output Bias\", seq_model_1.output_linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('output', seq_model_1(validation_x))\n",
    "# print('answer', validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b\n",
    "add 2 more hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0456, Validation loss 1.1854\n",
      "Epoch 25, Training loss 1.0272, Validation loss 1.1744\n",
      "Epoch 50, Training loss 1.0124, Validation loss 1.1663\n",
      "Epoch 75, Training loss 1.0010, Validation loss 1.1608\n",
      "Epoch 100, Training loss 0.9923, Validation loss 1.1571\n",
      "Epoch 125, Training loss 0.9855, Validation loss 1.1548\n",
      "Epoch 150, Training loss 0.9803, Validation loss 1.1534\n",
      "Epoch 175, Training loss 0.9763, Validation loss 1.1528\n",
      "Epoch 200, Training loss 0.9732, Validation loss 1.1526\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "\n",
    "seq_model_2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "seq_model_2.zero_grad()\n",
    "\n",
    "optimizer_2 = optim.SGD(seq_model_2.parameters(), lr=1e-3)\n",
    "optimizer_2.zero_grad()\n",
    "\n",
    "loss_2 = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer_2,\n",
    "    model = seq_model_2,\n",
    "    loss_fn = loss_2,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=5, out_features=1, bias=True)\n",
      "\n",
      "     Validation Loss: 1.3637760877609253\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear): Linear(in_features=5, out_features=8, bias=True)\n",
      "  (hidden_activation): Tanh()\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 1.2231050729751587\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation): Tanh()\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 1.1526341438293457\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [linear_model_0, seq_model_1, seq_model_2]\n",
    "for model in models:\n",
    "    print(f'{model}\\n')\n",
    "        \n",
    "    predictions = model(validation_x) \n",
    "    loss = loss_fn(predictions, validation_y)\n",
    "    print(f'     Validation Loss: {loss}\\n')\n",
    "        \n",
    "    for name, param in seq_model_2.named_parameters():\n",
    "        print(f'     {name}  \\t: ', param.shape)\n",
    "        \n",
    "    print('\\n' + '-'*90 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# x_sample = torch.arange(0, 5, 0.1).unsqueeze(1)\n",
    "# h = scaler.inverse_transform(x_sample)\n",
    "# print(h)\n",
    "# # Split x and y scaler?\n",
    "# # how to show output?\n",
    "\n",
    "# fig = plt.figure(dpi=600)\n",
    "# plt.xlabel(\"Fahrenheit\")\n",
    "# plt.ylabel(\"Celsius\")\n",
    "# # plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n",
    "# plt.plot(t_range.numpy(), seq_model(scaler.fit(t_range)).detach().numpy(), 'c-')\n",
    "# # plt.plot(t_u.numpy(), seq_model(0.1 * t_u).detach().numpy(), 'kx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exercises here!\n",
    "\n",
    "# neuron_count = 20\n",
    "\n",
    "# seq_model = nn.Sequential(OrderedDict([\n",
    "#     ('hidden_linear', nn.Linear(1, neuron_count)),\n",
    "#     ('hidden_activation', nn.Tanh()),\n",
    "#     ('output_linear', nn.Linear(neuron_count, 1))\n",
    "# ]))\n",
    "\n",
    "# optimizer = optim.SGD(seq_model.parameters(), lr=1e-4)\n",
    "\n",
    "# training_loop(\n",
    "#     n_epochs = 5000, \n",
    "#     optimizer = optimizer,\n",
    "#     model = seq_model,\n",
    "#     loss_fn = nn.MSELoss(),\n",
    "#     t_u_train = t_un_train,\n",
    "#     t_u_val = t_un_val, \n",
    "#     t_c_train = t_c_train,\n",
    "#     t_c_val = t_c_val)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# t_range = torch.arange(20., 90.).unsqueeze(1)\n",
    "\n",
    "# fig = plt.figure(dpi=150)\n",
    "# plt.xlabel(\"Fahrenheit\")\n",
    "# plt.ylabel(\"Celsius\")\n",
    "# plt.plot(t_u.numpy(), t_c.numpy(), 'o')\n",
    "# plt.plot(t_range.numpy(), seq_model(0.1 * t_range).detach().numpy(), 'c-')\n",
    "# plt.plot(t_u.numpy(), seq_model(0.1 * t_u).detach().numpy(), 'kx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77aa5c7a8032890130e9a412da4828609b1dfa25c62620094c03af7a5cea44b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
