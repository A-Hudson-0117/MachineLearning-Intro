{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5 Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## define model and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature, w5, w4, w3, w2, w1, b):\n",
    "    return feature[4] * w5 + feature[3] * w4 + feature[2] * w3 + feature[1] * w2 + feature[0] * w1 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(predicted, actual):\n",
    "    squared_diffs = (predicted - actual)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.01, 0.001, 0.0001, 1e-05]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_to_learn_at = [1/x for x in [10, 100, 1000, 10000, 100000]]\n",
    "rates_to_learn_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_for_validation = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(pd.read_csv('Housing.csv'))\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = (545, 13)\n",
      "features are: ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape = {np.shape(housing_df)}\")\n",
    "\n",
    "# creates a list of all variables from the column names\n",
    "feature_list = list( housing_df.columns )\n",
    "\n",
    "print(f\"features are: {feature_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary vars = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
      "furnish vars = ['furnishingstatus']\n",
      "value vars = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n"
     ]
    }
   ],
   "source": [
    "# Maps to turn categorys into numbers \n",
    "def boolean_map(x):\n",
    "    return x.map({'yes': 1 , 'no': 0})\n",
    "def furnish_map(x):\n",
    "    return x.map({'furnished': 1 , 'semi-furnished': 0.5 , 'unfurnished': 0})\n",
    "\n",
    "# Extracts the yes and no column names\n",
    "binary_vars = [*feature_list[5:10], feature_list[11]]\n",
    "print(f\"binary vars = {binary_vars}\")\n",
    "\n",
    "# Extracts the furnishing column names\n",
    "furnish_vars = [feature_list[12]]\n",
    "print(f\"furnish vars = {furnish_vars}\")\n",
    "\n",
    "# Extracts the column names that are actual values\n",
    "valued_vars = feature_list.copy()\n",
    "[valued_vars.remove( item ) for item in binary_vars]\n",
    "[valued_vars.remove( item ) for item in furnish_vars]\n",
    "print(f\"value vars = {valued_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = housing_df.copy()\n",
    "\n",
    "## scale data\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "x_df[valued_vars] = scaler.fit_transform(x_df[valued_vars])\n",
    "\n",
    "## map text values\n",
    "x_df[binary_vars] = x_df[binary_vars].apply(boolean_map)\n",
    "x_df[furnish_vars] = x_df[furnish_vars].apply(furnish_map)\n",
    "\n",
    "## make y_df\n",
    "y_df = x_df.pop('price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_values = valued_vars.copy()\n",
    "# input_values.remove('price')\n",
    "\n",
    "\n",
    "# x_df = x_df[input_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories  mainroad  guestroom  basement  \\\n",
       "0  1.046726  1.403419   1.421812  1.378217         1          0         0   \n",
       "1  1.757010  1.403419   5.405809  2.532024         1          0         0   \n",
       "2  2.218232  0.047278   1.421812  0.224410         1          0         1   \n",
       "3  1.083624  1.403419   1.421812  0.224410         1          0         1   \n",
       "4  1.046726  1.403419  -0.570187  0.224410         1          1         1   \n",
       "\n",
       "   hotwaterheating  airconditioning   parking  prefarea  furnishingstatus  \n",
       "0                0                1  1.517692         1               1.0  \n",
       "1                0                1  2.679409         0               1.0  \n",
       "2                0                0  1.517692         1               0.5  \n",
       "3                0                1  2.679409         1               1.0  \n",
       "4                0                1  1.517692         0               1.0  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.566365\n",
       "1    4.004484\n",
       "2    4.004484\n",
       "3    3.985755\n",
       "4    3.554979\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories   parking\n",
       "0  1.046726  1.403419   1.421812  1.378217  1.517692\n",
       "1  1.757010  1.403419   5.405809  2.532024  2.679409\n",
       "2  2.218232  0.047278   1.421812  0.224410  1.517692\n",
       "3  1.083624  1.403419   1.421812  0.224410  2.679409\n",
       "4  1.046726  1.403419  -0.570187  0.224410  1.517692"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted data\n",
    "for item in [*binary_vars, *furnish_vars] :\n",
    "    x_df.pop(item)\n",
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frame to tensor\n",
    "\n",
    "x = torch.tensor(x_df.values, dtype=torch.float32)\n",
    "y = torch.tensor(y_df.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([545, 5])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split into train and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set randomization keys\n",
    "Set so that it should reproduce the same results every time. \n",
    "Remove to test that network is learning regardless of the randomization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d1cc39bbf0>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 404\n",
    "\n",
    "torch.manual_seed(seed) ;\n",
    "gen = torch.Generator() ;\n",
    "gen.manual_seed(seed)   ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([223, 445, 209,  81,  86, 428,   0, 408, 206, 304, 127, 265,  30,\n",
       "         197, 303, 266, 339, 314, 337, 479, 352,  99, 450,  28, 370,  44,\n",
       "         477, 496, 488, 536,  82, 213, 379, 259,  12, 156,  35,  83, 291,\n",
       "         145, 192, 331, 514, 505, 153, 112, 173, 215, 393, 451, 297, 309,\n",
       "          41, 234, 378,  20, 122, 130, 201,  65,  96, 538,  19, 374,  84,\n",
       "         262, 124, 459, 363, 543, 399, 498, 381,  63, 106, 464, 328, 473,\n",
       "         185, 183, 162, 400,  49, 191, 409, 281, 268, 380, 336,  40, 544,\n",
       "         274, 275, 386,   7, 480, 119,  43,   6, 499, 415, 492, 426, 460,\n",
       "         184, 143, 397, 372,  27,  22,  50, 342, 487, 518,  57,  16,  56,\n",
       "         189, 155, 190,  32, 347, 177,  87,  18, 230,   3, 200,  70,  89,\n",
       "         420, 102,   9, 362, 141,  61, 247, 506,  15,  39, 243, 465, 248,\n",
       "         435, 252, 148, 182, 329, 466, 535, 402, 338, 241, 489, 302, 471,\n",
       "          25, 534, 472, 260, 319, 233, 101, 164, 404, 292, 167, 240, 434,\n",
       "          10,  52, 298, 436, 194,  62, 413, 318, 446, 308, 229, 277, 170,\n",
       "         113, 344, 422, 159, 299, 463, 531, 276, 392, 120, 495, 294,  76,\n",
       "         373, 305, 528, 493, 114, 335, 384, 388, 353, 483, 389, 485,  33,\n",
       "         325,  66, 161,  79, 439, 521, 267, 540, 396, 364, 481, 121, 462,\n",
       "         288,  42, 395, 175, 322, 320, 129, 217, 207, 416, 212,  38, 283,\n",
       "         165, 444, 250, 429, 511, 249, 414, 295, 382, 263, 199, 411,  45,\n",
       "         126, 287, 269, 366, 458, 210,  85, 208,  54, 160, 147, 326, 354,\n",
       "         360, 172, 151, 457, 361, 520,  23, 255, 419, 532, 375, 365, 282,\n",
       "         394, 198, 527, 236, 387, 449,   2,  21, 246, 501, 104,  55,  72,\n",
       "         149, 214, 452, 500, 474, 358, 503, 296, 123,  77, 519,  67,  94,\n",
       "         150,  48, 398, 349, 475, 327, 486, 116, 369, 316,  98, 401, 310,\n",
       "         115, 431, 136, 179, 166, 293, 220, 412,  13, 169, 453,  69, 542,\n",
       "         228, 321,  37, 333,   8,   4, 507, 313, 430, 484, 526, 125, 391,\n",
       "          88, 110, 134, 512, 238, 163, 509, 261,  51, 348, 195, 132, 118,\n",
       "         315, 478,  95, 330, 470, 418, 100, 340, 433, 440, 279,  26,   5,\n",
       "         138, 226,   1, 154, 476, 258, 332, 257, 517, 202, 253, 270, 356,\n",
       "          73, 139, 524,  36, 383, 539, 117, 516, 350, 334, 494, 359, 264,\n",
       "         508, 447, 224, 406, 523, 403, 357, 239, 461, 442, 286, 227, 390,\n",
       "         168, 205, 237, 231, 289, 455,  24, 225, 530, 306, 443, 256, 367,\n",
       "         142, 171,  60, 280, 467, 196, 438, 423, 135, 368, 178, 469, 222,\n",
       "          58, 251, 140, 490, 301, 504, 522]),\n",
       " tensor([ 74, 273, 174, 468,  71, 323, 482, 235, 221, 345, 219, 537, 108,\n",
       "         242, 312, 158, 513, 271, 128, 133, 157, 176, 421, 424,  64, 456,\n",
       "         410, 341, 146, 188, 144, 355, 417, 254, 181, 324, 515, 186, 245,\n",
       "         502, 285, 432, 105, 103, 203, 211, 525,  31, 497, 272, 377, 541,\n",
       "          97, 290, 152, 216,  93, 307, 109,  78, 529, 111,  34, 204, 510,\n",
       "         491, 137,  68,  91, 107, 343,  11, 441,  17, 371,  75, 180,  14,\n",
       "          46,  59, 232,  47,  92, 131, 405, 407, 346,  80,  29, 187, 244,\n",
       "          53, 448, 311,  90, 317, 437, 284, 376, 278, 427, 533, 454, 218,\n",
       "         385, 351, 193, 425, 300]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = x.shape[0]\n",
    "n_val = int(percent_for_validation * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples, generator=gen)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, val_indices  # <1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = x[train_indices]\n",
    "training_y  = y [train_indices]\n",
    "\n",
    "validation_x = x[val_indices]\n",
    "validation_y  = y[val_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([436, 5])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Learning how to use neural network component\n",
    "nothing to grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5357e-01],\n",
       "        [ 3.5349e-01],\n",
       "        [-6.4986e-01],\n",
       "        [ 6.1788e-01],\n",
       "        [-2.4617e-02],\n",
       "        [ 1.1321e-01],\n",
       "        [ 3.5952e-01],\n",
       "        [-2.2506e-02],\n",
       "        [-2.3100e-01],\n",
       "        [-4.0603e-01],\n",
       "        [ 4.9768e-01],\n",
       "        [ 1.0465e-01],\n",
       "        [ 9.7517e-01],\n",
       "        [ 7.5688e-01],\n",
       "        [-3.9271e-01],\n",
       "        [-1.5603e-01],\n",
       "        [ 2.6022e-01],\n",
       "        [ 4.2293e-01],\n",
       "        [ 7.0381e-02],\n",
       "        [-2.9799e-01],\n",
       "        [ 4.6221e-02],\n",
       "        [-2.5930e-01],\n",
       "        [ 3.8631e-02],\n",
       "        [-3.2389e-01],\n",
       "        [ 2.2576e-01],\n",
       "        [ 6.9338e-01],\n",
       "        [-1.3370e-01],\n",
       "        [-2.2506e-02],\n",
       "        [-1.6664e-01],\n",
       "        [-5.8248e-01],\n",
       "        [-4.4474e-01],\n",
       "        [-2.5973e-01],\n",
       "        [ 1.4941e-03],\n",
       "        [-1.5552e-01],\n",
       "        [ 1.0222e-02],\n",
       "        [-6.7070e-01],\n",
       "        [ 1.0302e+00],\n",
       "        [ 8.6532e-01],\n",
       "        [ 9.6198e-02],\n",
       "        [ 4.7854e-01],\n",
       "        [-6.3596e-01],\n",
       "        [ 2.1125e-01],\n",
       "        [ 9.0754e-02],\n",
       "        [-2.5075e-02],\n",
       "        [ 1.0612e+00],\n",
       "        [-4.9410e-01],\n",
       "        [-2.9506e-01],\n",
       "        [ 2.6612e-01],\n",
       "        [-7.3140e-01],\n",
       "        [-3.4104e-01],\n",
       "        [ 5.1923e-01],\n",
       "        [-4.1057e-01],\n",
       "        [ 8.2362e-01],\n",
       "        [ 7.7213e-01],\n",
       "        [ 4.8445e-01],\n",
       "        [ 2.1855e-01],\n",
       "        [-2.6522e-01],\n",
       "        [-4.2746e-01],\n",
       "        [-3.6079e-02],\n",
       "        [ 5.2632e-02],\n",
       "        [-7.7360e-01],\n",
       "        [ 1.8151e-02],\n",
       "        [ 3.3757e-01],\n",
       "        [ 5.3570e-01],\n",
       "        [ 2.8342e-01],\n",
       "        [ 6.4517e-03],\n",
       "        [ 9.4486e-01],\n",
       "        [ 3.5409e-02],\n",
       "        [ 2.5679e-02],\n",
       "        [-2.0854e-01],\n",
       "        [-2.7019e-01],\n",
       "        [ 5.1888e-01],\n",
       "        [-2.2506e-02],\n",
       "        [ 4.8230e-01],\n",
       "        [-3.1244e-01],\n",
       "        [ 3.6965e-01],\n",
       "        [ 4.1962e-01],\n",
       "        [-4.9162e-01],\n",
       "        [ 9.0754e-02],\n",
       "        [-6.5545e-01],\n",
       "        [-1.3592e-01],\n",
       "        [ 1.7437e-01],\n",
       "        [-2.3064e-01],\n",
       "        [-8.0113e-01],\n",
       "        [ 3.5259e-01],\n",
       "        [ 2.0027e-01],\n",
       "        [-4.4741e-01],\n",
       "        [-8.0420e-02],\n",
       "        [-5.2669e-01],\n",
       "        [-3.2044e-01],\n",
       "        [-7.7011e-03],\n",
       "        [-6.2115e-01],\n",
       "        [-2.6212e-02],\n",
       "        [-3.6730e-02],\n",
       "        [-1.0576e+00],\n",
       "        [ 1.7550e-01],\n",
       "        [-4.0391e-01],\n",
       "        [ 8.3372e-01],\n",
       "        [ 1.0375e+00],\n",
       "        [ 1.0230e+00],\n",
       "        [ 2.4346e-02],\n",
       "        [ 2.7164e-01],\n",
       "        [-1.8422e-01],\n",
       "        [-3.5706e-01],\n",
       "        [ 5.9336e-01],\n",
       "        [ 7.0007e-02],\n",
       "        [-1.0223e-01],\n",
       "        [ 6.9905e-02],\n",
       "        [-7.5912e-01],\n",
       "        [-6.6356e-01],\n",
       "        [ 8.3887e-01],\n",
       "        [-3.9017e-01],\n",
       "        [-4.9953e-01],\n",
       "        [ 3.5409e-02],\n",
       "        [ 3.4589e-01],\n",
       "        [ 4.4305e-03],\n",
       "        [-1.0588e+00],\n",
       "        [ 3.0776e-02],\n",
       "        [ 2.0526e-01],\n",
       "        [-4.7366e-01],\n",
       "        [ 2.0366e-01],\n",
       "        [ 5.0214e-02],\n",
       "        [-5.7225e-01],\n",
       "        [-4.9471e-02],\n",
       "        [ 6.8873e-01],\n",
       "        [ 1.2506e-01],\n",
       "        [ 1.8088e-01],\n",
       "        [-8.5307e-02],\n",
       "        [ 4.7753e-01],\n",
       "        [ 1.0575e-01],\n",
       "        [ 2.7332e-01],\n",
       "        [ 1.0636e+00],\n",
       "        [ 1.0346e+00],\n",
       "        [-2.8297e-02],\n",
       "        [-2.5192e-03],\n",
       "        [-4.4741e-01],\n",
       "        [ 1.9347e-01],\n",
       "        [ 1.0375e-01],\n",
       "        [-2.8833e-01],\n",
       "        [ 6.9338e-01],\n",
       "        [ 1.4288e-01],\n",
       "        [ 6.6024e-04],\n",
       "        [ 4.6852e-01],\n",
       "        [-2.7139e-02],\n",
       "        [-1.0136e+00],\n",
       "        [ 1.1290e-02],\n",
       "        [ 4.3264e-02],\n",
       "        [-2.0442e-02],\n",
       "        [ 8.0329e-02],\n",
       "        [ 1.9197e-01],\n",
       "        [-2.4027e-01],\n",
       "        [ 3.1270e-01],\n",
       "        [-2.6305e-02],\n",
       "        [ 1.9635e-01],\n",
       "        [ 6.3986e-01],\n",
       "        [ 3.8819e-03],\n",
       "        [ 1.5173e-01],\n",
       "        [-2.2154e-01],\n",
       "        [ 1.2653e-01],\n",
       "        [ 2.1234e-01],\n",
       "        [ 3.6888e-01],\n",
       "        [-3.5333e-01],\n",
       "        [ 2.5125e-01],\n",
       "        [ 3.0398e-01],\n",
       "        [-1.2932e-01],\n",
       "        [ 3.1037e-01],\n",
       "        [ 6.9130e-01],\n",
       "        [ 1.3380e-01],\n",
       "        [-3.1328e-01],\n",
       "        [-8.1001e-01],\n",
       "        [ 6.9338e-01],\n",
       "        [-2.6260e-01],\n",
       "        [ 1.8979e-01],\n",
       "        [-3.1288e-01],\n",
       "        [ 4.6129e-02],\n",
       "        [ 7.1498e-01],\n",
       "        [-3.7418e-01],\n",
       "        [ 6.2207e-01],\n",
       "        [ 1.0994e-01],\n",
       "        [-3.5082e-01],\n",
       "        [-6.1883e-01],\n",
       "        [-5.9345e-03],\n",
       "        [-7.0507e-01],\n",
       "        [-5.1312e-03],\n",
       "        [ 9.9266e-03],\n",
       "        [ 2.6627e-01],\n",
       "        [-2.6125e-01],\n",
       "        [ 8.2899e-02],\n",
       "        [-4.8538e-01],\n",
       "        [ 7.1510e-02],\n",
       "        [-2.3917e-02],\n",
       "        [-3.4831e-01],\n",
       "        [ 1.1527e-01],\n",
       "        [ 1.6524e-01],\n",
       "        [ 5.0695e-01],\n",
       "        [ 4.0305e-01],\n",
       "        [ 1.7898e-01],\n",
       "        [ 2.9326e-01],\n",
       "        [-3.3017e-01],\n",
       "        [-6.6134e-02],\n",
       "        [ 2.7950e-01],\n",
       "        [-8.0420e-02],\n",
       "        [ 1.5465e-02],\n",
       "        [ 4.1716e-01],\n",
       "        [-3.2797e-01],\n",
       "        [-4.0687e-01],\n",
       "        [ 2.0351e-02],\n",
       "        [ 8.9346e-01],\n",
       "        [-2.7482e-01],\n",
       "        [-9.4779e-01],\n",
       "        [ 4.1406e-02],\n",
       "        [ 5.5560e-01],\n",
       "        [-1.4398e-02],\n",
       "        [ 1.9772e-02],\n",
       "        [ 8.7087e-03],\n",
       "        [ 3.7402e-01],\n",
       "        [ 1.5954e-01],\n",
       "        [ 7.6855e-02],\n",
       "        [ 1.2807e-01],\n",
       "        [-3.9932e-01],\n",
       "        [ 1.8805e-01],\n",
       "        [-1.4554e-01],\n",
       "        [ 1.0904e+00],\n",
       "        [-7.7528e-01],\n",
       "        [-2.2588e-01],\n",
       "        [ 3.7071e-01],\n",
       "        [ 2.1855e-01],\n",
       "        [-2.9875e-01],\n",
       "        [-7.5885e-02],\n",
       "        [ 9.0754e-02],\n",
       "        [ 9.6022e-03],\n",
       "        [ 5.1312e-01],\n",
       "        [ 6.4341e-01],\n",
       "        [-3.7907e-01],\n",
       "        [-1.1597e-01],\n",
       "        [ 7.6855e-02],\n",
       "        [ 3.4140e-01],\n",
       "        [-4.2714e-01],\n",
       "        [-2.3982e-01],\n",
       "        [ 5.0569e-02],\n",
       "        [-2.7139e-02],\n",
       "        [ 1.6894e-01],\n",
       "        [ 7.3380e-02],\n",
       "        [-2.1369e-02],\n",
       "        [ 9.2106e-02],\n",
       "        [ 4.9951e-01],\n",
       "        [ 5.5560e-01],\n",
       "        [-4.2013e-01],\n",
       "        [-1.9882e-01],\n",
       "        [-1.3493e-02],\n",
       "        [ 2.0351e-02],\n",
       "        [-7.7011e-03],\n",
       "        [ 1.8079e-01],\n",
       "        [ 2.9498e-01],\n",
       "        [ 4.0395e-01],\n",
       "        [ 3.8622e-01],\n",
       "        [ 2.6095e-02],\n",
       "        [ 4.4414e-01],\n",
       "        [-6.5868e-01],\n",
       "        [-3.9181e-01],\n",
       "        [-2.7139e-02],\n",
       "        [-2.5403e-01],\n",
       "        [-1.0301e-01],\n",
       "        [-2.1897e-01],\n",
       "        [-5.6877e-01],\n",
       "        [-4.5108e-01],\n",
       "        [ 5.5302e-01],\n",
       "        [-1.0050e-01],\n",
       "        [-1.3884e-01],\n",
       "        [ 9.3324e-02],\n",
       "        [-2.5210e-01],\n",
       "        [-1.9046e-01],\n",
       "        [ 1.8631e-01],\n",
       "        [-2.7457e-01],\n",
       "        [-2.5071e-01],\n",
       "        [ 2.2815e-01],\n",
       "        [ 4.1811e-01],\n",
       "        [-5.2875e-02],\n",
       "        [ 2.4712e-01],\n",
       "        [ 6.7884e-02],\n",
       "        [ 8.3062e-02],\n",
       "        [-2.7920e-01],\n",
       "        [-1.5295e-01],\n",
       "        [ 2.7476e-01],\n",
       "        [-1.1639e-01],\n",
       "        [ 4.7623e-01],\n",
       "        [-4.4564e-01],\n",
       "        [-6.3046e-02],\n",
       "        [-3.2353e-01],\n",
       "        [-1.9580e-01],\n",
       "        [-2.3779e-01],\n",
       "        [ 3.7726e-02],\n",
       "        [-3.3480e-01],\n",
       "        [ 5.4838e-01],\n",
       "        [-2.1931e-01],\n",
       "        [ 4.9768e-01],\n",
       "        [ 1.8992e-01],\n",
       "        [ 1.9935e-02],\n",
       "        [ 6.9338e-01],\n",
       "        [-1.5666e-01],\n",
       "        [ 5.8313e-01],\n",
       "        [ 2.1720e-01],\n",
       "        [-1.2006e-01],\n",
       "        [ 4.0305e-01],\n",
       "        [-1.7199e-01],\n",
       "        [-2.5416e-01],\n",
       "        [-1.6810e-01],\n",
       "        [ 2.3826e-02],\n",
       "        [ 8.5511e-02],\n",
       "        [ 4.8610e-01],\n",
       "        [-2.4110e-01],\n",
       "        [-5.6472e-01],\n",
       "        [-5.1742e-01],\n",
       "        [-2.4239e-01],\n",
       "        [ 2.8377e-01],\n",
       "        [ 8.5321e-01],\n",
       "        [-4.9426e-01],\n",
       "        [ 7.0352e-02],\n",
       "        [ 8.7871e-02],\n",
       "        [ 1.3593e-01],\n",
       "        [ 5.0385e-01],\n",
       "        [-1.2897e-01],\n",
       "        [ 2.2568e-01],\n",
       "        [-4.9113e-01],\n",
       "        [ 2.1510e-02],\n",
       "        [ 2.9848e-01],\n",
       "        [ 8.0109e-01],\n",
       "        [ 4.8623e-01],\n",
       "        [ 9.0754e-02],\n",
       "        [-5.3158e-01],\n",
       "        [-4.5281e-01],\n",
       "        [ 2.3826e-02],\n",
       "        [ 5.1460e-01],\n",
       "        [ 1.5124e-01],\n",
       "        [ 8.8691e-02],\n",
       "        [ 7.2475e-02],\n",
       "        [-1.3977e+00],\n",
       "        [ 8.6584e-02],\n",
       "        [-4.4908e-01],\n",
       "        [-3.5526e-01],\n",
       "        [-4.0159e-01],\n",
       "        [ 4.0305e-01],\n",
       "        [ 1.0617e-01],\n",
       "        [-6.6202e-01],\n",
       "        [ 9.7651e-01],\n",
       "        [ 3.1681e-02],\n",
       "        [ 4.6541e-01],\n",
       "        [ 5.7856e-01],\n",
       "        [ 9.0105e-01],\n",
       "        [ 1.4565e-01],\n",
       "        [-6.1511e-01],\n",
       "        [-2.0783e-01],\n",
       "        [ 1.6160e-01],\n",
       "        [ 1.0564e+00],\n",
       "        [ 2.8143e-01],\n",
       "        [-4.5943e-01],\n",
       "        [ 1.2408e-03],\n",
       "        [-1.3335e-01],\n",
       "        [-2.9763e-01],\n",
       "        [-1.3679e-01],\n",
       "        [-2.9567e-01],\n",
       "        [-2.9586e-01],\n",
       "        [ 8.6532e-01],\n",
       "        [ 5.4571e-01],\n",
       "        [ 1.6882e-01],\n",
       "        [ 4.5885e-01],\n",
       "        [ 1.6364e+00],\n",
       "        [ 7.9877e-01],\n",
       "        [-9.9013e-02],\n",
       "        [ 1.1064e-01],\n",
       "        [-5.1111e-01],\n",
       "        [-8.2707e-01],\n",
       "        [ 2.3367e-01],\n",
       "        [ 1.0394e-01],\n",
       "        [ 3.4282e-01],\n",
       "        [ 8.6969e-01],\n",
       "        [-1.4500e-01],\n",
       "        [ 1.1081e+00],\n",
       "        [-3.2746e-01],\n",
       "        [ 6.2745e-02],\n",
       "        [ 5.2429e-01],\n",
       "        [ 3.8802e-01],\n",
       "        [ 2.3483e-01],\n",
       "        [-3.0262e-01],\n",
       "        [ 2.0587e-01],\n",
       "        [ 4.9475e-01],\n",
       "        [ 2.0008e-01],\n",
       "        [-3.4683e-01],\n",
       "        [-1.4812e-01],\n",
       "        [ 1.8297e-01],\n",
       "        [-6.8838e-02],\n",
       "        [ 3.5409e-02],\n",
       "        [-4.6459e-01],\n",
       "        [-3.5053e-02],\n",
       "        [ 3.0574e-01],\n",
       "        [-1.3708e+00],\n",
       "        [-5.3640e-01],\n",
       "        [ 1.1527e-01],\n",
       "        [-1.3370e-01],\n",
       "        [ 2.7027e-01],\n",
       "        [-1.9430e-01],\n",
       "        [-1.1382e-01],\n",
       "        [ 6.9356e-01],\n",
       "        [-3.6748e-01],\n",
       "        [-3.2051e-01],\n",
       "        [-1.4206e-01],\n",
       "        [-3.7186e-01],\n",
       "        [ 4.3904e-02],\n",
       "        [-5.0796e-01],\n",
       "        [ 2.0225e-01],\n",
       "        [ 1.1591e-01],\n",
       "        [-9.7348e-02],\n",
       "        [ 1.7975e-02],\n",
       "        [-2.3152e-01],\n",
       "        [ 2.5562e-01],\n",
       "        [ 2.0351e-02],\n",
       "        [-4.4730e-01],\n",
       "        [-9.2059e-01],\n",
       "        [ 3.8622e-01],\n",
       "        [ 1.3860e-02],\n",
       "        [ 3.4365e-01],\n",
       "        [-7.6175e-01],\n",
       "        [-8.0420e-02],\n",
       "        [-3.0584e-01],\n",
       "        [ 8.6532e-01],\n",
       "        [-2.1247e-01],\n",
       "        [-4.1144e-01],\n",
       "        [-9.2003e-02],\n",
       "        [-3.4019e-01],\n",
       "        [ 4.9878e-01],\n",
       "        [ 1.7898e-01],\n",
       "        [ 8.8849e-01],\n",
       "        [ 7.4732e-02],\n",
       "        [ 3.0523e-02],\n",
       "        [ 7.1895e-02],\n",
       "        [ 1.5156e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = training_x.shape[1]\n",
    "print(num_features)\n",
    "\n",
    "linear_model = nn.Linear(num_features,1) # <1>\n",
    "linear_model(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2511, -0.2303,  0.2523,  0.2684,  0.1208]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0335], requires_grad=True)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3476],\n",
       "        [-0.8496],\n",
       "        [-1.1790],\n",
       "        [-0.1512],\n",
       "        [-0.6138],\n",
       "        [-0.3761],\n",
       "        [ 0.2245],\n",
       "        [-0.8697],\n",
       "        [-1.1096],\n",
       "        [ 0.1140],\n",
       "        [-0.7039],\n",
       "        [-0.3881],\n",
       "        [ 0.4434],\n",
       "        [ 0.0087],\n",
       "        [-0.8833],\n",
       "        [ 0.0640],\n",
       "        [-0.4878],\n",
       "        [-0.0968],\n",
       "        [-0.6292],\n",
       "        [-0.4389],\n",
       "        [-0.1156],\n",
       "        [-0.4714],\n",
       "        [-0.4641],\n",
       "        [-0.0723],\n",
       "        [ 0.0909],\n",
       "        [ 0.1940],\n",
       "        [-0.9976],\n",
       "        [-0.8697],\n",
       "        [-0.3648],\n",
       "        [-0.3539],\n",
       "        [-1.2965],\n",
       "        [-1.0089],\n",
       "        [ 0.2452],\n",
       "        [-0.6852],\n",
       "        [-0.4378],\n",
       "        [-1.2030],\n",
       "        [ 0.5066],\n",
       "        [-0.3580],\n",
       "        [-0.3979],\n",
       "        [-0.1120],\n",
       "        [-1.1630],\n",
       "        [ 0.1331],\n",
       "        [-0.4041],\n",
       "        [-0.5373],\n",
       "        [-0.6697],\n",
       "        [-0.5308],\n",
       "        [-1.0496],\n",
       "        [-0.2794],\n",
       "        [-1.2728],\n",
       "        [-1.2361],\n",
       "        [-0.6022],\n",
       "        [-0.5684],\n",
       "        [-0.4060],\n",
       "        [ 0.3637],\n",
       "        [-0.0282],\n",
       "        [ 0.4179],\n",
       "        [-0.6777],\n",
       "        [-0.9232],\n",
       "        [-0.5500],\n",
       "        [-0.8014],\n",
       "        [-0.9838],\n",
       "        [-0.8230],\n",
       "        [-0.4736],\n",
       "        [-0.9186],\n",
       "        [ 0.4925],\n",
       "        [-0.8364],\n",
       "        [ 0.0710],\n",
       "        [-0.8031],\n",
       "        [-0.8143],\n",
       "        [-0.6714],\n",
       "        [-0.8171],\n",
       "        [-0.3240],\n",
       "        [-0.8697],\n",
       "        [ 0.3657],\n",
       "        [-1.0695],\n",
       "        [-0.1581],\n",
       "        [-0.7168],\n",
       "        [-1.4093],\n",
       "        [-0.4041],\n",
       "        [-0.8479],\n",
       "        [-0.9435],\n",
       "        [-0.3058],\n",
       "        [-1.3878],\n",
       "        [-1.4300],\n",
       "        [ 0.2367],\n",
       "        [ 0.0615],\n",
       "        [-0.6108],\n",
       "        [-0.9364],\n",
       "        [-0.3623],\n",
       "        [-0.8771],\n",
       "        [-0.5174],\n",
       "        [-0.8107],\n",
       "        [-0.8740],\n",
       "        [ 0.2013],\n",
       "        [-2.2822],\n",
       "        [ 0.0309],\n",
       "        [-0.2211],\n",
       "        [ 0.6930],\n",
       "        [ 0.2364],\n",
       "        [-0.7137],\n",
       "        [-0.1430],\n",
       "        [ 0.1415],\n",
       "        [-0.6434],\n",
       "        [-0.9170],\n",
       "        [-0.5169],\n",
       "        [-0.3712],\n",
       "        [-0.6239],\n",
       "        [-0.4281],\n",
       "        [-0.9672],\n",
       "        [-0.8573],\n",
       "        [-0.0509],\n",
       "        [-0.9573],\n",
       "        [-0.6708],\n",
       "        [-0.8031],\n",
       "        [-0.2057],\n",
       "        [-0.4445],\n",
       "        [-0.9765],\n",
       "        [-0.8085],\n",
       "        [-0.2113],\n",
       "        [ 0.0340],\n",
       "        [-0.2153],\n",
       "        [-0.4507],\n",
       "        [-1.0898],\n",
       "        [ 0.1866],\n",
       "        [ 0.2678],\n",
       "        [-0.7770],\n",
       "        [ 0.4335],\n",
       "        [-0.6066],\n",
       "        [-0.6502],\n",
       "        [-0.2691],\n",
       "        [-0.6064],\n",
       "        [ 0.2075],\n",
       "        [ 0.1742],\n",
       "        [-0.8764],\n",
       "        [-0.4525],\n",
       "        [-1.0210],\n",
       "        [ 0.9850],\n",
       "        [-0.7245],\n",
       "        [ 0.2472],\n",
       "        [ 0.1940],\n",
       "        [-0.3442],\n",
       "        [-0.8431],\n",
       "        [-0.9959],\n",
       "        [-0.8751],\n",
       "        [-1.5974],\n",
       "        [-0.5725],\n",
       "        [-0.4587],\n",
       "        [-0.5320],\n",
       "        [-0.4161],\n",
       "        [-0.2855],\n",
       "        [-1.1202],\n",
       "        [-0.5611],\n",
       "        [ 0.2132],\n",
       "        [ 0.0549],\n",
       "        [ 0.4880],\n",
       "        [-0.5040],\n",
       "        [ 0.0624],\n",
       "        [-0.3510],\n",
       "        [ 1.0619],\n",
       "        [ 0.0733],\n",
       "        [ 0.9262],\n",
       "        [-0.8380],\n",
       "        [ 0.0411],\n",
       "        [-0.5123],\n",
       "        [-0.6573],\n",
       "        [-0.4301],\n",
       "        [-0.0646],\n",
       "        [-0.0171],\n",
       "        [-0.4565],\n",
       "        [-0.7652],\n",
       "        [ 0.1940],\n",
       "        [-0.0585],\n",
       "        [-0.2902],\n",
       "        [-1.4824],\n",
       "        [-0.3965],\n",
       "        [-0.3770],\n",
       "        [-0.8619],\n",
       "        [-0.4817],\n",
       "        [-0.0445],\n",
       "        [-0.8531],\n",
       "        [-1.2181],\n",
       "        [-1.1293],\n",
       "        [-0.5675],\n",
       "        [-0.8498],\n",
       "        [-0.8324],\n",
       "        [-0.8162],\n",
       "        [ 0.2805],\n",
       "        [-0.7485],\n",
       "        [-0.9898],\n",
       "        [-0.4241],\n",
       "        [-0.5360],\n",
       "        [-0.1571],\n",
       "        [-0.0384],\n",
       "        [-0.5971],\n",
       "        [-0.6933],\n",
       "        [-0.4572],\n",
       "        [ 0.0349],\n",
       "        [-0.9189],\n",
       "        [-0.8113],\n",
       "        [-0.2449],\n",
       "        [ 0.1527],\n",
       "        [-0.9364],\n",
       "        [-0.4907],\n",
       "        [-0.1056],\n",
       "        [-0.8857],\n",
       "        [-0.5642],\n",
       "        [-0.8205],\n",
       "        [-0.5252],\n",
       "        [-0.4123],\n",
       "        [-1.5965],\n",
       "        [-0.5378],\n",
       "        [-0.6373],\n",
       "        [-0.8604],\n",
       "        [-0.8211],\n",
       "        [-0.1610],\n",
       "        [ 0.2614],\n",
       "        [-0.3228],\n",
       "        [-0.4201],\n",
       "        [-0.6965],\n",
       "        [-0.9678],\n",
       "        [-0.2922],\n",
       "        [-0.6759],\n",
       "        [ 0.5759],\n",
       "        [ 0.1742],\n",
       "        [-0.3719],\n",
       "        [-0.3586],\n",
       "        [ 0.4179],\n",
       "        [-0.2540],\n",
       "        [ 0.0793],\n",
       "        [-0.4041],\n",
       "        [ 0.2545],\n",
       "        [ 0.4781],\n",
       "        [ 0.7527],\n",
       "        [-0.5322],\n",
       "        [-1.2559],\n",
       "        [-0.4201],\n",
       "        [-0.1928],\n",
       "        [-0.5875],\n",
       "        [-0.7074],\n",
       "        [-0.7290],\n",
       "        [-0.8751],\n",
       "        [-0.3142],\n",
       "        [-0.4241],\n",
       "        [-0.5331],\n",
       "        [-0.0650],\n",
       "        [-0.0109],\n",
       "        [-0.6373],\n",
       "        [-0.2397],\n",
       "        [-0.7372],\n",
       "        [-0.5240],\n",
       "        [-0.8205],\n",
       "        [-0.5174],\n",
       "        [ 0.3745],\n",
       "        [-0.9371],\n",
       "        [-0.1208],\n",
       "        [-0.4177],\n",
       "        [-0.2201],\n",
       "        [-0.3511],\n",
       "        [-0.7769],\n",
       "        [-0.9570],\n",
       "        [-0.8751],\n",
       "        [-0.1257],\n",
       "        [ 0.4604],\n",
       "        [-0.6834],\n",
       "        [-1.0858],\n",
       "        [-1.3627],\n",
       "        [-0.2258],\n",
       "        [-0.6219],\n",
       "        [-0.3329],\n",
       "        [-0.7365],\n",
       "        [-0.7985],\n",
       "        [-1.0629],\n",
       "        [-0.2942],\n",
       "        [-0.7474],\n",
       "        [-0.7969],\n",
       "        [-0.5814],\n",
       "        [-0.4399],\n",
       "        [-0.5693],\n",
       "        [-0.2243],\n",
       "        [-0.4463],\n",
       "        [-0.3519],\n",
       "        [-0.7527],\n",
       "        [-0.6075],\n",
       "        [-0.1314],\n",
       "        [-0.3049],\n",
       "        [-0.1147],\n",
       "        [-1.2228],\n",
       "        [-0.9164],\n",
       "        [-0.2056],\n",
       "        [-0.6568],\n",
       "        [-0.0322],\n",
       "        [-0.8005],\n",
       "        [-0.8166],\n",
       "        [-0.2311],\n",
       "        [-1.0394],\n",
       "        [-0.7039],\n",
       "        [-0.7024],\n",
       "        [-0.4245],\n",
       "        [ 0.1940],\n",
       "        [-0.6887],\n",
       "        [-0.1912],\n",
       "        [ 0.0788],\n",
       "        [-0.6466],\n",
       "        [-0.4572],\n",
       "        [-0.3688],\n",
       "        [-1.1362],\n",
       "        [-1.3158],\n",
       "        [-0.8165],\n",
       "        [-0.3512],\n",
       "        [-0.7173],\n",
       "        [ 0.2267],\n",
       "        [-1.0811],\n",
       "        [-0.3517],\n",
       "        [-0.3750],\n",
       "        [ 0.2143],\n",
       "        [ 0.4570],\n",
       "        [-0.3250],\n",
       "        [-0.4254],\n",
       "        [ 0.5260],\n",
       "        [-0.3522],\n",
       "        [ 0.4675],\n",
       "        [-0.9355],\n",
       "        [-0.2468],\n",
       "        [-0.6770],\n",
       "        [-0.8191],\n",
       "        [ 0.5099],\n",
       "        [ 0.3970],\n",
       "        [ 0.2933],\n",
       "        [-0.4041],\n",
       "        [-0.0326],\n",
       "        [ 0.0580],\n",
       "        [-0.8165],\n",
       "        [-0.6075],\n",
       "        [-0.6699],\n",
       "        [-0.7418],\n",
       "        [-0.7605],\n",
       "        [-1.3642],\n",
       "        [-0.4089],\n",
       "        [-0.2730],\n",
       "        [-0.1651],\n",
       "        [-0.2184],\n",
       "        [-0.4572],\n",
       "        [-0.6650],\n",
       "        [-1.1930],\n",
       "        [-0.1510],\n",
       "        [-0.4721],\n",
       "        [ 0.2104],\n",
       "        [-0.8693],\n",
       "        [ 0.2334],\n",
       "        [-0.4179],\n",
       "        [-1.1391],\n",
       "        [-1.0829],\n",
       "        [ 0.0149],\n",
       "        [ 0.6137],\n",
       "        [-0.5971],\n",
       "        [-0.9600],\n",
       "        [ 0.5803],\n",
       "        [-1.2759],\n",
       "        [-0.7172],\n",
       "        [ 0.0840],\n",
       "        [-0.4363],\n",
       "        [-1.1842],\n",
       "        [-0.3580],\n",
       "        [-0.5107],\n",
       "        [-0.3913],\n",
       "        [-0.1346],\n",
       "        [ 0.5719],\n",
       "        [ 0.3944],\n",
       "        [-0.2849],\n",
       "        [-0.0437],\n",
       "        [-0.6841],\n",
       "        [-1.3829],\n",
       "        [-0.2376],\n",
       "        [-0.3868],\n",
       "        [-0.5265],\n",
       "        [ 0.0615],\n",
       "        [-0.1271],\n",
       "        [-0.4911],\n",
       "        [-0.1332],\n",
       "        [-0.7717],\n",
       "        [-0.3358],\n",
       "        [ 0.3342],\n",
       "        [-0.2362],\n",
       "        [-0.4443],\n",
       "        [-0.2695],\n",
       "        [-0.0142],\n",
       "        [-0.2762],\n",
       "        [-1.2428],\n",
       "        [-0.2644],\n",
       "        [-0.7104],\n",
       "        [-0.9230],\n",
       "        [-0.8031],\n",
       "        [-0.7032],\n",
       "        [-0.5467],\n",
       "        [-0.4354],\n",
       "        [-2.0083],\n",
       "        [-0.3757],\n",
       "        [-0.0384],\n",
       "        [-0.9976],\n",
       "        [-0.1955],\n",
       "        [-0.6550],\n",
       "        [-0.6373],\n",
       "        [-0.4017],\n",
       "        [-0.5189],\n",
       "        [-0.1252],\n",
       "        [-0.6719],\n",
       "        [-0.8593],\n",
       "        [-0.1183],\n",
       "        [-1.0158],\n",
       "        [-0.2918],\n",
       "        [ 0.3020],\n",
       "        [-0.5435],\n",
       "        [-0.1503],\n",
       "        [-0.3603],\n",
       "        [ 0.4606],\n",
       "        [-0.8205],\n",
       "        [-0.9641],\n",
       "        [-1.1529],\n",
       "        [-0.4177],\n",
       "        [-0.9049],\n",
       "        [ 0.5618],\n",
       "        [-1.3077],\n",
       "        [-0.9364],\n",
       "        [-0.7833],\n",
       "        [-0.3580],\n",
       "        [-1.0882],\n",
       "        [-0.2297],\n",
       "        [-0.9497],\n",
       "        [-0.5601],\n",
       "        [-0.0298],\n",
       "        [ 0.0349],\n",
       "        [-0.3314],\n",
       "        [-0.0850],\n",
       "        [-0.4734],\n",
       "        [-0.7612],\n",
       "        [-0.3342]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) # <1>\n",
    "optimizer = optim.SGD(\n",
    "    linear_model.parameters(), # <2>\n",
    "    lr=1e-2)\n",
    "\n",
    "linear_model(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001D1CC48FA50>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2889,  0.0392, -0.0566,  0.2421,  0.4295]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4330], requires_grad=True)]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(linear_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, \n",
    "                  train_x, val_x,\n",
    "                  train_y, val_y, \n",
    "                  epoch_report = 1000):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_p = model(train_x) # <1>\n",
    "        loss_train = loss_fn(train_p, train_y)\n",
    "\n",
    "        val_p = model(val_x) # <1>\n",
    "        loss_val = loss_fn(val_p, val_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % epoch_report == 0 or epoch == n_epochs:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Neural Network training with a single node\n",
    "nothign to grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.7092, Validation loss 1.3225\n",
      "Epoch 500, Training loss 1.0504, Validation loss 0.7987\n",
      "Epoch 1000, Training loss 1.0504, Validation loss 0.7987\n",
      "Epoch 1500, Training loss 1.0504, Validation loss 0.7987\n",
      "Epoch 2000, Training loss 1.0504, Validation loss 0.7987\n",
      "Epoch 2500, Training loss 1.0504, Validation loss 0.7987\n",
      "Epoch 3000, Training loss 1.0504, Validation loss 0.7987\n",
      "\n",
      "Weight Parameter containing:\n",
      "tensor([[-1.3901e-10,  4.9021e-11, -1.0323e-09,  2.8931e-10,  2.1499e-10]],\n",
      "       requires_grad=True)\n",
      "Bias Parameter containing:\n",
      "tensor([-0.0082], requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) # <1>\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 3000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 500\n",
    "    )\n",
    "\n",
    "print()\n",
    "print(\"Weight\", linear_model.weight)\n",
    "print(\"Bias\", linear_model.bias)\n",
    "\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning Sequential layer models\n",
    "nothing here to be graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=22, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=22, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model_example = nn.Sequential(\n",
    "            nn.Linear(9, 22), # <1>\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(22, 3)) # <2>\n",
    "seq_model_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([22, 9]), torch.Size([22]), torch.Size([3, 22]), torch.Size([3])]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.shape for param in seq_model_example.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([22, 9])\n",
      "0.bias torch.Size([22])\n",
      "2.weight torch.Size([3, 22])\n",
      "2.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model_example.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_linear): Linear(in_features=1, out_features=8, bias=True)\n",
       "  (hidden_activation): Tanh()\n",
       "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "seq_model_example = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(1, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 1))\n",
    "]))\n",
    "\n",
    "seq_model_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([8, 1])\n",
      "hidden_linear.bias torch.Size([8])\n",
      "output_linear.weight torch.Size([1, 8])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model_example.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0729], requires_grad=True)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model_example.output_linear.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper training with a sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### example of single layer\n",
    "for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.2593, Validation loss 1.0225\n",
      "Epoch 25, Training loss 1.2593, Validation loss 1.0225\n",
      "Epoch 50, Training loss 1.2593, Validation loss 1.0225\n",
      "Epoch 75, Training loss 1.2593, Validation loss 1.0225\n",
      "Epoch 100, Training loss 1.2593, Validation loss 1.0225\n",
      "Epoch 125, Training loss 1.2593, Validation loss 1.0225\n",
      "Epoch 150, Training loss 1.2593, Validation loss 1.0225\n",
      "Epoch 175, Training loss 1.2593, Validation loss 1.0225\n",
      "Epoch 200, Training loss 1.2593, Validation loss 1.0225\n",
      "\n",
      "Weight Parameter containing:\n",
      "tensor([[-1.3901e-10,  4.9021e-11, -1.0323e-09,  2.8931e-10,  2.1499e-10]],\n",
      "       requires_grad=True)\n",
      "Bias Parameter containing:\n",
      "tensor([-0.0082], requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([436])) that is different to the input size (torch.Size([436, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\Adam\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([109])) that is different to the input size (torch.Size([109, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "linear_model_0 = nn.Linear(5, 1)\n",
    "linear_model_0.zero_grad()\n",
    "\n",
    "optimizer_0 = optim.SGD(linear_model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_0 = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer_0,\n",
    "    model = linear_model_0,\n",
    "    loss_fn = loss_0, \n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y,  \n",
    "    epoch_report = 25)\n",
    "\n",
    "print()\n",
    "print(\"Weight\", linear_model.weight)\n",
    "print(\"Bias\", linear_model.bias)\n",
    "\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a\n",
    "1 hidden layer with 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.2123, Validation loss 0.9398\n",
      "Epoch 25, Training loss 1.2020, Validation loss 0.9310\n",
      "Epoch 50, Training loss 1.1921, Validation loss 0.9225\n",
      "Epoch 75, Training loss 1.1832, Validation loss 0.9148\n",
      "Epoch 100, Training loss 1.1750, Validation loss 0.9077\n",
      "Epoch 125, Training loss 1.1675, Validation loss 0.9013\n",
      "Epoch 150, Training loss 1.1606, Validation loss 0.8953\n",
      "Epoch 175, Training loss 1.1542, Validation loss 0.8898\n",
      "Epoch 200, Training loss 1.1484, Validation loss 0.8847\n"
     ]
    }
   ],
   "source": [
    "seq_model_1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(5, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 1))\n",
    "]))\n",
    "seq_model_1.zero_grad()\n",
    "\n",
    "optimizer_1 = optim.SGD(seq_model_1.parameters(), lr=1e-3)\n",
    "optimizer_1.zero_grad()\n",
    "\n",
    "loss_1 = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer_1,\n",
    "    model = seq_model_1,\n",
    "    loss_fn = loss_1,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b\n",
    "add 2 more hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.1121, Validation loss 0.8678\n",
      "Epoch 25, Training loss 1.1048, Validation loss 0.8597\n",
      "Epoch 50, Training loss 1.0984, Validation loss 0.8527\n",
      "Epoch 75, Training loss 1.0932, Validation loss 0.8468\n",
      "Epoch 100, Training loss 1.0889, Validation loss 0.8420\n",
      "Epoch 125, Training loss 1.0852, Validation loss 0.8378\n",
      "Epoch 150, Training loss 1.0821, Validation loss 0.8343\n",
      "Epoch 175, Training loss 1.0795, Validation loss 0.8313\n",
      "Epoch 200, Training loss 1.0772, Validation loss 0.8288\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "\n",
    "seq_model_2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "seq_model_2.zero_grad()\n",
    "\n",
    "optimizer_2 = optim.SGD(seq_model_2.parameters(), lr=1e-3)\n",
    "optimizer_2.zero_grad()\n",
    "\n",
    "loss_2 = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer_2,\n",
    "    model = seq_model_2,\n",
    "    loss_fn = loss_2,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=5, out_features=1, bias=True)\n",
      "\n",
      "     Validation Loss: 1.0225023031234741\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear): Linear(in_features=5, out_features=8, bias=True)\n",
      "  (hidden_activation): Tanh()\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 0.8844773769378662\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation): Tanh()\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 0.8286619186401367\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [linear_model_0, seq_model_1, seq_model_2]\n",
    "for model in models:\n",
    "    print(f'{model}\\n')\n",
    "        \n",
    "    predictions = model(validation_x) \n",
    "    loss = loss_fn(predictions, validation_y)\n",
    "    print(f'     Validation Loss: {loss}\\n')\n",
    "        \n",
    "    for name, param in seq_model_2.named_parameters():\n",
    "        print(f'     {name}  \\t: ', param.shape)\n",
    "        \n",
    "    print('\\n' + '-'*90 + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77aa5c7a8032890130e9a412da4828609b1dfa25c62620094c03af7a5cea44b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
