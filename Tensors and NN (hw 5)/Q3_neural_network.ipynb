{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5 Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## define model and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature, w5, w4, w3, w2, w1, b):\n",
    "    return feature[4] * w5 + feature[3] * w4 + feature[2] * w3 + feature[1] * w2 + feature[0] * w1 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(predicted, actual):\n",
    "    squared_diffs = (predicted - actual)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.01, 0.001, 0.0001, 1e-05]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_to_learn_at = [1/x for x in [10, 100, 1000, 10000, 100000]]\n",
    "rates_to_learn_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_for_validation = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(pd.read_csv('Housing.csv'))\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = (545, 13)\n",
      "features are: ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape = {np.shape(housing_df)}\")\n",
    "\n",
    "# creates a list of all variables from the column names\n",
    "feature_list = list( housing_df.columns )\n",
    "\n",
    "print(f\"features are: {feature_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary vars = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
      "furnish vars = ['furnishingstatus']\n",
      "value vars = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n"
     ]
    }
   ],
   "source": [
    "# Maps to turn categorys into numbers \n",
    "def boolean_map(x):\n",
    "    return x.map({'yes': 1 , 'no': 0})\n",
    "def furnish_map(x):\n",
    "    return x.map({'furnished': 1 , 'semi-furnished': 0.5 , 'unfurnished': 0})\n",
    "\n",
    "# Extracts the yes and no column names\n",
    "binary_vars = [*feature_list[5:10], feature_list[11]]\n",
    "print(f\"binary vars = {binary_vars}\")\n",
    "\n",
    "# Extracts the furnishing column names\n",
    "furnish_vars = [feature_list[12]]\n",
    "print(f\"furnish vars = {furnish_vars}\")\n",
    "\n",
    "# Extracts the column names that are actual values\n",
    "valued_vars = feature_list.copy()\n",
    "[valued_vars.remove( item ) for item in binary_vars]\n",
    "[valued_vars.remove( item ) for item in furnish_vars]\n",
    "print(f\"value vars = {valued_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = housing_df.copy()\n",
    "\n",
    "## scale data\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "x_df[valued_vars] = scaler.fit_transform(x_df[valued_vars])\n",
    "\n",
    "## map text values\n",
    "x_df[binary_vars] = x_df[binary_vars].apply(boolean_map)\n",
    "x_df[furnish_vars] = x_df[furnish_vars].apply(furnish_map)\n",
    "\n",
    "## make y_df\n",
    "y_df = x_df.pop('price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_values = valued_vars.copy()\n",
    "# input_values.remove('price')\n",
    "\n",
    "\n",
    "# x_df = x_df[input_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories  mainroad  guestroom  basement  \\\n",
       "0  1.046726  1.403419   1.421812  1.378217         1          0         0   \n",
       "1  1.757010  1.403419   5.405809  2.532024         1          0         0   \n",
       "2  2.218232  0.047278   1.421812  0.224410         1          0         1   \n",
       "3  1.083624  1.403419   1.421812  0.224410         1          0         1   \n",
       "4  1.046726  1.403419  -0.570187  0.224410         1          1         1   \n",
       "\n",
       "   hotwaterheating  airconditioning   parking  prefarea  furnishingstatus  \n",
       "0                0                1  1.517692         1               1.0  \n",
       "1                0                1  2.679409         0               1.0  \n",
       "2                0                0  1.517692         1               0.5  \n",
       "3                0                1  2.679409         1               1.0  \n",
       "4                0                1  1.517692         0               1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.566365\n",
       "1    4.004484\n",
       "2    4.004484\n",
       "3    3.985755\n",
       "4    3.554979\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories   parking\n",
       "0  1.046726  1.403419   1.421812  1.378217  1.517692\n",
       "1  1.757010  1.403419   5.405809  2.532024  2.679409\n",
       "2  2.218232  0.047278   1.421812  0.224410  1.517692\n",
       "3  1.083624  1.403419   1.421812  0.224410  2.679409\n",
       "4  1.046726  1.403419  -0.570187  0.224410  1.517692"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted data\n",
    "for item in [*binary_vars, *furnish_vars] :\n",
    "    x_df.pop(item)\n",
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frame to tensor\n",
    "\n",
    "x = torch.tensor(x_df.values, dtype=torch.float32)\n",
    "y = torch.tensor(y_df.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([545, 5])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Split into train and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set randomization keys\n",
    "Set so that it should reproduce the same results every time. \n",
    "Remove to test that network is learning regardless of the randomization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([273, 453,  72, 266, 237, 362, 241, 138, 195, 442,  71, 173, 311,\n",
       "         440, 317, 391, 379, 270,  40, 280, 376, 188, 336, 480, 168, 434,\n",
       "         512, 278, 457, 400, 420, 498, 229,  62, 253, 238, 359, 291, 219,\n",
       "         402, 109, 326, 398, 205,   3, 302, 357, 320, 318, 285, 171, 209,\n",
       "         319, 538, 103, 134, 145, 489, 158, 232, 192, 386, 283, 349, 128,\n",
       "         524, 177,  98,  53,  68,  92, 500, 406,  22, 255, 110, 256, 250,\n",
       "          49, 486, 120, 312, 175,  67, 217, 404, 544, 484, 119, 410, 466,\n",
       "         532, 245, 313, 401, 468,  70, 334, 353,  52, 527, 210, 321,  12,\n",
       "         375,  63, 354, 220,  61, 162,  46,  86,  58, 183,  78,  90, 330,\n",
       "         214,   1, 495, 343, 201, 378, 332, 461, 107,  99, 465, 298,  66,\n",
       "          38, 236, 531,  81,  24, 133, 426, 243, 505,  28, 445, 539,  54,\n",
       "         403, 230, 305, 485, 335, 493, 118, 492, 488, 387,   2, 413, 325,\n",
       "         172, 221, 160,  57, 121, 279, 275, 196, 427, 244, 542, 437, 314,\n",
       "         191, 352, 366, 418, 224, 190, 367, 102,  41, 530, 310, 458, 150,\n",
       "          95,  59,  11, 327, 282, 202, 186, 540, 301, 272, 451, 258, 251,\n",
       "         247, 297, 123, 329,  36, 517, 515, 137,   4, 381, 179, 211, 218,\n",
       "         249, 494, 409, 149, 276, 424, 333, 422,  37, 182, 293, 178, 502,\n",
       "          44, 342, 358,  74, 269, 112, 105, 380, 477, 139, 518, 454, 181,\n",
       "         476, 346, 248, 384, 447, 306, 361, 113, 233, 355,  15, 421, 184,\n",
       "         337, 533, 294, 448, 206, 449, 163, 161, 264, 455, 189, 417, 428,\n",
       "         289, 487, 100, 164,  84, 166, 299, 435,  85, 463,  26, 180, 514,\n",
       "         223,  80,  50, 307, 470, 371, 412, 227, 481, 525, 370, 392, 522,\n",
       "         503, 377, 526,   8, 129,  94,  25, 425, 507, 254, 231, 198, 274,\n",
       "         356, 328,  88,  87,  83,  32,  16, 419, 460,  91, 350,   5, 411,\n",
       "         115, 124, 222, 117, 154,  51, 360,  45, 125,  31, 513,  82, 389,\n",
       "         144, 127, 372, 213, 464, 143,  73, 407, 287, 373, 390, 497,  27,\n",
       "         348, 509, 284, 436, 429, 131, 469, 383, 474, 200, 140, 216, 499,\n",
       "         136, 146, 511, 263, 165, 141, 521, 340, 345, 155, 111, 475, 260,\n",
       "         529, 415, 262, 516, 126, 304, 382, 187,  18, 292, 104, 339, 259,\n",
       "          89, 226,  19, 388, 142, 432, 443, 277, 338, 281, 491, 385,  60,\n",
       "         482,  69, 467, 323, 152,  21, 176,  14,  43,  93, 364, 408, 106,\n",
       "          20, 286, 135, 315,  39, 472, 204, 308, 452, 268, 543, 393, 324,\n",
       "          55,  34, 504, 132,  79, 405, 351, 414,   0, 235, 363, 242, 431,\n",
       "          30,  76, 257, 490, 541, 303, 185]),\n",
       " tensor([  7,  29, 396, 240,  13, 536,  17, 456, 147, 215, 116, 439, 374,\n",
       "         167, 416,  48,   6,  47, 478, 395, 331, 153, 295, 441, 423,  23,\n",
       "         114, 501, 148, 519, 151, 430, 399, 265,  64,  35, 394, 479, 290,\n",
       "         471, 246,  97, 462, 170, 520, 234, 300, 309, 208, 459, 506, 252,\n",
       "         523, 341, 316, 225, 296, 157, 108,  96, 261,  56, 193, 344, 446,\n",
       "         174, 369, 199, 159, 535, 534, 271, 288,  65, 194, 508, 212,  42,\n",
       "         239, 322, 438,   9, 203, 228,  77,  33, 473, 510, 267, 156, 169,\n",
       "         197, 483, 122,  10, 450, 365, 537, 397, 528, 130, 347, 444, 101,\n",
       "         496, 207, 368,  75, 433]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = x.shape[0]\n",
    "n_val = int(percent_for_validation * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, val_indices  # <1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = x[train_indices]\n",
    "training_y  = y [train_indices].unsqueeze(1)\n",
    "\n",
    "validation_x = x[val_indices]\n",
    "validation_y  = y[val_indices].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([436, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Learning how to use neural network component\n",
    "nothing to grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7285],\n",
       "        [-0.4643],\n",
       "        [ 0.6932],\n",
       "        [-0.6636],\n",
       "        [-0.1336],\n",
       "        [-0.3109],\n",
       "        [-0.7795],\n",
       "        [ 0.2782],\n",
       "        [ 0.5942],\n",
       "        [-0.5041],\n",
       "        [ 1.0739],\n",
       "        [-0.2372],\n",
       "        [-0.1547],\n",
       "        [-0.6104],\n",
       "        [ 0.3751],\n",
       "        [-0.3380],\n",
       "        [-0.8044],\n",
       "        [ 0.7889],\n",
       "        [ 0.0258],\n",
       "        [ 0.3411],\n",
       "        [ 0.2859],\n",
       "        [ 0.2748],\n",
       "        [-0.3323],\n",
       "        [-0.3438],\n",
       "        [-0.5462],\n",
       "        [-0.5946],\n",
       "        [-0.0067],\n",
       "        [-0.4039],\n",
       "        [-0.7546],\n",
       "        [-0.4184],\n",
       "        [ 0.1092],\n",
       "        [-0.1102],\n",
       "        [ 0.5759],\n",
       "        [ 0.2212],\n",
       "        [ 0.0471],\n",
       "        [ 0.0939],\n",
       "        [-0.7443],\n",
       "        [-0.3465],\n",
       "        [ 0.0724],\n",
       "        [-0.1215],\n",
       "        [ 0.2600],\n",
       "        [-0.9756],\n",
       "        [-0.3811],\n",
       "        [-0.5166],\n",
       "        [ 0.2480],\n",
       "        [-0.0691],\n",
       "        [-0.3216],\n",
       "        [-0.3087],\n",
       "        [-0.6158],\n",
       "        [ 0.0362],\n",
       "        [-0.0539],\n",
       "        [-0.3695],\n",
       "        [-0.3674],\n",
       "        [-0.3524],\n",
       "        [ 1.0322],\n",
       "        [-0.4441],\n",
       "        [ 0.6911],\n",
       "        [-0.3624],\n",
       "        [-0.3427],\n",
       "        [-0.2646],\n",
       "        [-0.3819],\n",
       "        [-0.7702],\n",
       "        [-0.5358],\n",
       "        [-0.1533],\n",
       "        [ 0.2782],\n",
       "        [-0.3923],\n",
       "        [-0.4388],\n",
       "        [ 1.0581],\n",
       "        [ 1.2172],\n",
       "        [-0.4958],\n",
       "        [ 1.2846],\n",
       "        [-0.7753],\n",
       "        [-0.2313],\n",
       "        [-0.2836],\n",
       "        [-0.1728],\n",
       "        [-0.4855],\n",
       "        [-0.3418],\n",
       "        [ 0.1240],\n",
       "        [ 0.3193],\n",
       "        [-0.1091],\n",
       "        [-0.4918],\n",
       "        [-0.6924],\n",
       "        [ 0.5379],\n",
       "        [ 0.2426],\n",
       "        [-0.0455],\n",
       "        [-0.1450],\n",
       "        [-0.2537],\n",
       "        [-0.4155],\n",
       "        [-0.4421],\n",
       "        [-0.6666],\n",
       "        [-0.3324],\n",
       "        [-0.4196],\n",
       "        [-0.2010],\n",
       "        [ 0.3429],\n",
       "        [ 0.1757],\n",
       "        [-0.4367],\n",
       "        [ 0.3761],\n",
       "        [-0.4414],\n",
       "        [ 0.0563],\n",
       "        [ 1.0221],\n",
       "        [-0.5401],\n",
       "        [-0.2749],\n",
       "        [ 0.2341],\n",
       "        [ 0.2533],\n",
       "        [-0.0353],\n",
       "        [ 0.5947],\n",
       "        [ 0.0876],\n",
       "        [ 0.5734],\n",
       "        [ 0.1372],\n",
       "        [ 0.3103],\n",
       "        [ 1.3570],\n",
       "        [ 0.4511],\n",
       "        [ 1.1960],\n",
       "        [-0.2909],\n",
       "        [-0.5787],\n",
       "        [-0.1346],\n",
       "        [ 0.1020],\n",
       "        [-0.2799],\n",
       "        [ 2.4533],\n",
       "        [-0.2900],\n",
       "        [-0.3078],\n",
       "        [-0.2283],\n",
       "        [-0.0038],\n",
       "        [-0.4178],\n",
       "        [-0.2167],\n",
       "        [ 0.4252],\n",
       "        [ 0.0468],\n",
       "        [-0.3368],\n",
       "        [-0.5684],\n",
       "        [ 0.5844],\n",
       "        [ 0.6910],\n",
       "        [-0.0202],\n",
       "        [-0.5165],\n",
       "        [ 0.3243],\n",
       "        [ 0.7693],\n",
       "        [ 0.2575],\n",
       "        [-0.7856],\n",
       "        [-0.3883],\n",
       "        [-0.2382],\n",
       "        [ 0.0114],\n",
       "        [-0.0381],\n",
       "        [-0.4725],\n",
       "        [ 0.5313],\n",
       "        [ 0.2748],\n",
       "        [ 0.2417],\n",
       "        [-0.3469],\n",
       "        [-0.3544],\n",
       "        [-0.4388],\n",
       "        [-0.6552],\n",
       "        [-0.4005],\n",
       "        [-0.4297],\n",
       "        [-0.0360],\n",
       "        [-0.2133],\n",
       "        [ 0.8894],\n",
       "        [ 0.1639],\n",
       "        [-0.6290],\n",
       "        [ 0.1137],\n",
       "        [-0.0189],\n",
       "        [ 0.4814],\n",
       "        [ 1.3326],\n",
       "        [ 0.0963],\n",
       "        [-0.0718],\n",
       "        [-0.3128],\n",
       "        [-0.2695],\n",
       "        [-0.4302],\n",
       "        [-0.1015],\n",
       "        [-0.3554],\n",
       "        [-0.5083],\n",
       "        [ 0.0491],\n",
       "        [ 0.4554],\n",
       "        [-0.2303],\n",
       "        [-0.3544],\n",
       "        [-0.7285],\n",
       "        [ 0.2262],\n",
       "        [-0.3041],\n",
       "        [-0.3544],\n",
       "        [ 1.3053],\n",
       "        [ 1.4461],\n",
       "        [-0.8632],\n",
       "        [-0.4456],\n",
       "        [-0.2537],\n",
       "        [-0.1206],\n",
       "        [ 0.6957],\n",
       "        [ 1.3570],\n",
       "        [ 0.7587],\n",
       "        [-0.0333],\n",
       "        [-0.4271],\n",
       "        [-0.3555],\n",
       "        [ 0.8638],\n",
       "        [-0.5232],\n",
       "        [-0.2878],\n",
       "        [-0.7469],\n",
       "        [-0.0314],\n",
       "        [-0.2858],\n",
       "        [-0.3469],\n",
       "        [ 0.5526],\n",
       "        [ 0.3388],\n",
       "        [ 0.3848],\n",
       "        [-0.2423],\n",
       "        [ 1.0976],\n",
       "        [-0.4714],\n",
       "        [-0.3199],\n",
       "        [-0.5587],\n",
       "        [-0.3227],\n",
       "        [-0.3161],\n",
       "        [ 0.1875],\n",
       "        [ 0.1666],\n",
       "        [-0.2317],\n",
       "        [ 0.1436],\n",
       "        [-0.0263],\n",
       "        [-0.5041],\n",
       "        [-0.1026],\n",
       "        [-0.3265],\n",
       "        [-0.3313],\n",
       "        [-0.3417],\n",
       "        [-0.3451],\n",
       "        [ 1.2808],\n",
       "        [-0.2992],\n",
       "        [-0.3255],\n",
       "        [-0.4353],\n",
       "        [-0.4217],\n",
       "        [ 1.0221],\n",
       "        [ 0.0881],\n",
       "        [-0.3699],\n",
       "        [-0.2858],\n",
       "        [-0.2485],\n",
       "        [-0.5977],\n",
       "        [ 0.6393],\n",
       "        [-0.2643],\n",
       "        [-0.2167],\n",
       "        [-0.5104],\n",
       "        [-0.3678],\n",
       "        [-0.1864],\n",
       "        [ 0.0413],\n",
       "        [-0.0985],\n",
       "        [-0.0920],\n",
       "        [ 0.3085],\n",
       "        [-0.2643],\n",
       "        [-0.3678],\n",
       "        [-0.2030],\n",
       "        [-0.4419],\n",
       "        [-0.1729],\n",
       "        [-0.6345],\n",
       "        [-0.3147],\n",
       "        [-0.4697],\n",
       "        [-0.2385],\n",
       "        [ 0.2726],\n",
       "        [-0.5638],\n",
       "        [-0.4038],\n",
       "        [ 0.0411],\n",
       "        [-0.4099],\n",
       "        [-0.1298],\n",
       "        [-0.4814],\n",
       "        [-0.3586],\n",
       "        [ 0.3921],\n",
       "        [ 0.1899],\n",
       "        [-0.4963],\n",
       "        [-0.3637],\n",
       "        [-0.3534],\n",
       "        [-0.3638],\n",
       "        [-0.2282],\n",
       "        [-0.4282],\n",
       "        [ 0.2323],\n",
       "        [ 0.6048],\n",
       "        [-0.3666],\n",
       "        [-0.3613],\n",
       "        [-0.4960],\n",
       "        [-0.3119],\n",
       "        [ 1.2289],\n",
       "        [-0.4103],\n",
       "        [ 1.4089],\n",
       "        [-0.4236],\n",
       "        [-0.3417],\n",
       "        [-0.0497],\n",
       "        [-0.0830],\n",
       "        [ 1.5061],\n",
       "        [-0.3335],\n",
       "        [-0.5397],\n",
       "        [-0.2827],\n",
       "        [-0.3820],\n",
       "        [-0.1609],\n",
       "        [-0.4507],\n",
       "        [-0.3534],\n",
       "        [-0.3907],\n",
       "        [-0.2392],\n",
       "        [-0.3960],\n",
       "        [-0.6510],\n",
       "        [ 0.2570],\n",
       "        [-0.4010],\n",
       "        [-0.2523],\n",
       "        [ 0.8433],\n",
       "        [ 1.0221],\n",
       "        [ 0.2004],\n",
       "        [-0.5041],\n",
       "        [-0.3575],\n",
       "        [-0.6240],\n",
       "        [-0.6179],\n",
       "        [-0.0365],\n",
       "        [-0.3195],\n",
       "        [-0.9117],\n",
       "        [ 0.4278],\n",
       "        [-0.4017],\n",
       "        [-0.7588],\n",
       "        [ 1.4089],\n",
       "        [ 0.0804],\n",
       "        [ 0.2584],\n",
       "        [-0.0609],\n",
       "        [ 0.0565],\n",
       "        [-0.1351],\n",
       "        [-0.0151],\n",
       "        [ 0.8361],\n",
       "        [-0.0173],\n",
       "        [-0.3406],\n",
       "        [ 1.4114],\n",
       "        [ 0.1150],\n",
       "        [-0.6042],\n",
       "        [ 0.2362],\n",
       "        [ 0.7764],\n",
       "        [-0.3119],\n",
       "        [ 0.9960],\n",
       "        [ 0.4461],\n",
       "        [ 0.7945],\n",
       "        [-0.1968],\n",
       "        [ 0.5842],\n",
       "        [-0.5110],\n",
       "        [-0.5525],\n",
       "        [ 1.0477],\n",
       "        [-0.3230],\n",
       "        [-0.2688],\n",
       "        [ 0.0967],\n",
       "        [ 0.2019],\n",
       "        [ 1.8059],\n",
       "        [-0.0173],\n",
       "        [-0.0829],\n",
       "        [-0.0067],\n",
       "        [ 0.1830],\n",
       "        [-0.3229],\n",
       "        [-0.1982],\n",
       "        [ 0.2102],\n",
       "        [ 0.6178],\n",
       "        [ 0.0223],\n",
       "        [-0.4302],\n",
       "        [-0.4929],\n",
       "        [ 0.4419],\n",
       "        [-0.2540],\n",
       "        [-0.0108],\n",
       "        [-0.5885],\n",
       "        [-0.1843],\n",
       "        [ 1.3881],\n",
       "        [-0.5435],\n",
       "        [ 0.9520],\n",
       "        [ 0.0824],\n",
       "        [ 0.3049],\n",
       "        [-0.7359],\n",
       "        [-0.2415],\n",
       "        [ 0.2168],\n",
       "        [ 0.2647],\n",
       "        [-0.3539],\n",
       "        [-0.1593],\n",
       "        [-0.4436],\n",
       "        [ 0.0769],\n",
       "        [ 0.5236],\n",
       "        [-0.0067],\n",
       "        [-0.3767],\n",
       "        [-0.2413],\n",
       "        [-0.2087],\n",
       "        [-0.3420],\n",
       "        [-0.4466],\n",
       "        [-0.4276],\n",
       "        [-0.3666],\n",
       "        [-0.3261],\n",
       "        [-0.4337],\n",
       "        [ 0.3345],\n",
       "        [-0.0886],\n",
       "        [ 0.0148],\n",
       "        [-0.0438],\n",
       "        [-0.1236],\n",
       "        [ 0.6909],\n",
       "        [ 0.7087],\n",
       "        [ 0.5748],\n",
       "        [-0.2744],\n",
       "        [ 0.6621],\n",
       "        [-0.4378],\n",
       "        [-0.6697],\n",
       "        [ 0.2904],\n",
       "        [ 0.0740],\n",
       "        [-0.3680],\n",
       "        [-0.5087],\n",
       "        [-0.3534],\n",
       "        [ 0.5313],\n",
       "        [-0.3261],\n",
       "        [ 0.7749],\n",
       "        [-0.4205],\n",
       "        [-0.6616],\n",
       "        [-0.7631],\n",
       "        [ 0.1861],\n",
       "        [-0.2868],\n",
       "        [ 0.7694],\n",
       "        [ 0.9703],\n",
       "        [ 0.1390],\n",
       "        [-0.3293],\n",
       "        [-0.3161],\n",
       "        [-0.2217],\n",
       "        [-0.3087],\n",
       "        [-0.7766],\n",
       "        [ 1.4089],\n",
       "        [-0.1505],\n",
       "        [ 1.0221],\n",
       "        [-0.7669],\n",
       "        [-0.5713],\n",
       "        [-0.2852],\n",
       "        [ 0.1758],\n",
       "        [-0.4748],\n",
       "        [-0.7639],\n",
       "        [-0.2966],\n",
       "        [-0.1864],\n",
       "        [-0.0830],\n",
       "        [-0.6659],\n",
       "        [-0.4005],\n",
       "        [ 0.2989],\n",
       "        [ 0.9960],\n",
       "        [-0.7483],\n",
       "        [-0.3575],\n",
       "        [-0.3119],\n",
       "        [ 0.7044],\n",
       "        [-0.1161],\n",
       "        [-0.3592],\n",
       "        [-0.2754],\n",
       "        [-0.6580],\n",
       "        [ 1.4579],\n",
       "        [ 1.0395],\n",
       "        [-0.2111],\n",
       "        [-0.2538],\n",
       "        [-0.8167],\n",
       "        [-0.5993],\n",
       "        [-0.3417]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = training_x.shape[1]\n",
    "print(num_features)\n",
    "\n",
    "linear_model = nn.Linear(num_features,1) # <1>\n",
    "linear_model(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2244, -0.2470,  0.3084,  0.3578, -0.0446]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0478], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6709],\n",
       "        [ 0.9484],\n",
       "        [-0.1572],\n",
       "        [ 1.0041],\n",
       "        [ 0.0584],\n",
       "        [ 0.4906],\n",
       "        [ 1.0515],\n",
       "        [-0.0488],\n",
       "        [-0.8446],\n",
       "        [ 0.9646],\n",
       "        [-1.2211],\n",
       "        [-0.8687],\n",
       "        [ 0.8218],\n",
       "        [-0.1676],\n",
       "        [ 0.1533],\n",
       "        [ 0.1419],\n",
       "        [ 1.0616],\n",
       "        [-0.3498],\n",
       "        [-0.0067],\n",
       "        [ 0.2852],\n",
       "        [ 0.1897],\n",
       "        [ 0.3123],\n",
       "        [ 0.8687],\n",
       "        [ 0.5394],\n",
       "        [-0.1938],\n",
       "        [-0.1740],\n",
       "        [ 0.4274],\n",
       "        [ 0.9591],\n",
       "        [ 0.2510],\n",
       "        [ 0.9296],\n",
       "        [ 0.3800],\n",
       "        [ 0.4697],\n",
       "        [-0.7447],\n",
       "        [-0.5998],\n",
       "        [ 0.4054],\n",
       "        [-0.9429],\n",
       "        [ 0.6419],\n",
       "        [ 0.1454],\n",
       "        [-0.0258],\n",
       "        [ 0.4131],\n",
       "        [-0.6156],\n",
       "        [-0.0795],\n",
       "        [ 0.5546],\n",
       "        [ 0.9440],\n",
       "        [ 0.1795],\n",
       "        [ 0.4883],\n",
       "        [ 0.1095],\n",
       "        [ 0.9202],\n",
       "        [ 0.1943],\n",
       "        [-0.0110],\n",
       "        [ 0.3598],\n",
       "        [ 0.0937],\n",
       "        [ 0.5845],\n",
       "        [ 0.5075],\n",
       "        [-0.8444],\n",
       "        [ 0.9144],\n",
       "        [-0.1564],\n",
       "        [ 0.5470],\n",
       "        [ 0.8730],\n",
       "        [ 0.1119],\n",
       "        [ 0.0987],\n",
       "        [ 1.0477],\n",
       "        [-0.1981],\n",
       "        [ 0.0664],\n",
       "        [ 0.3464],\n",
       "        [ 0.5238],\n",
       "        [ 0.1220],\n",
       "        [-0.8550],\n",
       "        [-0.0686],\n",
       "        [ 0.5404],\n",
       "        [-0.8864],\n",
       "        [ 0.2595],\n",
       "        [ 0.8531],\n",
       "        [ 0.4537],\n",
       "        [ 0.8292],\n",
       "        [ 0.9314],\n",
       "        [ 0.9337],\n",
       "        [ 0.0142],\n",
       "        [-0.6753],\n",
       "        [ 0.4081],\n",
       "        [ 0.9339],\n",
       "        [ 0.2256],\n",
       "        [-0.3341],\n",
       "        [ 0.1463],\n",
       "        [ 0.8127],\n",
       "        [ 0.0630],\n",
       "        [ 0.1075],\n",
       "        [ 0.5333],\n",
       "        [ 0.9136],\n",
       "        [ 0.2151],\n",
       "        [ 0.1396],\n",
       "        [ 0.5350],\n",
       "        [ 0.8762],\n",
       "        [-0.6239],\n",
       "        [ 1.1174],\n",
       "        [ 0.5419],\n",
       "        [-0.6374],\n",
       "        [ 0.9390],\n",
       "        [ 0.0419],\n",
       "        [-0.8048],\n",
       "        [ 0.5842],\n",
       "        [ 0.9064],\n",
       "        [ 0.2109],\n",
       "        [-0.6129],\n",
       "        [ 0.0182],\n",
       "        [-0.2961],\n",
       "        [ 0.7229],\n",
       "        [ 0.2612],\n",
       "        [ 0.7026],\n",
       "        [-1.0313],\n",
       "        [-0.5209],\n",
       "        [-0.1194],\n",
       "        [-0.8759],\n",
       "        [ 0.4567],\n",
       "        [ 0.9694],\n",
       "        [ 0.0588],\n",
       "        [ 0.3830],\n",
       "        [ 0.4779],\n",
       "        [-1.5744],\n",
       "        [ 0.5174],\n",
       "        [ 0.4893],\n",
       "        [ 0.0971],\n",
       "        [ 0.0665],\n",
       "        [-0.2463],\n",
       "        [ 0.4521],\n",
       "        [-0.1088],\n",
       "        [-0.3750],\n",
       "        [ 0.5011],\n",
       "        [ 0.9652],\n",
       "        [ 0.5198],\n",
       "        [ 0.6340],\n",
       "        [ 0.4329],\n",
       "        [ 0.1537],\n",
       "        [-0.2211],\n",
       "        [-0.0078],\n",
       "        [-0.0403],\n",
       "        [ 0.2637],\n",
       "        [ 0.1624],\n",
       "        [ 0.1011],\n",
       "        [-0.5398],\n",
       "        [ 0.7999],\n",
       "        [ 0.9517],\n",
       "        [-0.3057],\n",
       "        [-0.1696],\n",
       "        [ 0.3259],\n",
       "        [ 0.5407],\n",
       "        [ 0.5083],\n",
       "        [ 1.3331],\n",
       "        [ 0.2104],\n",
       "        [ 0.1063],\n",
       "        [ 0.5745],\n",
       "        [-0.3412],\n",
       "        [ 0.0910],\n",
       "        [-0.0569],\n",
       "        [-0.5507],\n",
       "        [-0.1600],\n",
       "        [ 0.7476],\n",
       "        [-0.8968],\n",
       "        [-0.4915],\n",
       "        [-0.9317],\n",
       "        [-0.0356],\n",
       "        [ 0.3928],\n",
       "        [ 0.4913],\n",
       "        [ 0.0528],\n",
       "        [ 0.1796],\n",
       "        [ 0.0453],\n",
       "        [ 0.5087],\n",
       "        [ 0.5455],\n",
       "        [ 0.7997],\n",
       "        [-0.1823],\n",
       "        [ 1.2479],\n",
       "        [ 0.5083],\n",
       "        [ 0.6709],\n",
       "        [ 1.0613],\n",
       "        [ 0.4975],\n",
       "        [ 0.5083],\n",
       "        [-0.4997],\n",
       "        [-0.9524],\n",
       "        [ 0.2954],\n",
       "        [ 0.1247],\n",
       "        [ 0.1075],\n",
       "        [ 0.0531],\n",
       "        [ 0.0834],\n",
       "        [-0.5209],\n",
       "        [-0.9118],\n",
       "        [ 0.4125],\n",
       "        [ 0.1783],\n",
       "        [ 0.9039],\n",
       "        [ 0.0716],\n",
       "        [ 1.3676],\n",
       "        [ 0.1214],\n",
       "        [ 1.0382],\n",
       "        [ 0.3763],\n",
       "        [ 0.5157],\n",
       "        [ 0.5407],\n",
       "        [ 0.6648],\n",
       "        [-0.6222],\n",
       "        [-1.0618],\n",
       "        [ 0.1028],\n",
       "        [-0.4760],\n",
       "        [ 0.9513],\n",
       "        [ 0.1345],\n",
       "        [ 0.2064],\n",
       "        [ 0.5051],\n",
       "        [ 0.4927],\n",
       "        [ 0.2299],\n",
       "        [ 0.6649],\n",
       "        [ 0.4582],\n",
       "        [-0.9632],\n",
       "        [ 0.3742],\n",
       "        [ 1.3598],\n",
       "        [-0.9237],\n",
       "        [ 0.8921],\n",
       "        [ 0.1392],\n",
       "        [ 0.1434],\n",
       "        [ 0.5045],\n",
       "        [-0.5154],\n",
       "        [ 0.1261],\n",
       "        [ 0.8916],\n",
       "        [ 0.9108],\n",
       "        [ 0.9310],\n",
       "        [-0.8048],\n",
       "        [-0.0322],\n",
       "        [ 0.5147],\n",
       "        [ 0.5157],\n",
       "        [ 0.1053],\n",
       "        [-1.5020],\n",
       "        [-0.1352],\n",
       "        [ 0.4715],\n",
       "        [ 0.4521],\n",
       "        [ 0.9415],\n",
       "        [ 0.5138],\n",
       "        [ 0.0800],\n",
       "        [ 0.3821],\n",
       "        [ 0.4392],\n",
       "        [ 0.4622],\n",
       "        [-0.2501],\n",
       "        [ 0.4715],\n",
       "        [ 0.5138],\n",
       "        [ 0.4819],\n",
       "        [ 0.1233],\n",
       "        [ 0.8036],\n",
       "        [ 0.2019],\n",
       "        [ 0.8616],\n",
       "        [ 0.5652],\n",
       "        [ 0.4609],\n",
       "        [-0.5951],\n",
       "        [-0.7353],\n",
       "        [ 0.1688],\n",
       "        [-0.9213],\n",
       "        [ 1.3213],\n",
       "        [ 0.4165],\n",
       "        [ 0.2005],\n",
       "        [ 0.0892],\n",
       "        [-0.0953],\n",
       "        [ 0.3470],\n",
       "        [ 0.1455],\n",
       "        [ 0.5121],\n",
       "        [ 0.5079],\n",
       "        [ 0.9073],\n",
       "        [ 1.2470],\n",
       "        [-0.2421],\n",
       "        [-0.6398],\n",
       "        [-0.3357],\n",
       "        [ 0.9439],\n",
       "        [ 0.8806],\n",
       "        [ 1.3307],\n",
       "        [ 0.4910],\n",
       "        [-0.9248],\n",
       "        [ 0.5312],\n",
       "        [-0.9372],\n",
       "        [-0.0023],\n",
       "        [ 0.1434],\n",
       "        [ 0.4192],\n",
       "        [ 0.4328],\n",
       "        [-0.5818],\n",
       "        [ 0.9304],\n",
       "        [ 0.1632],\n",
       "        [ 0.1193],\n",
       "        [ 0.1599],\n",
       "        [ 0.8244],\n",
       "        [ 0.5477],\n",
       "        [ 0.5079],\n",
       "        [ 1.3134],\n",
       "        [ 0.1015],\n",
       "        [ 0.1656],\n",
       "        [ 0.2087],\n",
       "        [-0.5887],\n",
       "        [ 0.5274],\n",
       "        [ 0.4763],\n",
       "        [ 0.5106],\n",
       "        [-0.8048],\n",
       "        [-0.1962],\n",
       "        [ 1.3598],\n",
       "        [ 0.5096],\n",
       "        [ 0.6282],\n",
       "        [ 0.1952],\n",
       "        [ 0.0187],\n",
       "        [-0.2865],\n",
       "        [-0.6188],\n",
       "        [-0.6585],\n",
       "        [ 0.8971],\n",
       "        [ 1.0430],\n",
       "        [-0.9372],\n",
       "        [-0.5423],\n",
       "        [-0.6150],\n",
       "        [-0.3310],\n",
       "        [ 0.7356],\n",
       "        [ 1.2090],\n",
       "        [ 0.8259],\n",
       "        [-0.5837],\n",
       "        [ 0.0720],\n",
       "        [ 0.8721],\n",
       "        [-0.5431],\n",
       "        [ 1.1068],\n",
       "        [-0.1702],\n",
       "        [ 0.2100],\n",
       "        [ 0.2039],\n",
       "        [ 0.4910],\n",
       "        [-0.8296],\n",
       "        [ 0.5507],\n",
       "        [ 0.5917],\n",
       "        [ 0.0842],\n",
       "        [-0.3884],\n",
       "        [-0.2082],\n",
       "        [ 0.2039],\n",
       "        [-0.8507],\n",
       "        [ 0.1358],\n",
       "        [-0.8558],\n",
       "        [ 0.7802],\n",
       "        [-1.3467],\n",
       "        [-0.6786],\n",
       "        [ 0.0720],\n",
       "        [ 0.0377],\n",
       "        [ 0.4274],\n",
       "        [-0.5585],\n",
       "        [ 0.4955],\n",
       "        [ 0.4188],\n",
       "        [-0.2099],\n",
       "        [ 0.0798],\n",
       "        [ 0.7495],\n",
       "        [ 0.1796],\n",
       "        [-0.2156],\n",
       "        [-0.4754],\n",
       "        [ 0.4673],\n",
       "        [-0.1099],\n",
       "        [ 0.2186],\n",
       "        [ 0.0791],\n",
       "        [-0.9287],\n",
       "        [ 0.9550],\n",
       "        [-1.3602],\n",
       "        [-0.1479],\n",
       "        [ 0.6340],\n",
       "        [ 0.2434],\n",
       "        [ 0.1025],\n",
       "        [-0.6334],\n",
       "        [-0.6176],\n",
       "        [ 0.5081],\n",
       "        [-1.2603],\n",
       "        [ 0.1851],\n",
       "        [ 0.2140],\n",
       "        [ 0.6412],\n",
       "        [ 0.4274],\n",
       "        [ 0.5529],\n",
       "        [ 0.1024],\n",
       "        [ 0.4842],\n",
       "        [ 0.5032],\n",
       "        [ 0.9411],\n",
       "        [ 0.9077],\n",
       "        [ 1.2779],\n",
       "        [ 0.1371],\n",
       "        [ 0.1199],\n",
       "        [ 0.1699],\n",
       "        [-0.8683],\n",
       "        [ 0.2394],\n",
       "        [-0.8867],\n",
       "        [ 0.8092],\n",
       "        [-1.3049],\n",
       "        [-0.1636],\n",
       "        [-0.3234],\n",
       "        [ 0.1159],\n",
       "        [-0.7800],\n",
       "        [ 0.1216],\n",
       "        [ 0.6115],\n",
       "        [ 0.6400],\n",
       "        [ 0.3944],\n",
       "        [ 1.3041],\n",
       "        [ 0.9665],\n",
       "        [ 0.5079],\n",
       "        [-0.3057],\n",
       "        [ 0.1371],\n",
       "        [-0.4309],\n",
       "        [ 0.9659],\n",
       "        [ 1.3984],\n",
       "        [-0.5260],\n",
       "        [ 0.1694],\n",
       "        [ 0.8501],\n",
       "        [-0.7981],\n",
       "        [-0.3885],\n",
       "        [ 0.5838],\n",
       "        [ 0.1383],\n",
       "        [ 0.4927],\n",
       "        [-0.8751],\n",
       "        [ 0.9202],\n",
       "        [ 0.2600],\n",
       "        [-0.9372],\n",
       "        [ 0.4250],\n",
       "        [-0.8048],\n",
       "        [ 1.0817],\n",
       "        [ 0.1761],\n",
       "        [ 0.5155],\n",
       "        [ 0.7222],\n",
       "        [-0.2230],\n",
       "        [ 0.2548],\n",
       "        [ 0.0639],\n",
       "        [ 0.0800],\n",
       "        [ 0.4328],\n",
       "        [-0.1706],\n",
       "        [ 0.5271],\n",
       "        [-0.0572],\n",
       "        [-0.8296],\n",
       "        [ 0.2485],\n",
       "        [ 0.5096],\n",
       "        [ 0.4910],\n",
       "        [-0.3410],\n",
       "        [ 0.4464],\n",
       "        [ 0.5103],\n",
       "        [ 0.1163],\n",
       "        [-0.1482],\n",
       "        [-0.1669],\n",
       "        [-0.8473],\n",
       "        [ 0.0289],\n",
       "        [ 0.5026],\n",
       "        [ 0.2764],\n",
       "        [ 0.1876],\n",
       "        [ 0.1434]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) # <1>\n",
    "optimizer = optim.SGD(\n",
    "    linear_model.parameters(), # <2>\n",
    "    lr=1e-2)\n",
    "\n",
    "linear_model(training_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000018EBFC45DD0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0917, -0.2094, -0.3707, -0.0933,  0.3584]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1606], requires_grad=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(linear_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, \n",
    "                  train_x, val_x,\n",
    "                  train_y, val_y, \n",
    "                  epoch_report = 1000):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_p = model(train_x) # <1>\n",
    "        loss_train = loss_fn(train_p, train_y)\n",
    "\n",
    "        val_p = model(val_x) # <1>\n",
    "        loss_val = loss_fn(val_p, val_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward() # <2>\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 1 or epoch % epoch_report == 0 or epoch == n_epochs:\n",
    "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
    "                  f\" Validation loss {loss_val.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Neural Network training with a single node\n",
    "nothign to grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 0.9578, Validation loss 0.9070\n",
      "Epoch 500, Training loss 0.4547, Validation loss 0.3775\n",
      "Epoch 1000, Training loss 0.4547, Validation loss 0.3776\n",
      "Epoch 1500, Training loss 0.4547, Validation loss 0.3776\n",
      "Epoch 2000, Training loss 0.4547, Validation loss 0.3776\n",
      "Epoch 2500, Training loss 0.4547, Validation loss 0.3776\n",
      "Epoch 3000, Training loss 0.4547, Validation loss 0.3776\n",
      "\n",
      "Weight Parameter containing:\n",
      "tensor([[0.3760, 0.0722, 0.3187, 0.2267, 0.1625]], requires_grad=True)\n",
      "Bias Parameter containing:\n",
      "tensor([-8.7716e-05], requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(5, 1) # <1>\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 3000, \n",
    "    optimizer = optimizer,\n",
    "    model = linear_model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 500\n",
    "    )\n",
    "\n",
    "print()\n",
    "print(\"Weight\", linear_model.weight)\n",
    "print(\"Bias\", linear_model.bias)\n",
    "\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning Sequential layer models\n",
    "nothing here to be graded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=22, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=22, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model_example = nn.Sequential(\n",
    "            nn.Linear(9, 22), # <1>\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(22, 3)) # <2>\n",
    "seq_model_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([22, 9]), torch.Size([22]), torch.Size([3, 22]), torch.Size([3])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param.shape for param in seq_model_example.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([22, 9])\n",
      "0.bias torch.Size([22])\n",
      "2.weight torch.Size([3, 22])\n",
      "2.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model_example.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_linear): Linear(in_features=1, out_features=8, bias=True)\n",
       "  (hidden_activation): Tanh()\n",
       "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "seq_model_example = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(1, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 1))\n",
    "]))\n",
    "\n",
    "seq_model_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([8, 1])\n",
      "hidden_linear.bias torch.Size([8])\n",
      "output_linear.weight torch.Size([1, 8])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model_example.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0245], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model_example.output_linear.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper training with a sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramater Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x:  torch.Size([436, 5])\n",
      "train_y:  torch.Size([436, 1])\n",
      "valid_x:  torch.Size([109, 5])\n",
      "valid_y:  torch.Size([109, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_x:  {training_x.shape}\")\n",
    "print(f\"train_y:  {training_y.shape}\")\n",
    "print(f\"valid_x:  {validation_x.shape}\")\n",
    "print(f\"valid_y:  {validation_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### example of single layer\n",
    "for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 0.7408, Validation loss 0.6298\n",
      "Epoch 25, Training loss 0.7165, Validation loss 0.6104\n",
      "Epoch 50, Training loss 0.6937, Validation loss 0.5921\n",
      "Epoch 75, Training loss 0.6732, Validation loss 0.5755\n",
      "Epoch 100, Training loss 0.6546, Validation loss 0.5604\n",
      "Epoch 125, Training loss 0.6378, Validation loss 0.5468\n",
      "Epoch 150, Training loss 0.6226, Validation loss 0.5343\n",
      "Epoch 175, Training loss 0.6088, Validation loss 0.5229\n",
      "Epoch 200, Training loss 0.5962, Validation loss 0.5125\n",
      "\n",
      "Weight Parameter containing:\n",
      "tensor([[0.3760, 0.0722, 0.3187, 0.2267, 0.1625]], requires_grad=True)\n",
      "Bias Parameter containing:\n",
      "tensor([-8.7716e-05], requires_grad=True)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "linear_model_0 = nn.Linear(5, 1)\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = linear_model_0\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y,  \n",
    "    epoch_report = 25)\n",
    "\n",
    "print()\n",
    "print(\"Weight\", linear_model.weight)\n",
    "print(\"Bias\", linear_model.bias)\n",
    "\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a\n",
    "1 hidden layer with 8 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.4462, Validation loss 1.5959\n",
      "Epoch 25, Training loss 1.3866, Validation loss 1.5307\n",
      "Epoch 50, Training loss 1.3314, Validation loss 1.4702\n",
      "Epoch 75, Training loss 1.2823, Validation loss 1.4159\n",
      "Epoch 100, Training loss 1.2382, Validation loss 1.3670\n",
      "Epoch 125, Training loss 1.1984, Validation loss 1.3226\n",
      "Epoch 150, Training loss 1.1621, Validation loss 1.2820\n",
      "Epoch 175, Training loss 1.1289, Validation loss 1.2446\n",
      "Epoch 200, Training loss 1.0983, Validation loss 1.2101\n"
     ]
    }
   ],
   "source": [
    "seq_model_1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear', nn.Linear(5, 8)),\n",
    "    ('hidden_activation', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(8, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = seq_model_1\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b\n",
    "add 2 more hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0654, Validation loss 1.1568\n",
      "Epoch 25, Training loss 1.0403, Validation loss 1.1277\n",
      "Epoch 50, Training loss 1.0161, Validation loss 1.0995\n",
      "Epoch 75, Training loss 0.9933, Validation loss 1.0730\n",
      "Epoch 100, Training loss 0.9719, Validation loss 1.0479\n",
      "Epoch 125, Training loss 0.9515, Validation loss 1.0241\n",
      "Epoch 150, Training loss 0.9321, Validation loss 1.0013\n",
      "Epoch 175, Training loss 0.9135, Validation loss 0.9794\n",
      "Epoch 200, Training loss 0.8955, Validation loss 0.9583\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "\n",
    "seq_model_2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', nn.Tanh()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', nn.Tanh()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = seq_model_2\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0803, Validation loss 1.1498\n",
      "Epoch 25, Training loss 1.0479, Validation loss 1.1172\n",
      "Epoch 50, Training loss 1.0180, Validation loss 1.0868\n",
      "Epoch 75, Training loss 0.9912, Validation loss 1.0594\n",
      "Epoch 100, Training loss 0.9670, Validation loss 1.0345\n",
      "Epoch 125, Training loss 0.9449, Validation loss 1.0116\n",
      "Epoch 150, Training loss 0.9245, Validation loss 0.9903\n",
      "Epoch 175, Training loss 0.9056, Validation loss 0.9703\n",
      "Epoch 200, Training loss 0.8878, Validation loss 0.9514\n"
     ]
    }
   ],
   "source": [
    "a = 20\n",
    "b = 15\n",
    "c = 10\n",
    "\n",
    "seq_model_3 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', nn.Tanh()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', nn.Tanh()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = seq_model_3\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 0.9756, Validation loss 1.0590\n",
      "Epoch 25, Training loss 0.9478, Validation loss 1.0297\n",
      "Epoch 50, Training loss 0.9204, Validation loss 1.0008\n",
      "Epoch 75, Training loss 0.8945, Validation loss 0.9732\n",
      "Epoch 100, Training loss 0.8698, Validation loss 0.9467\n",
      "Epoch 125, Training loss 0.8462, Validation loss 0.9211\n",
      "Epoch 150, Training loss 0.8234, Validation loss 0.8964\n",
      "Epoch 175, Training loss 0.8014, Validation loss 0.8723\n",
      "Epoch 200, Training loss 0.7802, Validation loss 0.8489\n"
     ]
    }
   ],
   "source": [
    "a = 20\n",
    "b = 15\n",
    "c = 10\n",
    "\n",
    "seq_model_4 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', nn.Tanh()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', nn.Tanh()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', nn.Tanh()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = seq_model_4\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in activation\n",
    "for personal testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in activation\n",
    "for personal testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.1705, Validation loss 1.2562\n",
      "Epoch 25, Training loss 1.1205, Validation loss 1.2063\n",
      "Epoch 50, Training loss 1.0825, Validation loss 1.1684\n",
      "Epoch 75, Training loss 1.0550, Validation loss 1.1409\n",
      "Epoch 100, Training loss 1.0350, Validation loss 1.1210\n",
      "Epoch 125, Training loss 1.0205, Validation loss 1.1066\n",
      "Epoch 150, Training loss 1.0100, Validation loss 1.0961\n",
      "Epoch 175, Training loss 1.0023, Validation loss 1.0885\n",
      "Epoch 200, Training loss 0.9968, Validation loss 1.0830\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "activation = nn.Sigmoid\n",
    "\n",
    "sigmoid_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', activation()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', activation()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', activation()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = sigmoid_model\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0820, Validation loss 1.1854\n",
      "Epoch 25, Training loss 1.0688, Validation loss 1.1711\n",
      "Epoch 50, Training loss 1.0570, Validation loss 1.1580\n",
      "Epoch 75, Training loss 1.0468, Validation loss 1.1467\n",
      "Epoch 100, Training loss 1.0378, Validation loss 1.1366\n",
      "Epoch 125, Training loss 1.0298, Validation loss 1.1276\n",
      "Epoch 150, Training loss 1.0228, Validation loss 1.1195\n",
      "Epoch 175, Training loss 1.0164, Validation loss 1.1121\n",
      "Epoch 200, Training loss 1.0104, Validation loss 1.1053\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "activation = nn.ReLU\n",
    "\n",
    "sigmoid_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', activation()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', activation()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', activation()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = sigmoid_model\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leaky RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.1113, Validation loss 1.2064\n",
      "Epoch 25, Training loss 1.0891, Validation loss 1.1833\n",
      "Epoch 50, Training loss 1.0688, Validation loss 1.1620\n",
      "Epoch 75, Training loss 1.0510, Validation loss 1.1433\n",
      "Epoch 100, Training loss 1.0354, Validation loss 1.1268\n",
      "Epoch 125, Training loss 1.0216, Validation loss 1.1122\n",
      "Epoch 150, Training loss 1.0096, Validation loss 1.0994\n",
      "Epoch 175, Training loss 0.9990, Validation loss 1.0881\n",
      "Epoch 200, Training loss 0.9897, Validation loss 1.0780\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "activation = nn.LeakyReLU\n",
    "\n",
    "sigmoid_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', activation()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', activation()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', activation()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = sigmoid_model\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RELU 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 0.9809, Validation loss 1.0655\n",
      "Epoch 25, Training loss 0.9802, Validation loss 1.0648\n",
      "Epoch 50, Training loss 0.9796, Validation loss 1.0641\n",
      "Epoch 75, Training loss 0.9790, Validation loss 1.0634\n",
      "Epoch 100, Training loss 0.9784, Validation loss 1.0628\n",
      "Epoch 125, Training loss 0.9778, Validation loss 1.0621\n",
      "Epoch 150, Training loss 0.9772, Validation loss 1.0614\n",
      "Epoch 175, Training loss 0.9766, Validation loss 1.0607\n",
      "Epoch 200, Training loss 0.9759, Validation loss 1.0600\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "activation = nn.ReLU6\n",
    "\n",
    "sigmoid_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', activation()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', activation()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', activation()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = sigmoid_model\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0497, Validation loss 1.1426\n",
      "Epoch 25, Training loss 1.0300, Validation loss 1.1211\n",
      "Epoch 50, Training loss 1.0111, Validation loss 1.1001\n",
      "Epoch 75, Training loss 0.9935, Validation loss 1.0804\n",
      "Epoch 100, Training loss 0.9769, Validation loss 1.0616\n",
      "Epoch 125, Training loss 0.9611, Validation loss 1.0436\n",
      "Epoch 150, Training loss 0.9459, Validation loss 1.0261\n",
      "Epoch 175, Training loss 0.9312, Validation loss 1.0091\n",
      "Epoch 200, Training loss 0.9169, Validation loss 0.9924\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "activation = nn.ELU\n",
    "\n",
    "sigmoid_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', activation()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', activation()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', activation()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = sigmoid_model\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardsigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0054, Validation loss 1.0917\n",
      "Epoch 25, Training loss 0.9996, Validation loss 1.0859\n",
      "Epoch 50, Training loss 0.9951, Validation loss 1.0814\n",
      "Epoch 75, Training loss 0.9918, Validation loss 1.0781\n",
      "Epoch 100, Training loss 0.9894, Validation loss 1.0758\n",
      "Epoch 125, Training loss 0.9876, Validation loss 1.0740\n",
      "Epoch 150, Training loss 0.9863, Validation loss 1.0727\n",
      "Epoch 175, Training loss 0.9853, Validation loss 1.0718\n",
      "Epoch 200, Training loss 0.9846, Validation loss 1.0711\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "activation = nn.Hardsigmoid\n",
    "\n",
    "sigmoid_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', activation()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', activation()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', activation()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = sigmoid_model\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hardtanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.0800, Validation loss 1.1891\n",
      "Epoch 25, Training loss 1.0285, Validation loss 1.1367\n",
      "Epoch 50, Training loss 0.9810, Validation loss 1.0882\n",
      "Epoch 75, Training loss 0.9384, Validation loss 1.0447\n",
      "Epoch 100, Training loss 0.8999, Validation loss 1.0051\n",
      "Epoch 125, Training loss 0.8647, Validation loss 0.9687\n",
      "Epoch 150, Training loss 0.8323, Validation loss 0.9351\n",
      "Epoch 175, Training loss 0.8023, Validation loss 0.9038\n",
      "Epoch 200, Training loss 0.7745, Validation loss 0.8747\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "activation = nn.Hardtanh\n",
    "\n",
    "sigmoid_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', activation()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', activation()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', activation()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = sigmoid_model\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softsign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 0.9750, Validation loss 1.0614\n",
      "Epoch 25, Training loss 0.9726, Validation loss 1.0588\n",
      "Epoch 50, Training loss 0.9701, Validation loss 1.0561\n",
      "Epoch 75, Training loss 0.9677, Validation loss 1.0534\n",
      "Epoch 100, Training loss 0.9652, Validation loss 1.0507\n",
      "Epoch 125, Training loss 0.9628, Validation loss 1.0480\n",
      "Epoch 150, Training loss 0.9604, Validation loss 1.0453\n",
      "Epoch 175, Training loss 0.9579, Validation loss 1.0426\n",
      "Epoch 200, Training loss 0.9555, Validation loss 1.0399\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "c = 8\n",
    "activation = nn.Softsign\n",
    "\n",
    "sigmoid_model = nn.Sequential(OrderedDict([\n",
    "    ('hidden_linear_1', nn.Linear(5, a)),\n",
    "    ('hidden_activation_1', activation()),\n",
    "    ('hidden_linear_2', nn.Linear(a, b)),\n",
    "    ('hidden_activation_2', activation()),\n",
    "    ('hidden_linear_3', nn.Linear(b, c)),\n",
    "    ('hidden_activation_3', activation()),\n",
    "    ('output_linear', nn.Linear(c, 1))\n",
    "]))\n",
    "\n",
    "# -------------------- #\n",
    "\n",
    "model = sigmoid_model\n",
    "models.append(model)\n",
    "\n",
    "model.zero_grad()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "optimizer.zero_grad()\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 200, \n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss,\n",
    "    train_x = training_x,\n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y, \n",
    "    epoch_report = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of ALL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=5, out_features=1, bias=True)\n",
      "\n",
      "     Validation Loss: 0.5120754837989807\n",
      "\n",
      "     weight  \t:  torch.Size([1, 5])\n",
      "     bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear): Linear(in_features=5, out_features=8, bias=True)\n",
      "  (hidden_activation): Tanh()\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 1.2087867259979248\n",
      "\n",
      "     hidden_linear.weight  \t:  torch.Size([8, 5])\n",
      "     hidden_linear.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation_1): Tanh()\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_activation_2): Tanh()\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (hidden_activation_3): Tanh()\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 0.957441508769989\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=20, bias=True)\n",
      "  (hidden_activation_1): Tanh()\n",
      "  (hidden_linear_2): Linear(in_features=20, out_features=15, bias=True)\n",
      "  (hidden_activation_2): Tanh()\n",
      "  (hidden_linear_3): Linear(in_features=15, out_features=10, bias=True)\n",
      "  (hidden_activation_3): Tanh()\n",
      "  (output_linear): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 0.9506984353065491\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([20, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([20])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([15, 20])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([15])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([10, 15])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([10])\n",
      "     output_linear.weight  \t:  torch.Size([1, 10])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=20, bias=True)\n",
      "  (hidden_activation_1): Tanh()\n",
      "  (hidden_linear_2): Linear(in_features=20, out_features=15, bias=True)\n",
      "  (hidden_activation_2): Tanh()\n",
      "  (hidden_linear_3): Linear(in_features=15, out_features=10, bias=True)\n",
      "  (hidden_activation_3): Tanh()\n",
      "  (output_linear): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 0.8479285836219788\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([20, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([20])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([15, 20])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([15])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([10, 15])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([10])\n",
      "     output_linear.weight  \t:  torch.Size([1, 10])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation_1): Sigmoid()\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_activation_2): Sigmoid()\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (hidden_activation_3): Sigmoid()\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 1.082815170288086\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation_1): ReLU()\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_activation_2): ReLU()\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (hidden_activation_3): ReLU()\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 1.1049891710281372\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation_1): LeakyReLU(negative_slope=0.01)\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_activation_2): LeakyReLU(negative_slope=0.01)\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (hidden_activation_3): LeakyReLU(negative_slope=0.01)\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 1.0775953531265259\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation_1): ReLU6()\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_activation_2): ReLU6()\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (hidden_activation_3): ReLU6()\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 1.0599600076675415\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation_1): ELU(alpha=1.0)\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_activation_2): ELU(alpha=1.0)\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (hidden_activation_3): ELU(alpha=1.0)\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 0.9917411208152771\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation_1): Hardsigmoid()\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_activation_2): Hardsigmoid()\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (hidden_activation_3): Hardsigmoid()\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 1.0710723400115967\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation_1): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_activation_2): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (hidden_activation_3): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 0.8735508918762207\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (hidden_linear_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (hidden_activation_1): Softsign()\n",
      "  (hidden_linear_2): Linear(in_features=10, out_features=25, bias=True)\n",
      "  (hidden_activation_2): Softsign()\n",
      "  (hidden_linear_3): Linear(in_features=25, out_features=8, bias=True)\n",
      "  (hidden_activation_3): Softsign()\n",
      "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "     Validation Loss: 1.039789080619812\n",
      "\n",
      "     hidden_linear_1.weight  \t:  torch.Size([10, 5])\n",
      "     hidden_linear_1.bias  \t:  torch.Size([10])\n",
      "     hidden_linear_2.weight  \t:  torch.Size([25, 10])\n",
      "     hidden_linear_2.bias  \t:  torch.Size([25])\n",
      "     hidden_linear_3.weight  \t:  torch.Size([8, 25])\n",
      "     hidden_linear_3.bias  \t:  torch.Size([8])\n",
      "     output_linear.weight  \t:  torch.Size([1, 8])\n",
      "     output_linear.bias  \t:  torch.Size([1])\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'{model}\\n')\n",
    "        \n",
    "    predictions = model(validation_x) \n",
    "    loss = loss_fn(predictions, validation_y)\n",
    "    print(f'     Validation Loss: {loss}\\n')\n",
    "        \n",
    "    for name, param in model.named_parameters():\n",
    "        print(f'     {name}  \\t: ', param.shape)\n",
    "        # print(f'     {name}  \\t: ', param.shape)\n",
    "        \n",
    "    print('\\n' + '-'*90 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77aa5c7a8032890130e9a412da4828609b1dfa25c62620094c03af7a5cea44b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
