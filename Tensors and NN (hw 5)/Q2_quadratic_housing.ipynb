{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5 Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## define model and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_for_validation = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature, w5, w4, w3, w2, w1, b):\n",
    "    return feature[4] * w5 + feature[3] * w4 + feature[2] * w3 + feature[1] * w2 + feature[0] * w1 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(predicted, actual):\n",
    "    squared_diffs = (predicted - actual)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.01, 0.001, 0.0001, 1e-05]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_to_learn_at = [1/x for x in [10, 100, 1000, 10000, 100000]]\n",
    "rates_to_learn_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(pd.read_csv('Housing.csv'))\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = (545, 13)\n",
      "features are: ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape = {np.shape(housing_df)}\")\n",
    "\n",
    "# creates a list of all variables from the column names\n",
    "feature_list = list( housing_df.columns )\n",
    "\n",
    "print(f\"features are: {feature_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary vars = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
      "furnish vars = ['furnishingstatus']\n",
      "value vars = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n"
     ]
    }
   ],
   "source": [
    "# Maps to turn categorys into numbers \n",
    "def boolean_map(x):\n",
    "    return x.map({'yes': 1 , 'no': 0})\n",
    "def furnish_map(x):\n",
    "    return x.map({'furnished': 1 , 'semi-furnished': 0.5 , 'unfurnished': 0})\n",
    "\n",
    "# Extracts the yes and no column names\n",
    "binary_vars = [*feature_list[5:10], feature_list[11]]\n",
    "print(f\"binary vars = {binary_vars}\")\n",
    "\n",
    "# Extracts the furnishing column names\n",
    "furnish_vars = [feature_list[12]]\n",
    "print(f\"furnish vars = {furnish_vars}\")\n",
    "\n",
    "# Extracts the column names that are actual values\n",
    "valued_vars = feature_list.copy()\n",
    "[valued_vars.remove( item ) for item in binary_vars]\n",
    "[valued_vars.remove( item ) for item in furnish_vars]\n",
    "print(f\"value vars = {valued_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = housing_df.copy()\n",
    "\n",
    "## scale data\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "x_df[valued_vars] = scaler.fit_transform(x_df[valued_vars])\n",
    "\n",
    "## map text values\n",
    "x_df[binary_vars] = x_df[binary_vars].apply(boolean_map)\n",
    "x_df[furnish_vars] = x_df[furnish_vars].apply(furnish_map)\n",
    "\n",
    "## make y_df\n",
    "y_df = x_df.pop('price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_values = valued_vars.copy()\n",
    "# input_values.remove('price')\n",
    "\n",
    "\n",
    "# x_df = x_df[input_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories  mainroad  guestroom  basement  \\\n",
       "0  1.046726  1.403419   1.421812  1.378217         1          0         0   \n",
       "1  1.757010  1.403419   5.405809  2.532024         1          0         0   \n",
       "2  2.218232  0.047278   1.421812  0.224410         1          0         1   \n",
       "3  1.083624  1.403419   1.421812  0.224410         1          0         1   \n",
       "4  1.046726  1.403419  -0.570187  0.224410         1          1         1   \n",
       "\n",
       "   hotwaterheating  airconditioning   parking  prefarea  furnishingstatus  \n",
       "0                0                1  1.517692         1               1.0  \n",
       "1                0                1  2.679409         0               1.0  \n",
       "2                0                0  1.517692         1               0.5  \n",
       "3                0                1  2.679409         1               1.0  \n",
       "4                0                1  1.517692         0               1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.566365\n",
       "1    4.004484\n",
       "2    4.004484\n",
       "3    3.985755\n",
       "4    3.554979\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories   parking\n",
       "0  1.046726  1.403419   1.421812  1.378217  1.517692\n",
       "1  1.757010  1.403419   5.405809  2.532024  2.679409\n",
       "2  2.218232  0.047278   1.421812  0.224410  1.517692\n",
       "3  1.083624  1.403419   1.421812  0.224410  2.679409\n",
       "4  1.046726  1.403419  -0.570187  0.224410  1.517692"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted data\n",
    "for item in [*binary_vars, *furnish_vars] :\n",
    "    x_df.pop(item)\n",
    "x_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## convert data to tensor and test accessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frame to tensor\n",
    "\n",
    "x = torch.tensor(x_df.values)\n",
    "y = torch.tensor(y_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([545, 5])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0467,  1.4034,  ...,  1.3782,  1.5177],\n",
       "        [ 1.7570,  1.4034,  ...,  2.5320,  2.6794],\n",
       "        ...,\n",
       "        [-1.0334,  0.0473,  ..., -0.9294, -0.8057],\n",
       "        [-0.5998,  0.0473,  ...,  0.2244, -0.8057]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(\"\\n\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([545])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5664e+00,  4.0045e+00,  4.0045e+00,  3.9858e+00,  3.5550e+00,\n",
       "         3.2553e+00,  2.8807e+00,  2.8807e+00,  2.7309e+00,  2.6934e+00,\n",
       "         2.6934e+00,  2.6297e+00,  2.4312e+00,  2.3938e+00,  2.3938e+00,\n",
       "         2.3188e+00,  2.3188e+00,  2.2439e+00,  2.2065e+00,  2.1877e+00,\n",
       "         2.1315e+00,  2.0941e+00,  2.0754e+00,  2.0754e+00,  2.0379e+00,\n",
       "         2.0192e+00,  1.9780e+00,  1.9443e+00,  1.9443e+00,  1.9443e+00,\n",
       "         1.9443e+00,  1.9443e+00,  1.8881e+00,  1.8319e+00,  1.7944e+00,\n",
       "         1.7735e+00,  1.7532e+00,  1.7195e+00,  1.7101e+00,  1.6820e+00,\n",
       "         1.6633e+00,  1.6446e+00,  1.5697e+00,  1.5697e+00,  1.4947e+00,\n",
       "         1.4947e+00,  1.4760e+00,  1.4573e+00,  1.4386e+00,  1.4198e+00,\n",
       "         1.4198e+00,  1.4198e+00,  1.3824e+00,  1.3824e+00,  1.3824e+00,\n",
       "         1.3824e+00,  1.3786e+00,  1.3262e+00,  1.3075e+00,  1.3075e+00,\n",
       "         1.2700e+00,  1.2325e+00,  1.2325e+00,  1.2138e+00,  1.1951e+00,\n",
       "         1.1576e+00,  1.1576e+00,  1.1389e+00,  1.1202e+00,  1.0827e+00,\n",
       "         1.0827e+00,  1.0640e+00,  1.0452e+00,  1.0265e+00,  1.0078e+00,\n",
       "         1.0078e+00,  1.0078e+00,  1.0078e+00,  1.0078e+00,  1.0078e+00,\n",
       "         9.9655e-01,  9.8906e-01,  9.8906e-01,  9.7033e-01,  9.3287e-01,\n",
       "         9.3287e-01,  9.3287e-01,  9.1414e-01,  9.1414e-01,  8.9541e-01,\n",
       "         8.9541e-01,  8.8417e-01,  8.7668e-01,  8.2049e-01,  8.2049e-01,\n",
       "         8.2049e-01,  8.2049e-01,  8.2049e-01,  8.1675e-01,  8.0176e-01,\n",
       "         7.8303e-01,  7.8303e-01,  7.6430e-01,  7.6430e-01,  7.6430e-01,\n",
       "         7.4557e-01,  7.4557e-01,  7.2684e-01,  7.1748e-01,  7.0812e-01,\n",
       "         7.0812e-01,  7.0812e-01,  7.0437e-01,  7.0437e-01,  6.7066e-01,\n",
       "         6.7066e-01,  6.7066e-01,  6.3320e-01,  6.3320e-01,  6.3320e-01,\n",
       "         6.3320e-01,  6.3320e-01,  6.3320e-01,  6.3320e-01,  6.3320e-01,\n",
       "         6.2945e-01,  5.9574e-01,  5.9574e-01,  5.9199e-01,  5.9199e-01,\n",
       "         5.8825e-01,  5.5828e-01,  5.5828e-01,  5.5828e-01,  5.5453e-01,\n",
       "         5.3955e-01,  5.2082e-01,  5.2082e-01,  5.2082e-01,  5.2082e-01,\n",
       "         5.2082e-01,  4.7400e-01,  4.4590e-01,  4.4590e-01,  4.4590e-01,\n",
       "         4.4590e-01,  4.4590e-01,  4.4590e-01,  4.4590e-01,  4.4590e-01,\n",
       "         4.4590e-01,  4.2717e-01,  4.2717e-01,  4.0845e-01,  4.0845e-01,\n",
       "         4.0845e-01,  4.0470e-01,  3.8972e-01,  3.8972e-01,  3.7099e-01,\n",
       "         3.7099e-01,  3.7099e-01,  3.7099e-01,  3.5226e-01,  3.3353e-01,\n",
       "         3.2978e-01,  2.9607e-01,  2.7734e-01,  2.5861e-01,  2.5861e-01,\n",
       "         2.5861e-01,  2.5861e-01,  2.5861e-01,  2.5861e-01,  2.5861e-01,\n",
       "         2.5861e-01,  2.5861e-01,  2.5486e-01,  2.4737e-01,  2.3988e-01,\n",
       "         2.3988e-01,  2.3988e-01,  2.0242e-01,  2.0242e-01,  1.8369e-01,\n",
       "         1.8369e-01,  1.8369e-01,  1.8369e-01,  1.6496e-01,  1.4623e-01,\n",
       "         1.4623e-01,  1.4623e-01,  1.4623e-01,  1.4249e-01,  1.2750e-01,\n",
       "         1.0878e-01,  1.0878e-01,  1.0128e-01,  9.0046e-02,  7.5062e-02,\n",
       "         7.1316e-02,  7.1316e-02,  7.1316e-02,  7.1316e-02,  7.1316e-02,\n",
       "         7.1316e-02,  7.1316e-02,  7.1316e-02,  7.1316e-02,  7.1316e-02,\n",
       "         7.1316e-02,  7.1316e-02,  6.7571e-02,  6.7571e-02,  5.2587e-02,\n",
       "         3.3858e-02,  3.3858e-02,  3.3858e-02,  3.3858e-02,  1.5128e-02,\n",
       "         1.5128e-02,  1.4489e-04, -3.6010e-03, -3.6010e-03, -3.6010e-03,\n",
       "        -7.3469e-03, -4.1060e-02, -4.1060e-02, -4.1060e-02, -4.1060e-02,\n",
       "        -4.1060e-02, -4.1060e-02, -5.9789e-02, -7.8518e-02, -7.8518e-02,\n",
       "        -7.8518e-02, -7.8518e-02, -7.8518e-02, -8.2264e-02, -9.7248e-02,\n",
       "        -9.7248e-02, -1.1598e-01, -1.1598e-01, -1.1598e-01, -1.1598e-01,\n",
       "        -1.1598e-01, -1.1598e-01, -1.1598e-01, -1.1972e-01, -1.1972e-01,\n",
       "        -1.3471e-01, -1.3471e-01, -1.3471e-01, -1.3471e-01, -1.5344e-01,\n",
       "        -1.5344e-01, -1.5344e-01, -1.5344e-01, -1.5344e-01, -1.5718e-01,\n",
       "        -1.5718e-01, -1.5718e-01, -1.7217e-01, -1.9089e-01, -1.9089e-01,\n",
       "        -1.9464e-01, -1.9464e-01, -1.9464e-01, -2.0588e-01, -2.0962e-01,\n",
       "        -2.2835e-01, -2.2835e-01, -2.2835e-01, -2.2835e-01, -2.2835e-01,\n",
       "        -2.3959e-01, -2.4708e-01, -2.4708e-01, -2.6207e-01, -2.6581e-01,\n",
       "        -2.6581e-01, -2.6581e-01, -2.6581e-01, -2.6581e-01, -2.6581e-01,\n",
       "        -2.8454e-01, -2.8454e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01,\n",
       "        -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01,\n",
       "        -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01,\n",
       "        -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0702e-01,\n",
       "        -3.0702e-01, -3.2200e-01, -3.2200e-01, -3.2200e-01, -3.4073e-01,\n",
       "        -3.4073e-01, -3.4448e-01, -3.5759e-01, -3.5946e-01, -3.5946e-01,\n",
       "        -3.5946e-01, -3.7819e-01, -3.7819e-01, -3.7819e-01, -3.7819e-01,\n",
       "        -3.7819e-01, -3.9692e-01, -3.9692e-01, -3.9692e-01, -4.0628e-01,\n",
       "        -4.0628e-01, -4.1565e-01, -4.1565e-01, -4.1565e-01, -4.1565e-01,\n",
       "        -4.1565e-01, -4.5311e-01, -4.5311e-01, -4.5311e-01, -4.5311e-01,\n",
       "        -4.5311e-01, -4.5311e-01, -4.5311e-01, -4.7184e-01, -4.7184e-01,\n",
       "        -4.9056e-01, -4.9056e-01, -4.9056e-01, -4.9056e-01, -4.9056e-01,\n",
       "        -4.9056e-01, -4.9056e-01, -4.9806e-01, -5.0929e-01, -5.2802e-01,\n",
       "        -5.2802e-01, -5.2802e-01, -5.2802e-01, -5.2802e-01, -5.2802e-01,\n",
       "        -5.3177e-01, -5.3177e-01, -5.3177e-01, -5.4675e-01, -5.6548e-01,\n",
       "        -5.6548e-01, -5.6548e-01, -5.6548e-01, -5.6548e-01, -5.6923e-01,\n",
       "        -5.6923e-01, -5.8421e-01, -5.8421e-01, -5.8421e-01, -5.8421e-01,\n",
       "        -6.0294e-01, -6.0294e-01, -6.0294e-01, -6.0294e-01, -6.0294e-01,\n",
       "        -6.0294e-01, -6.0294e-01, -6.0294e-01, -6.0294e-01, -6.0669e-01,\n",
       "        -6.2167e-01, -6.2167e-01, -6.4040e-01, -6.4040e-01, -6.4040e-01,\n",
       "        -6.4040e-01, -6.5913e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01,\n",
       "        -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01,\n",
       "        -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01,\n",
       "        -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.8160e-01,\n",
       "        -6.9659e-01, -6.9659e-01, -6.9659e-01, -7.1532e-01, -7.1532e-01,\n",
       "        -7.1532e-01, -7.1532e-01, -7.1532e-01, -7.1532e-01, -7.1906e-01,\n",
       "        -7.3405e-01, -7.3405e-01, -7.3405e-01, -7.5278e-01, -7.5278e-01,\n",
       "        -7.5278e-01, -7.5278e-01, -7.5278e-01, -7.5278e-01, -7.5278e-01,\n",
       "        -7.5278e-01, -7.5652e-01, -7.6776e-01, -7.7151e-01, -7.7151e-01,\n",
       "        -7.9023e-01, -7.9023e-01, -7.9023e-01, -7.9023e-01, -7.9023e-01,\n",
       "        -7.9023e-01, -7.9023e-01, -7.9023e-01, -8.0896e-01, -8.0896e-01,\n",
       "        -8.2020e-01, -8.2769e-01, -8.2769e-01, -8.2769e-01, -8.2769e-01,\n",
       "        -8.6515e-01, -8.6515e-01, -8.6515e-01, -8.6515e-01, -8.6515e-01,\n",
       "        -8.6515e-01, -8.6515e-01, -8.6515e-01, -8.6515e-01, -8.6890e-01,\n",
       "        -8.7639e-01, -8.8182e-01, -8.8388e-01, -8.8388e-01, -8.8388e-01,\n",
       "        -8.9886e-01, -9.0261e-01, -9.0261e-01, -9.0261e-01, -9.0261e-01,\n",
       "        -9.2134e-01, -9.4007e-01, -9.4007e-01, -9.4007e-01, -9.4007e-01,\n",
       "        -9.4007e-01, -9.4007e-01, -9.4007e-01, -9.4382e-01, -9.5880e-01,\n",
       "        -9.6629e-01, -9.7753e-01, -9.7753e-01, -9.7753e-01, -9.7753e-01,\n",
       "        -9.7753e-01, -9.7753e-01, -9.7753e-01, -9.7753e-01, -1.0150e+00,\n",
       "        -1.0150e+00, -1.0150e+00, -1.0150e+00, -1.0244e+00, -1.0337e+00,\n",
       "        -1.0337e+00, -1.0337e+00, -1.0524e+00, -1.0524e+00, -1.0899e+00,\n",
       "        -1.0899e+00, -1.1086e+00, -1.1274e+00, -1.1274e+00, -1.1274e+00,\n",
       "        -1.1274e+00, -1.1274e+00, -1.1274e+00, -1.1274e+00, -1.1311e+00,\n",
       "        -1.1311e+00, -1.1573e+00, -1.1648e+00, -1.1648e+00, -1.1648e+00,\n",
       "        -1.2023e+00, -1.2023e+00, -1.2023e+00, -1.2210e+00, -1.2210e+00,\n",
       "        -1.2397e+00, -1.2397e+00, -1.2397e+00, -1.2397e+00, -1.2397e+00,\n",
       "        -1.2397e+00, -1.2622e+00, -1.2772e+00, -1.2772e+00, -1.2772e+00,\n",
       "        -1.2959e+00, -1.3147e+00, -1.3334e+00, -1.3334e+00, -1.3334e+00,\n",
       "        -1.3521e+00, -1.3559e+00, -1.4083e+00, -1.4270e+00, -1.4270e+00,\n",
       "        -1.4270e+00, -1.5020e+00, -1.5394e+00, -1.5394e+00, -1.5581e+00,\n",
       "        -1.5769e+00, -1.6051e+00, -1.6143e+00, -1.6143e+00, -1.6143e+00],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(\"\\n\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7570, dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4034, dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0467, 1.4034, 1.4218, 1.3782, 1.5177], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0467, 1.4034, 1.4218, 1.3782, 1.5177], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 545])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x.transpose(-2, 1)\n",
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4034,  1.4034,  0.0473,  1.4034,  1.4034,  0.0473,  1.4034,\n",
       "         2.7596,  1.4034,  0.0473,  0.0473,  1.4034,  1.4034,  1.4034,\n",
       "         0.0473,  1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         2.7596,  1.4034,  0.0473,  0.0473,  1.4034,  0.0473,  2.7596,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  0.0473,\n",
       "         1.4034,  1.4034,  1.4034,  0.0473,  0.0473, -1.3089,  1.4034,\n",
       "         1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  0.0473,  1.4034,\n",
       "         0.0473,  1.4034,  0.0473, -1.3089,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  2.7596,  0.0473,\n",
       "        -1.3089,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         4.1157,  0.0473, -1.3089,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  1.4034,  2.7596,  1.4034,  0.0473, -1.3089,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  1.4034,  2.7596,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  1.4034,\n",
       "         0.0473,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,\n",
       "         1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089,  1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  1.4034,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,\n",
       "         1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034,  1.4034, -1.3089,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  1.4034, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034, -1.3089,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  1.4034, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  2.7596,  0.0473,\n",
       "         1.4034,  1.4034, -1.3089, -1.3089, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473, -1.3089,  1.4034,  0.0473,  1.4034, -1.3089,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473, -1.3089,  0.0473,  0.0473, -1.3089,\n",
       "        -1.3089,  1.4034,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  0.0473, -1.3089, -1.3089,\n",
       "         0.0473,  1.4034, -1.3089,  1.4034,  2.7596, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  2.7596,\n",
       "         1.4034, -1.3089,  0.0473, -1.3089,  0.0473, -1.3089, -1.3089,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089, -1.3089, -1.3089, -1.3089,\n",
       "         0.0473,  0.0473, -1.3089, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473, -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  4.1157, -1.3089, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473, -1.3089, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -1.3089,  1.4034,  1.4034,\n",
       "        -1.3089, -1.3089, -1.3089,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089,  1.4034, -1.3089,  1.4034,  0.0473,  1.4034,\n",
       "         1.4034, -1.3089,  0.0473,  0.0473, -1.3089, -1.3089,  1.4034,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -2.6650, -1.3089, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473, -1.3089, -1.3089, -1.3089,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089,  0.0473,  0.0473, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473,  1.4034, -1.3089,  1.4034, -1.3089,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089,  1.4034,  1.4034,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "        -1.3089,  0.0473, -1.3089, -1.3089, -1.3089, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473,  0.0473, -1.3089, -1.3089,\n",
       "        -1.3089, -1.3089, -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "        -1.3089, -1.3089, -1.3089, -2.6650,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473,  1.4034, -1.3089,  2.7596,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  0.0473],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4034,  1.4034,  0.0473,  1.4034,  1.4034,  0.0473,  1.4034,\n",
       "         2.7596,  1.4034,  0.0473,  0.0473,  1.4034,  1.4034,  1.4034,\n",
       "         0.0473,  1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         2.7596,  1.4034,  0.0473,  0.0473,  1.4034,  0.0473,  2.7596,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  0.0473,\n",
       "         1.4034,  1.4034,  1.4034,  0.0473,  0.0473, -1.3089,  1.4034,\n",
       "         1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  0.0473,  1.4034,\n",
       "         0.0473,  1.4034,  0.0473, -1.3089,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  2.7596,  0.0473,\n",
       "        -1.3089,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         4.1157,  0.0473, -1.3089,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  1.4034,  2.7596,  1.4034,  0.0473, -1.3089,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  1.4034,  2.7596,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  1.4034,\n",
       "         0.0473,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,\n",
       "         1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089,  1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  1.4034,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,\n",
       "         1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034,  1.4034, -1.3089,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  1.4034, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034, -1.3089,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  1.4034, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  2.7596,  0.0473,\n",
       "         1.4034,  1.4034, -1.3089, -1.3089, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473, -1.3089,  1.4034,  0.0473,  1.4034, -1.3089,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473, -1.3089,  0.0473,  0.0473, -1.3089,\n",
       "        -1.3089,  1.4034,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  0.0473, -1.3089, -1.3089,\n",
       "         0.0473,  1.4034, -1.3089,  1.4034,  2.7596, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  2.7596,\n",
       "         1.4034, -1.3089,  0.0473, -1.3089,  0.0473, -1.3089, -1.3089,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089, -1.3089, -1.3089, -1.3089,\n",
       "         0.0473,  0.0473, -1.3089, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473, -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  4.1157, -1.3089, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473, -1.3089, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -1.3089,  1.4034,  1.4034,\n",
       "        -1.3089, -1.3089, -1.3089,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089,  1.4034, -1.3089,  1.4034,  0.0473,  1.4034,\n",
       "         1.4034, -1.3089,  0.0473,  0.0473, -1.3089, -1.3089,  1.4034,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -2.6650, -1.3089, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473, -1.3089, -1.3089, -1.3089,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089,  0.0473,  0.0473, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473,  1.4034, -1.3089,  1.4034, -1.3089,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089,  1.4034,  1.4034,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "        -1.3089,  0.0473, -1.3089, -1.3089, -1.3089, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473,  0.0473, -1.3089, -1.3089,\n",
       "        -1.3089, -1.3089, -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "        -1.3089, -1.3089, -1.3089, -2.6650,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473,  1.4034, -1.3089,  2.7596,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  0.0473],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[:][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "tensor([374, 387, 527, 146, 284, 428,  34, 369, 231, 186, 258, 144,  82,\n",
      "         78, 211, 201, 311, 310, 114, 316, 266, 378, 239, 430,   5, 271,\n",
      "          6,  94, 419, 459, 251, 522, 154, 305, 205, 543, 117, 406, 277,\n",
      "         95, 519, 112, 223, 265, 292, 422, 128, 279, 518, 108, 254, 361,\n",
      "        306,  41, 373, 237, 501, 436, 323, 166, 125,  27, 278,  26, 247,\n",
      "        368, 468, 318,  92, 359, 443, 227, 484, 149, 249, 532,  22, 236,\n",
      "        118, 386, 500, 407, 486,  93, 356, 155, 287,  58,  23, 412, 434,\n",
      "        447,  90, 152, 253, 230, 136, 194,   7, 491, 107, 226, 440,  33,\n",
      "        487, 132, 122, 204, 307, 445, 328, 474, 504,  51, 182, 332, 302,\n",
      "        393, 375,  17, 212, 296, 479, 458, 180, 450,  11, 206, 343, 472,\n",
      "        110, 380, 475, 461, 240, 379, 524, 417, 241, 224, 203, 485, 156,\n",
      "        327, 507, 520, 483,  18, 289, 342, 537,  84, 370, 470,  69, 121,\n",
      "         83, 395, 488,  38, 161,  55, 358, 133, 503, 286, 471, 403, 539,\n",
      "        355, 477, 424, 544, 531, 541, 273, 494, 147, 353,  24,  89, 280,\n",
      "        404, 219, 400, 515, 441, 234, 516, 261, 199, 435, 169, 312, 297,\n",
      "        509, 301, 295, 175,  59, 269,  67,  49,  96, 354, 364, 498, 171,\n",
      "        198, 446,  86, 388,  12, 215, 134, 517, 105, 506,  60, 229, 340,\n",
      "        250, 493, 139, 528, 151, 168, 357, 331, 362, 360, 130, 216, 416,\n",
      "        448,  45, 106, 150, 476, 181, 345, 325, 347, 496, 202,  75,  81,\n",
      "          1, 481, 218,  76, 334, 263, 246, 526, 492, 467, 464, 442, 392,\n",
      "        482, 228, 143,  14, 101,   0,   2, 282, 193,  71, 534, 252, 191,\n",
      "        389,   9, 338, 238,  85, 408, 137, 119, 326, 398,  48, 385, 188,\n",
      "        178, 530, 268, 367, 274, 138, 179, 457, 433, 432, 308, 262,  64,\n",
      "         77, 542, 208, 346, 293,  61, 189, 452, 341, 196, 135,  35, 255,\n",
      "        288,  39, 225, 174, 511,  20,  99, 173, 153, 209, 508, 439, 190,\n",
      "        113, 409, 185, 401, 162,  68, 195, 525, 429, 248,  25, 453, 348,\n",
      "         19, 111, 499,  36, 402, 115, 290, 207,  42, 165, 245, 167, 418,\n",
      "        423, 210, 363,   8, 285, 172, 410, 336, 214, 497, 157, 187, 462,\n",
      "        431, 183, 140, 460, 217,  47, 120,  52, 322, 260, 523,  74, 170,\n",
      "         98, 513, 383, 469, 335, 411,  66, 264,  70, 257, 455, 415,  65,\n",
      "        426,  50, 319, 444, 303, 421, 324, 222, 456,   3, 330, 329, 275,\n",
      "         30, 478, 437, 351, 233, 124, 281, 300, 397, 384, 465, 256, 102,\n",
      "        371, 109,  44, 291, 103, 382, 313, 438, 145, 270, 339,  91, 197,\n",
      "        536, 352,  13, 381, 502, 160, 514])\n",
      "\n",
      "validation:\n",
      "tensor([372, 473,  10,  79, 221, 244, 177, 533, 377, 366, 276, 451,  88,\n",
      "        123,  54, 333, 243,  97, 321, 449,  62, 200,  21, 164, 394, 283,\n",
      "        510, 141, 294, 142,  32, 298, 315, 413, 272, 337, 463, 540, 104,\n",
      "        521,  40, 420, 131, 480,  46,  72, 259,  56, 376, 505, 390,  15,\n",
      "        220, 159, 538,  16, 399,  73,  87, 126,   4, 232, 365,  43, 490,\n",
      "        158, 309, 148, 320, 495,  57,  31, 535, 425, 466, 129,  80,  53,\n",
      "        512, 184, 454,  29, 213,  37, 163, 317, 529, 116, 314, 242, 414,\n",
      "        176, 304, 235, 391, 427, 349, 192, 405, 299,  63, 489, 267, 127,\n",
      "        100, 344, 396,  28, 350])\n"
     ]
    }
   ],
   "source": [
    "n_samples = x.shape[0]\n",
    "n_val = int(percent_for_validation * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "print(f\"training:\\n{train_indices}\")\n",
    "print()\n",
    "print(f\"validation:\\n{val_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = x[train_indices]\n",
    "training_y  = y [train_indices]\n",
    "\n",
    "validation_x = x[val_indices]\n",
    "validation_y  = y[val_indices]\n",
    "\n",
    "# training_un   = 0.1 * training_feature\n",
    "# validation_un = 0.1 * validation_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, \n",
    "                  train_x, val_x,\n",
    "                  train_y, val_y):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_predicted = model(train_x.transpose(-2, 1), *params)\n",
    "        train_loss = loss_function(train_predicted, train_y)\n",
    "\n",
    "        # For the valudation step\n",
    "        with torch.no_grad(): \n",
    "            val_predicted = model(val_x.transpose(-2, 1), *params)\n",
    "            val_loss = loss_function(val_predicted, val_y)\n",
    "            assert val_loss.requires_grad == False # <2>\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "                  f\" Validation loss {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 6.1335, Validation loss 5.7506\n",
      "Epoch 2, Training loss 6.1292, Validation loss 5.7465\n",
      "Epoch 3, Training loss 6.1248, Validation loss 5.7424\n",
      "Epoch 500, Training loss 4.3153, Validation loss 4.0400\n",
      "Epoch 1000, Training loss 3.0776, Validation loss 2.8793\n",
      "Epoch 1500, Training loss 2.2366, Validation loss 2.0941\n",
      "Epoch 2000, Training loss 1.6647, Validation loss 1.5635\n",
      "Epoch 2500, Training loss 1.2756, Validation loss 1.2052\n",
      "Epoch 3000, Training loss 1.0104, Validation loss 0.9637\n",
      "Epoch 3500, Training loss 0.8296, Validation loss 0.8012\n",
      "Epoch 4000, Training loss 0.7060, Validation loss 0.6922\n",
      "Epoch 4500, Training loss 0.6214, Validation loss 0.6192\n",
      "Epoch 5000, Training loss 0.5633, Validation loss 0.5707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.3712, 0.3808, 0.3324, 0.2068, 0.4515, 0.0130],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    train_x = training_x, \n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y\n",
    ")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 6.1335, Validation loss 5.7506\n",
      "Epoch 2, Training loss 6.1321, Validation loss 5.7493\n",
      "Epoch 3, Training loss 6.1306, Validation loss 5.7479\n",
      "Epoch 500, Training loss 5.4315, Validation loss 5.0999\n",
      "Epoch 1000, Training loss 4.7956, Validation loss 4.4975\n",
      "Epoch 1500, Training loss 4.2185, Validation loss 3.9443\n",
      "Epoch 2000, Training loss 3.6948, Validation loss 3.4424\n",
      "Epoch 2500, Training loss 3.2206, Validation loss 2.9893\n",
      "Epoch 3000, Training loss 2.7926, Validation loss 2.5820\n",
      "Epoch 3500, Training loss 2.4083, Validation loss 2.2178\n",
      "Epoch 4000, Training loss 2.0653, Validation loss 1.8946\n",
      "Epoch 4500, Training loss 1.7619, Validation loss 1.6104\n",
      "Epoch 5000, Training loss 1.4962, Validation loss 1.3635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5560, 0.5569, 0.5594, 0.5502, 0.5643, 0.0236],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    train_x = training_x,  \n",
    "    val_x = validation_x, \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y\n",
    ")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77aa5c7a8032890130e9a412da4828609b1dfa25c62620094c03af7a5cea44b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
