{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5 Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## define model and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_for_validation = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(feature, w5, w4, w3, w2, w1, b):\n",
    "    return feature[4] * w5 + feature[3] * w4 + feature[2] * w3 + feature[1] * w2 + feature[0] * w1 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(predicted, actual):\n",
    "    squared_diffs = (predicted - actual)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.01, 0.001, 0.0001, 1e-05]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_to_learn_at = [1/x for x in [10, 100, 1000, 10000, 100000]]\n",
    "rates_to_learn_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13300000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12250000</td>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12250000</td>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>semi-furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12215000</td>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11410000</td>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>furnished</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  area  bedrooms  bathrooms  stories mainroad guestroom basement  \\\n",
       "0  13300000  7420         4          2        3      yes        no       no   \n",
       "1  12250000  8960         4          4        4      yes        no       no   \n",
       "2  12250000  9960         3          2        2      yes        no      yes   \n",
       "3  12215000  7500         4          2        2      yes        no      yes   \n",
       "4  11410000  7420         4          1        2      yes       yes      yes   \n",
       "\n",
       "  hotwaterheating airconditioning  parking prefarea furnishingstatus  \n",
       "0              no             yes        2      yes        furnished  \n",
       "1              no             yes        3       no        furnished  \n",
       "2              no              no        2      yes   semi-furnished  \n",
       "3              no             yes        3      yes        furnished  \n",
       "4              no             yes        2       no        furnished  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.DataFrame(pd.read_csv('Housing.csv'))\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = (545, 13)\n",
      "features are: ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'parking', 'prefarea', 'furnishingstatus']\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape = {np.shape(housing_df)}\")\n",
    "\n",
    "# creates a list of all variables from the column names\n",
    "feature_list = list( housing_df.columns )\n",
    "\n",
    "print(f\"features are: {feature_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary vars = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
      "furnish vars = ['furnishingstatus']\n",
      "value vars = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n"
     ]
    }
   ],
   "source": [
    "# Maps to turn categorys into numbers \n",
    "def boolean_map(x):\n",
    "    return x.map({'yes': 1 , 'no': 0})\n",
    "def furnish_map(x):\n",
    "    return x.map({'furnished': 1 , 'semi-furnished': 0.5 , 'unfurnished': 0})\n",
    "\n",
    "# Extracts the yes and no column names\n",
    "binary_vars = [*feature_list[5:10], feature_list[11]]\n",
    "print(f\"binary vars = {binary_vars}\")\n",
    "\n",
    "# Extracts the furnishing column names\n",
    "furnish_vars = [feature_list[12]]\n",
    "print(f\"furnish vars = {furnish_vars}\")\n",
    "\n",
    "# Extracts the column names that are actual values\n",
    "valued_vars = feature_list.copy()\n",
    "[valued_vars.remove( item ) for item in binary_vars]\n",
    "[valued_vars.remove( item ) for item in furnish_vars]\n",
    "print(f\"value vars = {valued_vars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = housing_df.copy()\n",
    "\n",
    "## scale data\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "x_df[valued_vars] = scaler.fit_transform(x_df[valued_vars])\n",
    "\n",
    "## map text values\n",
    "x_df[binary_vars] = x_df[binary_vars].apply(boolean_map)\n",
    "x_df[furnish_vars] = x_df[furnish_vars].apply(furnish_map)\n",
    "\n",
    "## make y_df\n",
    "y_df = x_df.pop('price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_values = valued_vars.copy()\n",
    "# input_values.remove('price')\n",
    "\n",
    "\n",
    "# x_df = x_df[input_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679409</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.517692</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories  mainroad  guestroom  basement  \\\n",
       "0  1.046726  1.403419   1.421812  1.378217         1          0         0   \n",
       "1  1.757010  1.403419   5.405809  2.532024         1          0         0   \n",
       "2  2.218232  0.047278   1.421812  0.224410         1          0         1   \n",
       "3  1.083624  1.403419   1.421812  0.224410         1          0         1   \n",
       "4  1.046726  1.403419  -0.570187  0.224410         1          1         1   \n",
       "\n",
       "   hotwaterheating  airconditioning   parking  prefarea  furnishingstatus  \n",
       "0                0                1  1.517692         1               1.0  \n",
       "1                0                1  2.679409         0               1.0  \n",
       "2                0                0  1.517692         1               0.5  \n",
       "3                0                1  2.679409         1               1.0  \n",
       "4                0                1  1.517692         0               1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.566365\n",
       "1    4.004484\n",
       "2    4.004484\n",
       "3    3.985755\n",
       "4    3.554979\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>1.378217</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.757010</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>5.405809</td>\n",
       "      <td>2.532024</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.218232</td>\n",
       "      <td>0.047278</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.083624</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>1.421812</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>2.679409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.046726</td>\n",
       "      <td>1.403419</td>\n",
       "      <td>-0.570187</td>\n",
       "      <td>0.224410</td>\n",
       "      <td>1.517692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       area  bedrooms  bathrooms   stories   parking\n",
       "0  1.046726  1.403419   1.421812  1.378217  1.517692\n",
       "1  1.757010  1.403419   5.405809  2.532024  2.679409\n",
       "2  2.218232  0.047278   1.421812  0.224410  1.517692\n",
       "3  1.083624  1.403419   1.421812  0.224410  2.679409\n",
       "4  1.046726  1.403419  -0.570187  0.224410  1.517692"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted data\n",
    "for item in [*binary_vars, *furnish_vars] :\n",
    "    x_df.pop(item)\n",
    "x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data frame to tensor\n",
    "\n",
    "x = torch.tensor(x_df.values)\n",
    "y = torch.tensor(y_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([545, 5])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0467,  1.4034,  ...,  1.3782,  1.5177],\n",
       "        [ 1.7570,  1.4034,  ...,  2.5320,  2.6794],\n",
       "        ...,\n",
       "        [-1.0334,  0.0473,  ..., -0.9294, -0.8057],\n",
       "        [-0.5998,  0.0473,  ...,  0.2244, -0.8057]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(\"\\n\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([545])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5664e+00,  4.0045e+00,  4.0045e+00,  3.9858e+00,  3.5550e+00,\n",
       "         3.2553e+00,  2.8807e+00,  2.8807e+00,  2.7309e+00,  2.6934e+00,\n",
       "         2.6934e+00,  2.6297e+00,  2.4312e+00,  2.3938e+00,  2.3938e+00,\n",
       "         2.3188e+00,  2.3188e+00,  2.2439e+00,  2.2065e+00,  2.1877e+00,\n",
       "         2.1315e+00,  2.0941e+00,  2.0754e+00,  2.0754e+00,  2.0379e+00,\n",
       "         2.0192e+00,  1.9780e+00,  1.9443e+00,  1.9443e+00,  1.9443e+00,\n",
       "         1.9443e+00,  1.9443e+00,  1.8881e+00,  1.8319e+00,  1.7944e+00,\n",
       "         1.7735e+00,  1.7532e+00,  1.7195e+00,  1.7101e+00,  1.6820e+00,\n",
       "         1.6633e+00,  1.6446e+00,  1.5697e+00,  1.5697e+00,  1.4947e+00,\n",
       "         1.4947e+00,  1.4760e+00,  1.4573e+00,  1.4386e+00,  1.4198e+00,\n",
       "         1.4198e+00,  1.4198e+00,  1.3824e+00,  1.3824e+00,  1.3824e+00,\n",
       "         1.3824e+00,  1.3786e+00,  1.3262e+00,  1.3075e+00,  1.3075e+00,\n",
       "         1.2700e+00,  1.2325e+00,  1.2325e+00,  1.2138e+00,  1.1951e+00,\n",
       "         1.1576e+00,  1.1576e+00,  1.1389e+00,  1.1202e+00,  1.0827e+00,\n",
       "         1.0827e+00,  1.0640e+00,  1.0452e+00,  1.0265e+00,  1.0078e+00,\n",
       "         1.0078e+00,  1.0078e+00,  1.0078e+00,  1.0078e+00,  1.0078e+00,\n",
       "         9.9655e-01,  9.8906e-01,  9.8906e-01,  9.7033e-01,  9.3287e-01,\n",
       "         9.3287e-01,  9.3287e-01,  9.1414e-01,  9.1414e-01,  8.9541e-01,\n",
       "         8.9541e-01,  8.8417e-01,  8.7668e-01,  8.2049e-01,  8.2049e-01,\n",
       "         8.2049e-01,  8.2049e-01,  8.2049e-01,  8.1675e-01,  8.0176e-01,\n",
       "         7.8303e-01,  7.8303e-01,  7.6430e-01,  7.6430e-01,  7.6430e-01,\n",
       "         7.4557e-01,  7.4557e-01,  7.2684e-01,  7.1748e-01,  7.0812e-01,\n",
       "         7.0812e-01,  7.0812e-01,  7.0437e-01,  7.0437e-01,  6.7066e-01,\n",
       "         6.7066e-01,  6.7066e-01,  6.3320e-01,  6.3320e-01,  6.3320e-01,\n",
       "         6.3320e-01,  6.3320e-01,  6.3320e-01,  6.3320e-01,  6.3320e-01,\n",
       "         6.2945e-01,  5.9574e-01,  5.9574e-01,  5.9199e-01,  5.9199e-01,\n",
       "         5.8825e-01,  5.5828e-01,  5.5828e-01,  5.5828e-01,  5.5453e-01,\n",
       "         5.3955e-01,  5.2082e-01,  5.2082e-01,  5.2082e-01,  5.2082e-01,\n",
       "         5.2082e-01,  4.7400e-01,  4.4590e-01,  4.4590e-01,  4.4590e-01,\n",
       "         4.4590e-01,  4.4590e-01,  4.4590e-01,  4.4590e-01,  4.4590e-01,\n",
       "         4.4590e-01,  4.2717e-01,  4.2717e-01,  4.0845e-01,  4.0845e-01,\n",
       "         4.0845e-01,  4.0470e-01,  3.8972e-01,  3.8972e-01,  3.7099e-01,\n",
       "         3.7099e-01,  3.7099e-01,  3.7099e-01,  3.5226e-01,  3.3353e-01,\n",
       "         3.2978e-01,  2.9607e-01,  2.7734e-01,  2.5861e-01,  2.5861e-01,\n",
       "         2.5861e-01,  2.5861e-01,  2.5861e-01,  2.5861e-01,  2.5861e-01,\n",
       "         2.5861e-01,  2.5861e-01,  2.5486e-01,  2.4737e-01,  2.3988e-01,\n",
       "         2.3988e-01,  2.3988e-01,  2.0242e-01,  2.0242e-01,  1.8369e-01,\n",
       "         1.8369e-01,  1.8369e-01,  1.8369e-01,  1.6496e-01,  1.4623e-01,\n",
       "         1.4623e-01,  1.4623e-01,  1.4623e-01,  1.4249e-01,  1.2750e-01,\n",
       "         1.0878e-01,  1.0878e-01,  1.0128e-01,  9.0046e-02,  7.5062e-02,\n",
       "         7.1316e-02,  7.1316e-02,  7.1316e-02,  7.1316e-02,  7.1316e-02,\n",
       "         7.1316e-02,  7.1316e-02,  7.1316e-02,  7.1316e-02,  7.1316e-02,\n",
       "         7.1316e-02,  7.1316e-02,  6.7571e-02,  6.7571e-02,  5.2587e-02,\n",
       "         3.3858e-02,  3.3858e-02,  3.3858e-02,  3.3858e-02,  1.5128e-02,\n",
       "         1.5128e-02,  1.4489e-04, -3.6010e-03, -3.6010e-03, -3.6010e-03,\n",
       "        -7.3469e-03, -4.1060e-02, -4.1060e-02, -4.1060e-02, -4.1060e-02,\n",
       "        -4.1060e-02, -4.1060e-02, -5.9789e-02, -7.8518e-02, -7.8518e-02,\n",
       "        -7.8518e-02, -7.8518e-02, -7.8518e-02, -8.2264e-02, -9.7248e-02,\n",
       "        -9.7248e-02, -1.1598e-01, -1.1598e-01, -1.1598e-01, -1.1598e-01,\n",
       "        -1.1598e-01, -1.1598e-01, -1.1598e-01, -1.1972e-01, -1.1972e-01,\n",
       "        -1.3471e-01, -1.3471e-01, -1.3471e-01, -1.3471e-01, -1.5344e-01,\n",
       "        -1.5344e-01, -1.5344e-01, -1.5344e-01, -1.5344e-01, -1.5718e-01,\n",
       "        -1.5718e-01, -1.5718e-01, -1.7217e-01, -1.9089e-01, -1.9089e-01,\n",
       "        -1.9464e-01, -1.9464e-01, -1.9464e-01, -2.0588e-01, -2.0962e-01,\n",
       "        -2.2835e-01, -2.2835e-01, -2.2835e-01, -2.2835e-01, -2.2835e-01,\n",
       "        -2.3959e-01, -2.4708e-01, -2.4708e-01, -2.6207e-01, -2.6581e-01,\n",
       "        -2.6581e-01, -2.6581e-01, -2.6581e-01, -2.6581e-01, -2.6581e-01,\n",
       "        -2.8454e-01, -2.8454e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01,\n",
       "        -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01,\n",
       "        -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01,\n",
       "        -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0327e-01, -3.0702e-01,\n",
       "        -3.0702e-01, -3.2200e-01, -3.2200e-01, -3.2200e-01, -3.4073e-01,\n",
       "        -3.4073e-01, -3.4448e-01, -3.5759e-01, -3.5946e-01, -3.5946e-01,\n",
       "        -3.5946e-01, -3.7819e-01, -3.7819e-01, -3.7819e-01, -3.7819e-01,\n",
       "        -3.7819e-01, -3.9692e-01, -3.9692e-01, -3.9692e-01, -4.0628e-01,\n",
       "        -4.0628e-01, -4.1565e-01, -4.1565e-01, -4.1565e-01, -4.1565e-01,\n",
       "        -4.1565e-01, -4.5311e-01, -4.5311e-01, -4.5311e-01, -4.5311e-01,\n",
       "        -4.5311e-01, -4.5311e-01, -4.5311e-01, -4.7184e-01, -4.7184e-01,\n",
       "        -4.9056e-01, -4.9056e-01, -4.9056e-01, -4.9056e-01, -4.9056e-01,\n",
       "        -4.9056e-01, -4.9056e-01, -4.9806e-01, -5.0929e-01, -5.2802e-01,\n",
       "        -5.2802e-01, -5.2802e-01, -5.2802e-01, -5.2802e-01, -5.2802e-01,\n",
       "        -5.3177e-01, -5.3177e-01, -5.3177e-01, -5.4675e-01, -5.6548e-01,\n",
       "        -5.6548e-01, -5.6548e-01, -5.6548e-01, -5.6548e-01, -5.6923e-01,\n",
       "        -5.6923e-01, -5.8421e-01, -5.8421e-01, -5.8421e-01, -5.8421e-01,\n",
       "        -6.0294e-01, -6.0294e-01, -6.0294e-01, -6.0294e-01, -6.0294e-01,\n",
       "        -6.0294e-01, -6.0294e-01, -6.0294e-01, -6.0294e-01, -6.0669e-01,\n",
       "        -6.2167e-01, -6.2167e-01, -6.4040e-01, -6.4040e-01, -6.4040e-01,\n",
       "        -6.4040e-01, -6.5913e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01,\n",
       "        -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01,\n",
       "        -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01,\n",
       "        -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.7786e-01, -6.8160e-01,\n",
       "        -6.9659e-01, -6.9659e-01, -6.9659e-01, -7.1532e-01, -7.1532e-01,\n",
       "        -7.1532e-01, -7.1532e-01, -7.1532e-01, -7.1532e-01, -7.1906e-01,\n",
       "        -7.3405e-01, -7.3405e-01, -7.3405e-01, -7.5278e-01, -7.5278e-01,\n",
       "        -7.5278e-01, -7.5278e-01, -7.5278e-01, -7.5278e-01, -7.5278e-01,\n",
       "        -7.5278e-01, -7.5652e-01, -7.6776e-01, -7.7151e-01, -7.7151e-01,\n",
       "        -7.9023e-01, -7.9023e-01, -7.9023e-01, -7.9023e-01, -7.9023e-01,\n",
       "        -7.9023e-01, -7.9023e-01, -7.9023e-01, -8.0896e-01, -8.0896e-01,\n",
       "        -8.2020e-01, -8.2769e-01, -8.2769e-01, -8.2769e-01, -8.2769e-01,\n",
       "        -8.6515e-01, -8.6515e-01, -8.6515e-01, -8.6515e-01, -8.6515e-01,\n",
       "        -8.6515e-01, -8.6515e-01, -8.6515e-01, -8.6515e-01, -8.6890e-01,\n",
       "        -8.7639e-01, -8.8182e-01, -8.8388e-01, -8.8388e-01, -8.8388e-01,\n",
       "        -8.9886e-01, -9.0261e-01, -9.0261e-01, -9.0261e-01, -9.0261e-01,\n",
       "        -9.2134e-01, -9.4007e-01, -9.4007e-01, -9.4007e-01, -9.4007e-01,\n",
       "        -9.4007e-01, -9.4007e-01, -9.4007e-01, -9.4382e-01, -9.5880e-01,\n",
       "        -9.6629e-01, -9.7753e-01, -9.7753e-01, -9.7753e-01, -9.7753e-01,\n",
       "        -9.7753e-01, -9.7753e-01, -9.7753e-01, -9.7753e-01, -1.0150e+00,\n",
       "        -1.0150e+00, -1.0150e+00, -1.0150e+00, -1.0244e+00, -1.0337e+00,\n",
       "        -1.0337e+00, -1.0337e+00, -1.0524e+00, -1.0524e+00, -1.0899e+00,\n",
       "        -1.0899e+00, -1.1086e+00, -1.1274e+00, -1.1274e+00, -1.1274e+00,\n",
       "        -1.1274e+00, -1.1274e+00, -1.1274e+00, -1.1274e+00, -1.1311e+00,\n",
       "        -1.1311e+00, -1.1573e+00, -1.1648e+00, -1.1648e+00, -1.1648e+00,\n",
       "        -1.2023e+00, -1.2023e+00, -1.2023e+00, -1.2210e+00, -1.2210e+00,\n",
       "        -1.2397e+00, -1.2397e+00, -1.2397e+00, -1.2397e+00, -1.2397e+00,\n",
       "        -1.2397e+00, -1.2622e+00, -1.2772e+00, -1.2772e+00, -1.2772e+00,\n",
       "        -1.2959e+00, -1.3147e+00, -1.3334e+00, -1.3334e+00, -1.3334e+00,\n",
       "        -1.3521e+00, -1.3559e+00, -1.4083e+00, -1.4270e+00, -1.4270e+00,\n",
       "        -1.4270e+00, -1.5020e+00, -1.5394e+00, -1.5394e+00, -1.5581e+00,\n",
       "        -1.5769e+00, -1.6051e+00, -1.6143e+00, -1.6143e+00, -1.6143e+00],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(\"\\n\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7570, dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4034, dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0467, 1.4034, 1.4218, 1.3782, 1.5177], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0467, 1.4034, 1.4218, 1.3782, 1.5177], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 545])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t = x.transpose(-2, 1)\n",
    "x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4034,  1.4034,  0.0473,  1.4034,  1.4034,  0.0473,  1.4034,\n",
       "         2.7596,  1.4034,  0.0473,  0.0473,  1.4034,  1.4034,  1.4034,\n",
       "         0.0473,  1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         2.7596,  1.4034,  0.0473,  0.0473,  1.4034,  0.0473,  2.7596,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  0.0473,\n",
       "         1.4034,  1.4034,  1.4034,  0.0473,  0.0473, -1.3089,  1.4034,\n",
       "         1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  0.0473,  1.4034,\n",
       "         0.0473,  1.4034,  0.0473, -1.3089,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  2.7596,  0.0473,\n",
       "        -1.3089,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         4.1157,  0.0473, -1.3089,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  1.4034,  2.7596,  1.4034,  0.0473, -1.3089,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  1.4034,  2.7596,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  1.4034,\n",
       "         0.0473,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,\n",
       "         1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089,  1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  1.4034,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,\n",
       "         1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034,  1.4034, -1.3089,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  1.4034, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034, -1.3089,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  1.4034, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  2.7596,  0.0473,\n",
       "         1.4034,  1.4034, -1.3089, -1.3089, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473, -1.3089,  1.4034,  0.0473,  1.4034, -1.3089,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473, -1.3089,  0.0473,  0.0473, -1.3089,\n",
       "        -1.3089,  1.4034,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  0.0473, -1.3089, -1.3089,\n",
       "         0.0473,  1.4034, -1.3089,  1.4034,  2.7596, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  2.7596,\n",
       "         1.4034, -1.3089,  0.0473, -1.3089,  0.0473, -1.3089, -1.3089,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089, -1.3089, -1.3089, -1.3089,\n",
       "         0.0473,  0.0473, -1.3089, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473, -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  4.1157, -1.3089, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473, -1.3089, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -1.3089,  1.4034,  1.4034,\n",
       "        -1.3089, -1.3089, -1.3089,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089,  1.4034, -1.3089,  1.4034,  0.0473,  1.4034,\n",
       "         1.4034, -1.3089,  0.0473,  0.0473, -1.3089, -1.3089,  1.4034,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -2.6650, -1.3089, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473, -1.3089, -1.3089, -1.3089,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089,  0.0473,  0.0473, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473,  1.4034, -1.3089,  1.4034, -1.3089,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089,  1.4034,  1.4034,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "        -1.3089,  0.0473, -1.3089, -1.3089, -1.3089, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473,  0.0473, -1.3089, -1.3089,\n",
       "        -1.3089, -1.3089, -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "        -1.3089, -1.3089, -1.3089, -2.6650,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473,  1.4034, -1.3089,  2.7596,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  0.0473],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4034,  1.4034,  0.0473,  1.4034,  1.4034,  0.0473,  1.4034,\n",
       "         2.7596,  1.4034,  0.0473,  0.0473,  1.4034,  1.4034,  1.4034,\n",
       "         0.0473,  1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         2.7596,  1.4034,  0.0473,  0.0473,  1.4034,  0.0473,  2.7596,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  0.0473,\n",
       "         1.4034,  1.4034,  1.4034,  0.0473,  0.0473, -1.3089,  1.4034,\n",
       "         1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  0.0473,  1.4034,\n",
       "         0.0473,  1.4034,  0.0473, -1.3089,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  2.7596,  0.0473,\n",
       "        -1.3089,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         4.1157,  0.0473, -1.3089,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  1.4034,  2.7596,  1.4034,  0.0473, -1.3089,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  1.4034,  2.7596,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  1.4034,\n",
       "         0.0473,  1.4034,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,\n",
       "         1.4034,  1.4034,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089,  1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  1.4034,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,\n",
       "         1.4034,  0.0473,  0.0473, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034,  1.4034, -1.3089,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  1.4034, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034, -1.3089,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  1.4034, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473,  0.0473,  1.4034,  0.0473,  0.0473,  2.7596,  0.0473,\n",
       "         1.4034,  1.4034, -1.3089, -1.3089, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473, -1.3089,  1.4034,  0.0473,  1.4034, -1.3089,\n",
       "         1.4034,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  1.4034,  0.0473, -1.3089,  0.0473,  0.0473, -1.3089,\n",
       "        -1.3089,  1.4034,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  1.4034,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  0.0473, -1.3089, -1.3089,\n",
       "         0.0473,  1.4034, -1.3089,  1.4034,  2.7596, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  2.7596,\n",
       "         1.4034, -1.3089,  0.0473, -1.3089,  0.0473, -1.3089, -1.3089,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089, -1.3089, -1.3089, -1.3089,\n",
       "         0.0473,  0.0473, -1.3089, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473, -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473,  0.0473,  1.4034,  0.0473,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  4.1157, -1.3089, -1.3089,  0.0473,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473, -1.3089, -1.3089,  0.0473,  0.0473,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -1.3089,  1.4034,  1.4034,\n",
       "        -1.3089, -1.3089, -1.3089,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089,  1.4034, -1.3089,  1.4034,  0.0473,  1.4034,\n",
       "         1.4034, -1.3089,  0.0473,  0.0473, -1.3089, -1.3089,  1.4034,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -2.6650, -1.3089, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473,  0.0473,  0.0473,  0.0473, -1.3089, -1.3089, -1.3089,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089,  0.0473,  0.0473, -1.3089,\n",
       "        -1.3089,  0.0473,  0.0473,  1.4034, -1.3089,  1.4034, -1.3089,\n",
       "         0.0473, -1.3089,  0.0473,  1.4034,  0.0473, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089, -1.3089, -1.3089,  1.4034,  1.4034,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473, -1.3089,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473,  0.0473,  0.0473, -1.3089,  0.0473,\n",
       "        -1.3089,  0.0473, -1.3089, -1.3089, -1.3089, -1.3089,  0.0473,\n",
       "         0.0473, -1.3089,  0.0473,  0.0473,  0.0473, -1.3089, -1.3089,\n",
       "        -1.3089, -1.3089, -1.3089, -1.3089,  0.0473,  1.4034, -1.3089,\n",
       "        -1.3089, -1.3089, -1.3089, -2.6650,  0.0473,  0.0473,  0.0473,\n",
       "        -1.3089,  0.0473,  1.4034, -1.3089,  2.7596,  0.0473, -1.3089,\n",
       "        -1.3089, -1.3089,  0.0473, -1.3089,  0.0473,  0.0473],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t[:][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([330, 232, 145, 185, 457, 194, 266, 444, 182,  55,   7, 516, 536,\n",
       "         183, 141, 440, 476,  23,  29,  69, 282,  25, 108, 407, 388, 350,\n",
       "         268, 252, 479,  36, 320, 496, 253, 419, 509, 161, 163,  85, 488,\n",
       "         504, 513, 453,  79, 213,  97, 519, 405,  28, 309, 345, 426,  49,\n",
       "         326, 303, 178, 402,  77, 254, 462, 523, 358, 130, 114, 143, 248,\n",
       "          12, 498,  39, 461, 466, 410, 450,  16,  45, 157, 292, 325, 492,\n",
       "         208, 107, 172,  48, 352, 443, 533, 532,  47, 314, 520, 262,  88,\n",
       "           6, 195, 249, 442, 416,  61, 201,  75, 404, 217, 480, 486, 164,\n",
       "         428,  34,  87, 500, 104,  18, 135,   2, 151, 379, 354, 390, 403,\n",
       "         382, 497, 142, 171, 275, 441, 429, 203, 166, 133, 211, 220,  40,\n",
       "         356, 324, 273, 229, 300, 196, 338, 487, 448, 274, 264, 117, 342,\n",
       "         515,  62, 214, 216, 234, 173, 246, 198, 294, 483, 265, 401,  27,\n",
       "           8,  33, 335,  21,  58, 505, 256, 490,   4,  38, 353, 417,  57,\n",
       "         210,   5, 176, 180, 199, 424,  83, 339, 389, 286,  90, 514, 425,\n",
       "         255, 418, 392, 144, 455, 360, 535,  10, 437, 192,  78, 277, 366,\n",
       "         447, 226, 489, 190, 329, 169, 297,  70,  41, 109,  93, 209, 540,\n",
       "         302, 472,  91, 175, 250, 270,  86,  51,  73, 432, 336, 278, 140,\n",
       "         283, 276, 522, 373,  95, 393, 106, 346, 351, 412, 218, 103, 467,\n",
       "         415, 128, 285, 167, 334, 411,  71, 181, 293,  44, 267, 464, 506,\n",
       "         362, 279, 328, 260, 230, 111, 237,  72, 159, 367, 306, 468, 526,\n",
       "         212,  15, 184, 380, 120,  46,  19, 435, 543, 456, 129, 469, 258,\n",
       "           0, 205, 537, 170, 421,  42, 397, 272, 239, 387, 313, 357, 261,\n",
       "         289, 207, 206, 451, 225, 307, 446, 484, 281, 238, 291, 471,  67,\n",
       "         134, 233,  66, 127,  74, 125, 459,   3, 224, 465, 318, 433, 245,\n",
       "         189, 445,  30, 131, 377, 149, 344,  99, 501, 347, 138, 162, 337,\n",
       "         200, 152, 499,  52, 530,  76, 315, 102, 257, 116, 305,  35, 343,\n",
       "         316, 531, 333, 269, 491,  13, 263,  96,  17, 221, 244, 363, 359,\n",
       "         240, 370, 284, 454, 375, 177, 280, 332, 174, 431,  32, 478, 123,\n",
       "         430, 160,  84, 413, 341,  24, 259, 473, 118, 202, 191, 452, 517,\n",
       "         371, 527, 365, 386, 503, 301, 364, 495,  81, 156, 525, 449,   9,\n",
       "         395, 434, 470, 414, 331, 436,  94, 222, 197, 271, 541, 186, 369,\n",
       "          82, 308,  64, 420, 534,  14, 512, 391,  63, 101, 439, 511, 311,\n",
       "         378, 544, 122, 147, 231, 398, 427, 422, 458, 477, 394, 228, 361,\n",
       "         179, 154, 408, 400, 241, 299, 399]),\n",
       " tensor([  1, 150, 155, 494, 475, 165, 409, 236, 304,  43, 287,  98,  60,\n",
       "         481, 251,  68,  37, 323, 132, 385, 507,  65, 126, 119, 148, 242,\n",
       "          59, 110, 502, 374, 368, 288, 518, 482, 529, 193, 542,  54,  50,\n",
       "         247, 521, 474,  92, 423, 319, 158, 538,  53, 340,  80, 485, 508,\n",
       "          20, 539, 460, 312, 348, 227,  31, 372, 327, 317, 349, 296, 290,\n",
       "         298, 463, 219, 376, 493, 146, 321, 384,  11,  56, 124, 121, 204,\n",
       "         510, 438, 381, 112, 153, 168, 355, 105,  26, 383, 115,  22, 243,\n",
       "         137, 322, 396, 139, 406, 524, 136, 188, 215, 310, 100, 295, 235,\n",
       "         113, 187, 223,  89, 528]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = x.shape[0]\n",
    "n_val = int(percent_for_validation * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, val_indices  # <1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_x = x[train_indices]\n",
    "training_y  = y [train_indices]\n",
    "\n",
    "validation_x = x[val_indices]\n",
    "validation_y  = y[val_indices]\n",
    "\n",
    "# training_un   = 0.1 * training_feature\n",
    "# validation_un = 0.1 * validation_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, \n",
    "                  train_x, val_x,\n",
    "                  train_y, val_y):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_predicted = model(train_x.transpose(-2, 1), *params)\n",
    "        train_loss = loss_function(train_predicted, train_y)\n",
    "\n",
    "        # For the valudation step\n",
    "        with torch.no_grad(): \n",
    "            val_predicted = model(val_x.transpose(-2, 1), *params)\n",
    "            val_loss = loss_function(val_predicted, val_y)\n",
    "            assert val_loss.requires_grad == False # <2>\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "                  f\" Validation loss {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 5.5141, Validation loss 8.2283\n",
      "Epoch 2, Training loss 5.5106, Validation loss 8.2230\n",
      "Epoch 3, Training loss 5.5070, Validation loss 8.2177\n",
      "Epoch 500, Training loss 4.0157, Validation loss 5.9960\n",
      "Epoch 1000, Training loss 2.9606, Validation loss 4.4107\n",
      "Epoch 1500, Training loss 2.2191, Validation loss 3.2856\n",
      "Epoch 2000, Training loss 1.6978, Validation loss 2.4856\n",
      "Epoch 2500, Training loss 1.3312, Validation loss 1.9153\n",
      "Epoch 3000, Training loss 1.0731, Validation loss 1.5077\n",
      "Epoch 3500, Training loss 0.8913, Validation loss 1.2154\n",
      "Epoch 4000, Training loss 0.7632, Validation loss 1.0051\n",
      "Epoch 4500, Training loss 0.6727, Validation loss 0.8531\n",
      "Epoch 5000, Training loss 0.6087, Validation loss 0.7428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4142, 0.3865, 0.3929, 0.2513, 0.4349, 0.0102],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    train_x = training_x, # <1> \n",
    "    val_x = validation_x, # <1> \n",
    "    train_y = training_y,\n",
    "    val_y = validation_y)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000, \n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    train_t_u = training_t_un, # <1> \n",
    "    val_t_u = validation_t_un, # <1> \n",
    "    train_t_c = training_output,\n",
    "    val_t_c = validation_output)\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77aa5c7a8032890130e9a412da4828609b1dfa25c62620094c03af7a5cea44b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
